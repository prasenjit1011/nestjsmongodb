<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>NodeJS</title>
<script src="cdn/jquery-3.6.0.min.js"></script>
<script src="cdn/js.cookie.min.js"></script>
<link rel="stylesheet" href="styles.css">
</head>
<body>

<div>
<a href="/doctor/index.html">Nodejs</a> &nbsp; 
<a href="/doctor/react.html">React</a> &nbsp; 
<a href="/doctor/docker.html">Docker</a> &nbsp; 
<a href="/doctor/cmd.html">CMD</a> &nbsp; 
<a href="/doctor/kafka.html">Kafka</a> &nbsp; 
<a href="kafka-interview.html">Kafka Interview</a> &nbsp; 
<a href="mongodb.html">Mongo DB</a> &nbsp; 
<a href="DynamoDB.html">Dynamo DB</a> &nbsp; 
<a href="code.html">Promise</a> &nbsp; 
<a href="code.html">Code</a> &nbsp; 
<a href="crud.html">Crud</a> &nbsp; 
<a href="skill.html">Skill</a> &nbsp; 
<a href="https://onecompiler.com/nodejs/43hqq7r87" target="_blank">Coding</a> &nbsp; 
</div>

<ul class="faq">

<li data-id="allq"><span class="faq-question">
Nodejs + Express + Reactjs + PostGre SQL + Redis
</span><div class="answer">
  <table border="1" cellpadding="5">
    <tbody>
      <tr>
        <td>Nodejs</td>
        <td>TypeScript</td>
        <td>NestJS</td>
        <td>AWS Lambda</td>
      </tr>
      <tr>
        <td>Coding</td>
        <td>Reactjs</td>
        <td>Redux</td>
        <td>NextJS</td>
      </tr>
      <tr>
        <td>Docker</td>
        <td>Appsync,DynamoDB,API Gateway</td>
        <td>CI/CD</td>
        <td></td>
      </tr>
      <tr>
        <td>Redis</td>
        <td>MongoDB</td>
        <td>PostGre SQL</td>
        <td>DynamoDB</td>
      </tr>
      <tr>
        <td colspan="4">
          + GraphQL User + MongoDB CRUD + callbind + debounce + Any + => fn + NestJS workflow ++websocket + kafka+Appsync
        </td>
      </tr>
</tbody></table>  

</div></li>

<li data-id="q122"><span class="faq-question green">
  AWS SQS vs SNS
</span>
<div class="answer">
 
    <section>
      <h2>SQS ‚Äì Simple Queue Service</h2>
      <p><strong>Type:</strong> Message Queue (Pull-based)</p>
      <p><strong>Use Case:</strong> Decoupling components, job queues, buffering systems.</p>
      <p><strong>How It Works:</strong> Producers send messages to a queue, and consumers poll the queue to receive messages. FIFO and Standard options available.</p>
      <ul>
        <li>At-least-once delivery (Standard)</li>
        <li>FIFO support with exactly-once processing</li>
        <li>Dead-letter queues for message failure handling</li>
        <li>Consumers must poll ‚Äî no push</li>
      </ul>
    </section>
  
    <section>
      <h2>SNS ‚Äì Simple Notification Service</h2>
      <p><strong>Type:</strong> Publish/Subscribe (Push-based)</p>
      <p><strong>Use Case:</strong> Broadcasting messages to multiple systems like Lambda, email, SMS.</p>
      <p><strong>How It Works:</strong> Publishers send messages to a topic, which pushes messages to all subscribed endpoints.</p>
      <ul>
        <li>Push delivery to multiple endpoints</li>
        <li>Supports SQS, Lambda, HTTP, email, SMS</li>
        <li>Scalable and real-time</li>
      </ul>
    </section>
  
    <section>
      <h2>SQS + SNS Together</h2>
      <p>Commonly used together in fan-out architectures. SNS broadcasts to multiple SQS queues that each process messages independently.</p>
    </section>
  
    <section>
      <h2>Comparison Table</h2>
      <table>
        <thead>
          <tr>
            <th>Feature</th>
            <th>SQS</th>
            <th>SNS</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Pattern</td>
            <td>Pull-based (Queue)</td>
            <td>Push-based (Pub/Sub)</td>
          </tr>
          <tr>
            <td>Use Case</td>
            <td>Decoupling systems</td>
            <td>Broadcast messages to multiple endpoints</td>
          </tr>
          <tr>
            <td>Delivery</td>
            <td>Consumer polls messages</td>
            <td>Pushes to subscribers</td>
          </tr>
          <tr>
            <td>Message Retention</td>
            <td>Up to 14 days</td>
            <td>Short-lived (instant delivery)</td>
          </tr>
          <tr>
            <td>Fan-out</td>
            <td>Not directly supported</td>
            <td>Built-in support</td>
          </tr>
          <tr>
            <td>Subscribers</td>
            <td>One or more consumers</td>
            <td>Multiple (SQS, Lambda, HTTP, etc.)</td>
          </tr>
        </tbody>
      </table>
    </section>
  
    <section class="highlight">
      <h2>TL;DR</h2>
      <p><strong>Use SQS</strong> for reliable message queuing and decoupled, asynchronous processing.</p>
      <p><strong>Use SNS</strong> when you need to notify multiple systems in real time.</p>
    </section>

  
</div></li>


<li data-id="q122"><span class="faq-question green">
  MongoDB
  </span>
  <div class="answer">
  






<pre>
  const mongoose = require('mongoose');

  const userSchema = new mongoose.Schema({
    name: { type: String, required: true },
    email: { type: String, unique: true, required: true },
    age: { type: Number, required: true },
  }, { timestamps: true });
  
  module.exports = mongoose.model('User', userSchema);
</pre>

<pre>
  const user = await User.create(req.body);
  const users = await User.find();
  const user = await User.findById(req.params.id);
  const user = await User.findByIdAndUpdate(req.params.id, req.body, { new: true });
  const user = await User.findByIdAndDelete(req.params.id);
</pre>

<pre>
  await User.updateOne(
    { email: "prasenjit@example.com" },
    { $set: { name: "Prasenjit", age: 30 } },
    { upsert: true }
  );

  const user = await User.findOneAndUpdate(
    { email: "prasenjit@example.com" },     // filter
    { name: "Prasenjit", age: 30 },         // update
    { new: true, upsert: true }             // options
  );
    

  db.orders.aggregate([
  {
      $lookup: {
        from: "products",        // foreign collection
        localField: "product_id",// field in orders
        foreignField: "_id",     // field in products
        as: "productDetails"     // result array field
      }
    }
  ]);

  const result = await Order.aggregate([
  {
      $lookup: {
        from: "products",
        localField: "product_id",
        foreignField: "_id",
        as: "productDetails"
      }
    },
    { $unwind: "$productDetails" }
  ]);

  db.orders.aggregate([
    {
      $lookup: {
        from: "products",
        localField: "product_id",
        foreignField: "_id",
        as: "productDetails"
      }
    },
    { $unwind: "$productDetails" },
    {
      $match: { "productDetails.price": { $gt: 500 } }
    },
    {
      $project: {
        quantity: 1,
        productName: "$productDetails.name",
        price: "$productDetails.price"
      }
    }
  ]);


</pre>


<pre>
  mongoose.connect(process.env.MONGO_URI, {
        useNewUrlParser: true,
        useUnifiedTopology: true
    }).then(() => {
        console.log('MongoDB connected');
        app.listen(PORT, () => console.log(`Server running on port ${PORT}`));
    }).catch(err => console.error(err));
</pre>
<ol>
  <li><strong>Insert Operations</strong>
    <ul>
      <li><code>User.create({ name: "Prasenjit", age: 30 });</code></li>
      <li><code>User.insertMany([{ name: "A", age: 25 }, { name: "B", age: 28 }]);</code></li>
    </ul>
  </li>

  <li><strong>Find Operations</strong>
    <ul>
      <li><code>User.find();</code></li>
      <li><code>User.findById("id");</code></li>
      <li><code>User.find({ age: { $gt: 25 } });</code></li>
      <li><code>User.find({}, 'name age');</code> (select fields)</li>
      <li><code>User.find({}, { password: 0 });</code> (exclude fields)</li>
    </ul>
  </li>

  <li><strong>Update Operations</strong>
    <ul>
      <li><code>User.updateOne({ name: "A" }, { $set: { age: 35 } });</code></li>
      <li><code>User.updateMany({ age: { $lt: 30 } }, { $inc: { age: 1 } });</code></li>
      <li><code>User.findByIdAndUpdate(id, { $set: { name: "Updated" } }, { new: true });</code></li>
    </ul>
  </li>

  <li><strong>Delete Operations</strong>
    <ul>
      <li><code>User.deleteOne({ name: "A" });</code></li>
      <li><code>User.deleteMany({ age: { $gt: 40 } });</code></li>
      <li><code>User.findByIdAndDelete(id);</code></li>
    </ul>
  </li>

  <li><strong>Upsert</strong>
    <ul>
      <li><code>User.updateOne({ email: "a@example.com" }, { $set: { name: "Upserted User" } }, { upsert: true });</code></li>
    </ul>
  </li>

  <li><strong>Sorting, Limiting, Skipping (Pagination)</strong>
    <ul>
      <li><code>User.find().sort({ age: -1 });</code></li>
      <li><code>User.find().limit(10);</code></li>
      <li><code>User.find().skip(10).limit(10);</code></li>
    </ul>
  </li>

  <li><strong>Aggregation Operators</strong>
    <ul>
      <li>
        <code>
          User.aggregate([
            { $match: { age: { $gte: 25 } } },
            { $group: { _id: "$age", total: { $sum: 1 } } },
            { $sort: { _id: 1 } }
          ]);
        </code>
      </li>
    </ul>
  </li>

  <li><strong>$lookup (Join)</strong>
    <ul>
      <li>
        <code>
          User.aggregate([
            {
              $lookup: {
                from: "orders",
                localField: "_id",
                foreignField: "userId",
                as: "userOrders"
              }
            }
          ]);
        </code>
      </li>
    </ul>
  </li>

  <li><strong>Count</strong>
    <ul>
      <li><code>User.countDocuments({ age: { $gt: 25 } });</code></li>
    </ul>
  </li>

  <li><strong>Regex Search</strong>
    <ul>
      <li><code>User.find({ name: { $regex: "pras", $options: "i" } });</code></li>
    </ul>
  </li>

  <li><strong>Indexing</strong>
    <ul>
      <li><code>userSchema.index({ email: 1 }, { unique: true });</code></li>
      <li><code>User.collection.createIndex({ name: 1 });</code></li>
    </ul>
  </li>

  <li><strong>Transactions</strong>
    <ul>
      <li>
        <code>
          const session = await mongoose.startSession();<br>
          try {<br>
          &nbsp;&nbsp;session.startTransaction();<br>
          &nbsp;&nbsp;await User.create([{ name: "Tx User" }], { session });<br>
          &nbsp;&nbsp;await Order.create([{ total: 100 }], { session });<br>
          &nbsp;&nbsp;await session.commitTransaction();<br>
          } catch (err) {<br>
          &nbsp;&nbsp;await session.abortTransaction();<br>
          } finally {<br>
          &nbsp;&nbsp;session.endSession();<br>
          }
        </code>
      </li>
    </ul>
  </li>

  <li><strong>Utility Functions</strong>
    <ul>
      <li><code>User.exists({ email: "a@example.com" });</code></li>
      <li><code>User.distinct("age");</code></li>
      <li><code>User.estimatedDocumentCount();</code></li>
    </ul>
  </li>
</ol>

</div>
</li>









<li data-id="q122"><span class="faq-question green">
  Arrow Function
</span>
<div class="answer">
  <h2>Arrow Function vs Normal Function in Node.js</h2>

<table border="1" cellpadding="8" cellspacing="0">
  <thead>
    <tr>
      <th>Feature</th>
      <th>Arrow Function</th>
      <th>Normal Function</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Syntax</strong></td>
      <td><b>const fn = () => {}</b></td>
      <td><b>function fn() {}</b></td>
    </tr>
    <tr>
      <td><strong>this Binding</strong></td>
      <td>Inherits <b>this</b> from the enclosing scope</td>
      <td>Has its own <b>this</b> context</td>
    </tr>
    <tr>
      <td><strong>Constructor</strong></td>
      <td>Cannot be used as a constructor (no <b>new</b>)</td>
      <td>Can be used as a constructor with <b>new</b></td>
    </tr>
    <tr>
      <td><strong>Arguments Object</strong></td>
      <td>No <b>arguments</b> object</td>
      <td>Has <b>arguments</b> object</td>
    </tr>
    <tr>
      <td><strong>Usage in Callbacks</strong></td>
      <td>Best for callbacks due to lexical <b>this</b></td>
      <td>Requires manual <b>this</b> binding in some cases</td>
    </tr>
    <tr>
      <td><strong>Hoisting</strong></td>
      <td>Not hoisted</td>
      <td>Function declarations are hoisted</td>
    </tr>
    <tr>
      <td><strong>Readable/Verbose</strong></td>
      <td>Shorter and cleaner syntax</td>
      <td>More verbose, but clearer in some contexts</td>
    </tr>
  </tbody>
</table>

<h3>Example:</h3>

<pre>
  // Arrow Function
  const add = (a, b) => a + b;

  // Normal Function
  function add(a, b) {
    return a + b;
  }
</pre>

</div></li>

<li data-id="q122"><span class="faq-question green">
  CORS
</span>
<div class="answer">
Cross-Origin Resource Sharing

  <p><strong>CORS</strong> is a security feature implemented by web browsers that restricts web pages from making requests to a different domain (origin) than the one that served the web page.</p>
  
  <h3>‚úÖ Example Scenario:</h3>
  <ul>
    <li>Your frontend is served from <code>http://localhost:3000</code></li>
    <li>Your backend API is running at <code>http://localhost:5000</code></li>
    <li>Calling the backend from the frontend without proper CORS setup will cause a CORS error.</li>
  </ul>
  
  <h3>üö´ Example CORS Error:</h3>
  <pre style="background:#f8f8f8;padding:10px;">
  Access to fetch at 'http://localhost:5000/api' from origin 'http://localhost:3000' 
  has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present.
  </pre>
  
  <h3>üõ†Ô∏è How to Fix CORS in Node.js (Express)</h3>
  
  <pre><code>
  // Install the CORS middleware
  // npm install cors
  
  const express = require('express');
  const cors = require('cors');
  const app = express();
  
  // Enable CORS for all routes
  app.use(cors());
  
  app.get('/api', (req, res) => {
    res.json({ message: 'CORS is enabled!' });
  });
  
  app.listen(5000, () => console.log('Server running on port 5000'));
  </code></pre>
  
  <h3>üåê CORS Headers Sent by Server:</h3>
  <ul>
    <li><code>Access-Control-Allow-Origin: *</code> ‚Äî Allow all origins</li>
    <li><code>Access-Control-Allow-Methods: GET, POST, PUT, DELETE</code></li>
    <li><code>Access-Control-Allow-Headers: Content-Type</code></li>
  </ul>
  
  <h3>üîí Important Notes:</h3>
  <ul>
    <li>Always restrict allowed origins in production (do not use <code>*</code>)</li>
    <li>Preflight OPTIONS requests are sent before certain methods like <code>POST</code> with custom headers</li>
  </ul>
  
</div></li>


<li data-id="q122"><span class="faq-question green">
  React useReducer Example
</span>
<div class="answer">

<pre>
  
      const { useReducer } = React;
  
      // Step 1: Define the reducer function
      function counterReducer(state, action) {
        switch (action.type) {
          case 'increment':
            return { count: state.count + 1 };
          case 'decrement':
            return { count: state.count - 1 };
          case 'reset':
            return { count: 0 };
          default:
            return state;
        }
      }
  
      // Step 2: Component using useReducer
      function Counter() {
        const [state, dispatch] = useReducer(counterReducer, { count: 0 });
  
        return (
          <div style={{ fontFamily: 'Arial', padding: '20px' }}>
            <h2>useReducer Counter</h2>
            <p>Count: {state.count}</p>
            <button onClick={() => dispatch({ type: 'increment' })}>Increment</button>
            <button onClick={() => dispatch({ type: 'decrement' })}>Decrement</button>
            <button onClick={() => dispatch({ type: 'reset' })}>Reset</button>
          </div>
        );
      }
  
      // Render the component
      ReactDOM.createRoot(document.getElementById('root')).render(<Counter />);
  
    </pre>
</div></li>

<li data-id="q122"><span class="faq-question green">
  Calls, apply, bind, callBind
</span>
<div class="answer">
  <h2>Are <b>call</b>, <b>apply</b>, <b>bind</b>, and <b>callBind</b> Mandatory to Learn?</h2>

<ol>
  <li>
    <h3><b>call()</b>, <b>apply()</b>, and <b>bind()</b> ‚Äì <span style="color: green;">Yes, Mandatory</span></h3>
    <ul>
      <li>They are core JavaScript features and part of the official ECMAScript specification.</li>
      <li>Used frequently in real-world development for:
        <ul>
          <li>Function borrowing (e.g., using <b>Array.prototype</b> methods on objects)</li>
          <li>Controlling the <b>this</b> context in callback functions and event handlers</li>
          <li>Partial function application with <b>bind()</b></li>
        </ul>
      </li>
      <li>Commonly asked in technical interviews and coding assessments.</li>
      <li>Essential for understanding how JavaScript functions and scope resolution work.</li>
    </ul>
  </li>

  <li>
    <h3><b>callBind()</b> ‚Äì <span style="color: orange;">Optional</span></h3>
    <ul>
      <li><strong>Not part of standard JavaScript or Node.js</strong>.</li>
      <li>Found in some utility libraries or polyfills (e.g., <b>es-abstract</b>).</li>
      <li>Only necessary if you're working with low-level utility libraries, custom polyfills, or contributing to frameworks.</li>
      <li>Understanding it gives insight into advanced JavaScript patterns but is not required for day-to-day development.</li>
    </ul>
  </li>
</ol>

<h3>Conclusion</h3>
<p><strong>If you're learning JavaScript/Node.js seriously, mastering <b>call</b>, <b>apply</b>, and <b>bind</b> is <span style="color: green;">essential</span>.</strong></p>
<p><b>callBind</b> is <span style="color: orange;">optional</span> and only useful in specialized or advanced scenarios.</p>

</div>


<div class="answer">
<h3>1. <b>call()</b></h3>
<p>Calls a function with a given <b>this</b> value and arguments provided one by one.</p>
<pre>
  function greet(greeting) {
    console.log(`${greeting}, ${this.name}`);
  }

  const person = { name: 'Alice' };
  greet.call(person, 'Hello');  // Output: Hello, Alice
</pre>

<h3>2. apply()</h3>
<p>Calls a function with a given <b>this</b> value, and arguments provided as an array.</p>
<pre>
  greet.apply(person, ['Hi']);  // Output: Hi, Alice
</pre>

<h3>3. <b>bind()</b></h3>
<p>Returns a new function with the bound <b>this</b> context and optional preset arguments.</p>
<pre>
  const boundGreet = greet.bind(person, 'Hey');
  boundGreet();  // Output: Hey, Alice
</pre>

<h3>4. <b>callBind</b> (Not Standard)</h3>
<p><b>callBind</b> is <strong>not</strong> a standard method in JavaScript or Node.js.</p>
<p>However, it may appear in some libraries or polyfills. For example:</p>
<pre>const callBind = Function.prototype.call.bind(Function.prototype.bind);
</pre>
<p>This pattern is used in advanced libraries (like <b>core-js</b> or <b>es-abstract</b>) to create utility functions.</p>

<h3>Summary Table</h3>
<table border="1" cellpadding="6">
  <thead>
    <tr>
      <th>Method</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>call</code></td>
      <td>Invokes a function with a specific <b>this</b> and individual arguments</td>
    </tr>
    <tr>
      <td><code>apply</code></td>
      <td>Like <b>call</b>, but accepts arguments as an array</td>
    </tr>
    <tr>
      <td><code>bind</code></td>
      <td>Returns a new function with <b>this</b> permanently bound</td>
    </tr>
    <tr>
      <td><code>callBind</code></td>
      <td><strong>Not a built-in method</strong>, used in some libraries as a utility</td>
    </tr>
  </tbody>
</table>

  </div>


<div class="answer">
  <h2>Advantages of <b>call</b>, <b>apply</b>, <b>bind</b>, and <b>callBind</b> in JavaScript</h2>

  <ol>
    <li>
      <h3><b>call()</b></h3>
      <ul>
        <li>Allows invoking a function with an explicitly set <b>this</b> context.</li>
        <li>Useful for borrowing methods from other objects.</li>
        <li>Arguments are passed individually, which can be simpler when you know the exact number.</li>
        <li>Good for invoking functions immediately with dynamic context.</li>
      </ul>
    </li>
  
    <li>
      <h3><b>apply()</b></h3>
      <ul>
        <li>Similar to <b>call</b>, but accepts arguments as an array.</li>
        <li>Helpful when arguments are already in an array or array-like structure (e.g., <b>arguments</b> object).</li>
        <li>Commonly used with functions like <b>Math.max.apply(null, array)</b>.</li>
      </ul>
    </li>
  
    <li>
      <h3><b>bind()</b></h3>
      <ul>
        <li>Returns a new function with permanently bound <b>this</b> context.</li>
        <li>Ideal for callback scenarios where <b>this</b> context needs to persist (e.g., event handlers).</li>
        <li>Supports partial application (pre-setting arguments).</li>
        <li>Improves readability and predictability of context-bound code.</li>
      </ul>
    </li>
  
    <li>
      <h3><b>callBind()</b> (Non-standard)</h3>
      <ul>
        <li>Not part of native JavaScript, but found in utility libraries (e.g., <b>es-abstract</b>).</li>
        <li>Combines the behavior of <b>Function.prototype.call</b> and <b>bind</b>.</li>
        <li>Enables reusable, context-fixed versions of functions.</li>
        <li>Useful in building polyfills or reusable low-level utilities.</li>
      </ul>
    </li>
  </ol>
  
</div>

</li>

<li data-id="q122"><span class="faq-question">
Express + PostGre SQL + Redis
</span><div class="answer">
  <ol>
    <li>How do Express.js, PostgreSQL, and Redis work together in a backend architecture?</li>
    <li>What are the common use cases for Redis when using PostgreSQL as the main DB?</li>
    <li>How do you structure an Express app to connect with PostgreSQL and Redis efficiently?</li>
    <li>When should you cache PostgreSQL queries with Redis?</li>
    <li>How do you invalidate a Redis cache when PostgreSQL data is updated?</li>
  
    <li>What are the main data types in PostgreSQL?</li>
    <li>What is the difference between <b>VARCHAR</b>, <b>TEXT</b>, and <b>CHAR</b> in PostgreSQL?</li>
    <li>How do you write a <b>JOIN</b> query in PostgreSQL?</li>
    <li>How does indexing work in PostgreSQL? What types of indexes are there?</li>
    <li>What is a composite index and when should you use it?</li>
    <li>How does <b>UPSERT</b> work in PostgreSQL (<b>ON CONFLICT</b>)?</li>
    <li>How do you create and use stored procedures in PostgreSQL?</li>
    <li>How do transactions work in PostgreSQL and how are they handled in Node.js?</li>
    <li>What are triggers and when would you use them in PostgreSQL?</li>
    <li>How do you implement pagination using <b>LIMIT</b> and <b>OFFSET</b> in PostgreSQL?</li>
  
    <li>What is the difference between row-level and table-level locking?</li>
    <li>What is a CTE (Common Table Expression) and how do you use it?</li>
    <li>Explain the use of <b>WITH</b> queries in PostgreSQL.</li>
    <li>What is the purpose of PostgreSQL extensions like <b>pg_stat_statements</b> or <b>uuid-ossp</b>?</li>
    <li>How do you optimize slow queries in PostgreSQL?</li>
    <li>Explain the difference between <b>INNER JOIN</b>, <b>LEFT JOIN</b>, and <b>FULL OUTER JOIN</b>.</li>
    <li>What is query plan analysis (<b>EXPLAIN ANALYZE</b>) and how do you use it?</li>
    <li>What are sequences and how do they work for auto-incrementing IDs?</li>
    <li>How does PostgreSQL handle JSON and JSONB fields?</li>
    <li>How do you use array columns in PostgreSQL and what are their pros/cons?</li>
  
    <li>What are the main data types in Redis and their use cases?</li>
    <li>How does Redis differ from a traditional SQL or NoSQL database?</li>
    <li>What is the purpose of setting key expiration in Redis?</li>
    <li>How can Redis help improve PostgreSQL performance?</li>
    <li>How do you cache a PostgreSQL query result in Redis with expiration?</li>
    <li>What are Redis eviction policies and when do they matter?</li>
    <li>What‚Äôs the difference between <b>SET</b>, <b>HSET</b>, and <b>ZADD</b> in Redis?</li>
    <li>How do you implement a cache-aside pattern using Redis?</li>
    <li>How would you ensure cache consistency between Redis and PostgreSQL?</li>
    <li>What is Redis Pub/Sub and can it be used to synchronize PostgreSQL events?</li>
  
    <li>How do you monitor and debug Redis performance?</li>
    <li>What are Redis Streams and how could they be used in a microservice system?</li>
    <li>How do you secure a Redis server?</li>
    <li>Can Redis be used for rate limiting? How would you implement it in Express?</li>
    <li>How can Redis be used for session storage in Express apps?</li>
    <li>What‚Äôs the role of Redis in distributed locking and how do you implement it?</li>
    <li>Explain the difference between <b>DEL</b>, <b>UNLINK</b>, and key expiration.</li>
    <li>How does Redis handle replication and clustering?</li>
    <li>How would you handle failover with Redis Sentinel?</li>
    <li>What are the trade-offs of using Redis as a primary data store instead of PostgreSQL?</li>
  
    <li>How do you prevent the N+1 query problem with PostgreSQL in Express?</li>
    <li>How do you structure caching logic for REST endpoints?</li>
    <li>How do you test Redis cache logic in unit/integration tests?</li>
    <li>What tools or ORMs do you use for PostgreSQL in Express?</li>
    <li>How do you manage environment-based Redis and PostgreSQL connections in Node.js?</li>

    <!-- Architecture & Design -->
    <li>How do Express.js, PostgreSQL, Redis, and a scheduler (e.g., node-cron) work together in a backend architecture?</li>
    <li>What are the common use cases for Redis in a system that also uses PostgreSQL?</li>
    <li>Why would you schedule jobs in a Node.js application using PostgreSQL and Redis?</li>
    <li>When would you choose Redis over PostgreSQL for certain types of data?</li>
    <li>How do you manage distributed job scheduling when using PostgreSQL and Redis?</li>
  
    <!-- PostgreSQL Core -->
    <li>What are the most used PostgreSQL data types and their purposes?</li>
    <li>How do you implement complex joins in PostgreSQL?</li>
    <li>How do indexes improve PostgreSQL performance?</li>
    <li>What are partial indexes and when should you use them?</li>
    <li>How do you implement cascading deletes or updates using foreign keys?</li>
  
    <!-- PostgreSQL Advanced -->
    <li>What is the difference between CTEs and subqueries in PostgreSQL?</li>
    <li>What are materialized views and how do you use them?</li>
    <li>How do you handle schema migrations in a production PostgreSQL database?</li>
    <li>How would you implement recurring job logic in PostgreSQL using stored procedures?</li>
    <li>How can you track execution logs or audit trails using PostgreSQL?</li>
  
    <!-- PostgreSQL + Scheduler -->
    <li>How can PostgreSQL and a scheduler be combined to run periodic reports?</li>
    <li>How do you ensure transactional integrity during a scheduled job that involves writes to PostgreSQL?</li>
    <li>How can a failed PostgreSQL transaction during a scheduled job be retried safely?</li>
    <li>How do you use PostgreSQL advisory locks in scheduled tasks?</li>
    <li>What is the role of cron expressions in job scheduling?</li>
  
    <!-- Redis Core -->
    <li>What are the main Redis data structures and when do you use them?</li>
    <li>How do you use Redis to cache PostgreSQL query results?</li>
    <li>What is the difference between Redis `SETEX` and `EXPIRE`?</li>
    <li>How do Redis TTL and eviction policies affect caching strategies?</li>
    <li>How do you prevent cache stampede in Redis?</li>
  
    <!-- Redis Advanced -->
    <li>What are Redis streams and how can they be used to log scheduled job activity?</li>
    <li>How would you use Redis Pub/Sub to trigger events from scheduled jobs?</li>
    <li>How do you use Redis to implement distributed locking in scheduled tasks?</li>
    <li>What are Redis sorted sets and how could they help with job prioritization?</li>
    <li>How do you monitor Redis memory and performance in a production system?</li>
  
    <!-- Scheduler Integration -->
    <li>What is node-cron and how does it compare to libraries like Agenda or Bull?</li>
    <li>How do you prevent overlapping scheduled jobs in an Express+Redis setup?</li>
    <li>How would you implement retry logic for a failed scheduled task?</li>
    <li>How do you dynamically schedule jobs from a PostgreSQL table?</li>
    <li>What is a dead-letter queue and how can you implement one with Redis?</li>
  
    <!-- Caching Strategy -->
    <li>What is cache-aside strategy and how is it implemented with PostgreSQL and Redis?</li>
    <li>How do you invalidate Redis cache when PostgreSQL records are updated?</li>
    <li>What‚Äôs the tradeoff between caching full objects vs. partial query results?</li>
    <li>What are some best practices for Redis key naming and structure?</li>
    <li>How can Redis assist in paginating large PostgreSQL datasets?</li>
  
    <!-- Real-Time & Messaging -->
    <li>How can Redis Pub/Sub be used for real-time notifications after scheduled DB updates?</li>
    <li>How can Redis help decouple PostgreSQL writes from real-time user updates?</li>
    <li>How do you throttle scheduled API calls using Redis counters?</li>
    <li>How can you use Redis bitmaps or HyperLogLogs for scheduled analytics?</li>
    <li>How do you implement rate limiting for scheduled jobs in Redis?</li>
  
    <!-- Testing, Security, Deployment -->
    <li>How do you test scheduled jobs that modify PostgreSQL and Redis state?</li>
    <li>How do you secure Redis and PostgreSQL connections in Node.js applications?</li>
    <li>How would you structure a production-ready scheduler using Express + PostgreSQL + Redis?</li>
    <li>What logging and alerting strategies would you implement for background jobs?</li>
    <li>What tools can be used to visualize PostgreSQL query metrics and Redis cache hits?</li>
  </ol>
  

  
</div></li>





<li data-id="q122"><span class="faq-question">
Node.js?
</span><div class="answer">
Node.js is an open-source, cross-platform runtime built on Chrome‚Äôs V8 JavaScript engine that allows JavaScript to run outside the browser. <br />
It‚Äôs designed for building scalable, event-driven, non-blocking I/O applications, commonly used for servers and APIs.
<br />
<br />
<br />

Indexing
Async / await ?
CICD : workflow
CROS
sequlize
MySQL
TypeScript
nestjs 
tailwind

shallow / shadow copy



</div></li>





<li data-id="q_redux_formatted" class="yellow"><span class="faq-question">
  Redux
  </span><div class="answer">
  <strong>Redux</strong> is a state management library often used with React for building user interfaces. It provides a centralized store for managing the application's state, making it predictable and maintainable.


  <ol class="subul">
  <li><strong>Store:</strong> The single source of state data that holds the entire state data of the application.</li>
  <li><strong>Actions:</strong> Plain JavaScript objects that describe an event that occurred. Every action must have a type field.</li>
  <li><strong>Reducers:</strong> A pure function that takes the current state and an action, and returns a new state based on the action type.</li>
  <li><strong>Dispatch:</strong> A method to send actions to the reducer to update the state.</li>
  <li><strong>Subscription:</strong> Listeners that get called whenever the state changes. </li>
  </ol>

  <br><strong>React Redux:</strong> is the official React binding for Redux. It allows React components to interact with the Redux store.
  <ol class="subul">
  <li><strong>Provider:</strong> Makes the Redux store available to the app.</li>
  <li><strong>useSelector:</strong> Hook to read data from the store.</li>
  <li><strong>useDispatch:</strong> Hook to dispatch actions to the store.</li>
  </ol>

  <br><strong>How It Works:</strong>
  <ol class="subul">
  <li>A component dispatches an action.</li>
  <li>The action is sent to a reducer.</li>
  <li>The reducer updates the state based on the action.</li>
  <li>Subscribed components are notified and re-render with new data.</li>
  </ol>

  <br><strong>Redux Toolkit:</strong>
  The recommended way to write Redux logic, simplifying store setup, reducers, and immutable updates.

  <br><br><strong>Benefits:</strong>
  <ul class="subul">
  <li>Centralized State Management</li>
  <li>Predictable State Updates</li>
  <li>Improved Debugging</li>
  <li>Performance Optimization</li>
  </ul>

  <br><strong>Use Cases:</strong><br>
  Redux is best suited for large, complex applications with shared state. For simpler apps, React's Context API may be enough.
  </div></li>
  <li data-id="q_redux_example"><span class="faq-question">
    Redux Example ***
    </span><div class="answer">
    
<pre>
  This sets up a working counter app using Redux.
  <strong>1. Install Redux:</strong>  npm install redux react-redux

  <strong>2. Create Action:</strong>  actions.js
  export const increment = () =&gt; ({ type: 'INCREMENT' });


  <strong>3. Create Reducer:</strong>  reducer.js
  const counterReducer = (state = 0, action) =&gt; {
    switch (action.type) {
      case 'INCREMENT':
        return state + 1;
      default:
        return state;
    }
  };
  export default counterReducer;



  <strong>4. Create Store:</strong>  store.js
  import { createStore } from 'redux';
  import counterReducer from './reducer';
  const store = createStore(counterReducer);
  export default store;



  <strong>5. Provide Store to React:</strong>  index.js
  import React from 'react';
  import ReactDOM from 'react-dom';
  import { Provider } from 'react-redux';
  import App from './App';
  import store from './store';
  
  ReactDOM.render(
    &lt;Provider store={store}&gt;
      &lt;App /&gt;
    &lt;/Provider&gt;,
    document.getElementById('root')
  );


  
  <strong>6. Use Redux in Component:</strong>  App.js
  import React from 'react';
  import { useSelector, useDispatch } from 'react-redux';
  import { increment } from './actions';
  
  function App() {
    const count = useSelector(state =&gt; state);
    const dispatch = useDispatch();
  
    return (
      &lt;div&gt;
        &lt;h1&gt;Count: {count}&lt;/h1&gt;
        &lt;button onClick={() =&gt; dispatch(increment())}&gt;Increment&lt;/button&gt;
      &lt;/div&gt;
    );
  }
  export default App;
</pre>
    
    
    </div></li>

    <li data-id="q_redux_middleware"><span class="faq-question">
      Redux Middleware?
      </span><div class="answer">
      Redux middleware is a function that sits between the dispatching of an action and the moment it reaches the reducer. It provides a powerful way to extend Redux with custom functionality such as logging, crash reporting, asynchronous operations (like API calls), etc.
      
      <br><br><strong>How Middleware Works:</strong><br>
      When an action is dispatched, middleware can intercept it, perform tasks (e.g., logging or fetching data), and then pass the action to the reducer.
      

<pre>
  <strong>Example:</strong> 
  const loggerMiddleware = store =&gt; next =&gt; action =&gt; {
    console.log('Dispatching:', action);
    return next(action);
  };

  <strong>Apply Middleware:</strong>
  import { createStore, applyMiddleware } from 'redux';
  const store = createStore(reducer, applyMiddleware(loggerMiddleware));


</pre>
      
      <br><strong>Common Middleware:</strong><br>
      <ul>
        <li><strong>redux-thunk:</strong> For async logic using functions as actions.</li>
        <li><strong>redux-saga:</strong> For complex async flows using generators.</li>
        <li><strong>redux-logger:</strong> For logging actions and state.</li>
      </ul>
      
      Middleware enhances Redux functionality while keeping actions and reducers pure and focused.
      </div></li>
      
      <li data-id="q_redux_thunk"><span class="faq-question">
        Redux-Thunk?
        </span><div class="answer">
        <code>redux-thunk</code> is a middleware for Redux that allows you to write action creators that return a function instead of an action. This function can perform asynchronous operations (like API calls) and then dispatch regular actions based on the result.
        
        <br><br><strong>Why Use redux-thunk?</strong><br>
        Redux only supports synchronous data flow by default. To handle async operations like fetching data, you need middleware like <code>redux-thunk</code>.
        
        <br><br><strong>Installation:</strong><br>
        <code>npm install redux-thunk</code>
        
        <br><br><strong>Apply Thunk Middleware:</strong><br>
        <pre><code>
        import { createStore, applyMiddleware } from 'redux';
        import thunk from 'redux-thunk';
        const store = createStore(reducer, applyMiddleware(thunk));
        </code></pre>
        
        <br><strong>Example Usage:</strong><br>
        <pre><code>
        const fetchUser = () =&gt; {
          return dispatch =&gt; {
            dispatch({ type: 'USER_FETCH_REQUEST' });
            fetch('/api/user')
              .then(res =&gt; res.json())
              .then(data =&gt; dispatch({ type: 'USER_FETCH_SUCCESS', payload: data }))
              .catch(error =&gt; dispatch({ type: 'USER_FETCH_FAILURE', error }));
          };
        };
        </code></pre>
        
        <br>With <code>redux-thunk</code>, you can delay the dispatch of an action or dispatch only if a certain condition is met, enabling more flexible and powerful Redux logic.
        </div></li>
        
        <li data-id="q_redux_saga"><span class="faq-question">
          Redux-Saga?
          </span><div class="answer">
          Redux-Saga is a middleware library for Redux that manages side effects like asynchronous data fetching and impure things (e.g., accessing browser cache). It uses ES6 generator functions to make async flows easier to read, write, and test.
          
          <br><br><strong>How Redux-Saga Works:</strong><br>
          Sagas listen for dispatched actions and run generator functions (‚Äúsagas‚Äù) that yield effects, such as calling APIs or dispatching other actions.
          
          <br><br><strong>Benefits:</strong><br>
          <ul>
            <li>Better handling of complex async logic and side effects</li>
            <li>Easy to test due to generator functions</li>
            <li>Declarative effects make flow control simpler</li>
          </ul>
          
          <br><strong>Basic Example:</strong><br>
          <pre><code>
          import { takeEvery, call, put } from 'redux-saga/effects';
          
          function* fetchUser(action) {
            try {
              const data = yield call(fetch, '/api/user');
              const user = yield data.json();
              yield put({ type: 'USER_FETCH_SUCCESS', payload: user });
            } catch (e) {
              yield put({ type: 'USER_FETCH_FAILURE', error: e.message });
            }
          }
          
          function* watchFetchUser() {
            yield takeEvery('USER_FETCH_REQUEST', fetchUser);
          }
          </code></pre>
          
          Redux-Saga offers powerful control over side effects and concurrency in Redux apps.
          </div></li>
          
          <li data-id="q_redux_logger"><span class="faq-question">
            Redux-Logger?
            </span><div class="answer">
            <code>redux-logger</code> is a middleware for Redux that logs actions and state changes to the console. It helps developers debug by showing detailed information about every dispatched action and how the state updates.
            
            <br><br><strong>How it works:</strong><br>
            When an action is dispatched, redux-logger prints the previous state, the action, and the next state in a formatted and readable way.
            
            <br><br><strong>Installation:</strong><br>
            <code>npm install redux-logger</code>
            
            <br><br><strong>Setup Example:</strong><br>
            <pre><code>
            import { createStore, applyMiddleware } from 'redux';
            import logger from 'redux-logger';
            const store = createStore(reducer, applyMiddleware(logger));
            </code></pre>
            
            <br><strong>Benefits:</strong><br>
            <ul>
              <li>Helps track dispatched actions in real-time</li>
              <li>Shows state changes clearly for easier debugging</li>
              <li>Useful in development but should be disabled in production</li>
            </ul>
            </div></li>
            



            <li data-id="q_react_state"><span class="faq-question">
              State in React?
              </span><div class="answer">
              State in React is an object that holds dynamic data for a component. It determines how the component behaves and renders. When the state changes, React automatically re-renders the component to reflect the new data. State is managed within the component (using <code>useState</code> in functional components) and should be updated using the provided setter function to ensure proper reactivity.
              
              </div></li>
              
              <li data-id="q_react_vs_next"><span class="faq-question">
              Difference between React.js and Next.js?
              </span><div class="answer">
              <strong>React.js</strong> is a JavaScript library for building user interfaces, mainly focused on the frontend. It offers a component-based approach and handles client-side rendering but doesn‚Äôt include built-in routing or server-side rendering.
              
              <strong>Next.js</strong> is a React framework that extends React by adding powerful features like:
              <ul>
              <li>File-based routing</li>
              <li>Server-side rendering (SSR)</li>
              <li>Static site generation (SSG)</li>
              <li>API routes</li>
              <li>SEO optimization</li>
              </ul>
              While React provides the foundation for UI, Next.js offers a complete solution for building full-stack applications with better performance and scalability.
              </div></li>
              
              <li data-id="q_react_memory_virtualization"><span class="faq-question">
              memory cleanup and virtualization in React.js?
              </span><div class="answer">
              <strong>Memory Cleanup:</strong> In React, memory cleanup is often done using the <code>useEffect</code> hook‚Äôs cleanup function. It prevents memory leaks by cleaning up subscriptions, timers, or event listeners when a component unmounts or before re-running the effect.
              
              Example:
              <pre><code>
              useEffect(() => {
              const timer = setInterval(() => console.log('Tick'), 1000);
              return () => clearInterval(timer); // Cleanup
              }, []);
              </code></pre>
              
              <strong>Virtualization:</strong> Virtualization improves performance by rendering only the visible portion of large lists instead of the entire list. Libraries like <code>react-window</code> or <code>react-virtualized</code> help with this.
              
              Example with <code>react-window</code>:
              <pre><code>
              import { FixedSizeList as List } from 'react-window';
              
              &lt;List height={400} itemCount={1000} itemSize={35} width={300}&gt;
              {({ index, style }) =&gt; &lt;div style={style}&gt;Item {index}&lt;/div&gt;}
              &lt;/List&gt;
              </code></pre>
              
              This boosts performance and reduces memory usage in large UIs.
              </div></li>
              


              <li data-id="q_virtual_dom"><span class="faq-question green ">
                Virtual DOM in ReactJS?
                </span><div class="answer">
                The <strong>Virtual DOM</strong> is a lightweight, in-memory representation of the real DOM used by React.<br />
                
                When the state or props of a component change, React creates a new Virtual DOM tree and compares it with the previous one (called "diffing").
                <br />
                Only the differences (minimal changes) are then applied to the actual browser DOM, improving performance by reducing costly DOM manipulations.
                <br />
                This process allows React to update UI efficiently and smoothly without reloading the entire page.
                </div></li>
                
                
                <li data-id="q_useeffect"><span class="faq-question">
                useEffect in ReactJS?
                </span><div class="answer">
                <code>useEffect</code> is a React Hook that lets you perform side effects in functional components, such as data fetching, subscriptions, or manually changing the DOM.
                
                It runs after the component renders and can be configured to run:
                - After every render (no dependencies),
                - Only once on mount (empty dependency array),
                - Or when specific values change (dependencies array).
                
                Example:
                <pre>
                useEffect(() => {
                // side effect logic
                }, [dependency]);
                </pre>
                
                It replaces lifecycle methods like <code>componentDidMount</code>, <code>componentDidUpdate</code>, and <code>componentWillUnmount</code>.
                </div></li>
                
                <li data-id="q_context_api"><span class="faq-question">
                Context API in React?
                </span><div class="answer">
                The <strong>Context API</strong> in React provides a way to pass data through the component tree without prop drilling (passing props manually at every level).
                
                It allows sharing global data like themes, user info, or settings.
                
                Usage involves three parts:
                - <code>React.createContext()</code> to create context.
                - <code>Context.Provider</code> to provide data.
                - <code>Context.Consumer</code> or <code>useContext()</code> hook to consume data.
                
                Example:
                <pre><code>
                const ThemeContext = React.createContext('light');
                
                function App() {
                return (
                &lt;ThemeContext.Provider value="dark"&gt;
                &lt;Toolbar /&gt;
                &lt;/ThemeContext.Provider&gt;
                );
                }
                </code></pre>
                
                It simplifies state management for global data.
                </div></li>
                
                <li data-id="q_event_bubbling"><span class="faq-question">
                What is Event Bubbling in ReactJS?
                </span><div class="answer">
                  <strong>Event bubbling</strong> in ReactJS is a mechanism where an event triggered on a child element propagates (or "bubbles") up through its parent elements in the DOM tree.
                  
                  For example, clicking a button inside a <code>&lt;div&gt;</code> will first fire the button‚Äôs <code>onClick</code> handler, then the <code>&lt;div&gt;</code>'s if one is defined.
                  
                  Example:
                  <pre><code>
                  &lt;div onClick={() =&gt; console.log('Div clicked')}&gt;
                    &lt;button onClick={() =&gt; console.log('Button clicked')}&gt;Click Me&lt;/button&gt;
                  &lt;/div&gt;
                  </code></pre>
                  
                  Clicking the button will log:<br>
                  <code>Button clicked</code><br>
                  <code>Div clicked</code>
                  
                  You can stop bubbling with <code>event.stopPropagation()</code>.
                  </div></li>
                  
                
                
                





              <li data-id="q_mysql_acid"><span class="faq-question">
                ACID in MySQL?
                </span><div class="answer">
                ACID stands for Atomicity, Consistency, Isolation, and Durability ‚Äî key properties that ensure reliable database transactions.
                <br />
                - <strong>Atomicity:</strong> Transactions are all-or-nothing; either fully completed or fully rolled back.<br>
                - <strong>Consistency:</strong> Transactions bring the database from one valid state to another, maintaining data integrity.<br>
                - <strong>Isolation:</strong> Concurrent transactions don‚Äôt interfere; intermediate states are hidden.<br>
                - <strong>Durability:</strong> Once committed, changes persist even after crashes.
                
                MySQL‚Äôs InnoDB engine supports ACID to guarantee safe and reliable transactions.
                </div></li>      

            <li data-id="q_sql_normalization"><span class="faq-question">
              SQL Normalization?
              </span><div class="answer">
              SQL Normalization is a database design technique that organizes tables to reduce data redundancy and improve data integrity. It divides large tables into smaller, related tables and defines relationships between them.
              
              <br><br><strong>Normalization Forms:</strong><br>
              <ol class="subul">
                <li><strong>1NF (First Normal Form):</strong> Eliminate duplicate columns, ensure atomic values.</li>
                <li><strong>2NF (Second Normal Form):</strong> Remove partial dependencies on primary key.</li>
                <li><strong>3NF (Third Normal Form):</strong> Remove transitive dependencies.</li>
                <li><strong>BCNF (Boyce-Codd Normal Form):</strong> A stricter version of 3NF.</li>
              </ol>
              
              <br><strong>Benefits:</strong><br>
              - Avoids data duplication<br>
              - Maintains data consistency<br>
              - Simplifies data maintenance and updates<br>
              
              Normalization helps design efficient, reliable, and scalable relational databases.
              </div></li>
              
              <li data-id="q_redis"><span class="faq-question">
                Redis DB and What Are Its Uses?
                </span><div class="answer">
                <strong>Redis</strong> (Remote Dictionary Server) is an open-source, in-memory data store used as a database, cache, and message broker. It supports various data structures like strings, hashes, lists, sets, and sorted sets.
                
                <br><br><strong>Key Features:</strong><br>
                - Extremely fast (in-memory storage)<br>
                - Supports persistence (RDB, AOF)<br>
                - Pub/Sub messaging system<br>
                - Built-in replication and clustering<br>
                
                <br><strong>Common Uses:</strong><br>
                <ol class="subul">
                  <li><strong>Caching:</strong> Speeds up web apps by caching frequently accessed data.</li>
                  <li><strong>Session Store:</strong> Stores user sessions for fast access in scalable applications.</li>
                  <li><strong>Real-time Analytics:</strong> Useful for counters, leaderboard rankings, etc.</li>
                  <li><strong>Message Queues:</strong> Implements lightweight queues using lists or Pub/Sub.</li>
                  <li><strong>Rate Limiting:</strong> Controls API usage with time-based counters.</li>
                </ol>
                
                Redis is widely used for high-performance applications that require low-latency data access.
                </div></li>
                














              <li data-id="q3"><span class="faq-question">---------------------------------------</span><br /><span class="faq-question">---------------------------------------</span></li>    





<li data-id="q122obj"><span class="faq-question green ">
  Object, Rest, Rest Operator, Event
</span><div class="answer">
<pre>
  <b>Object</b>
  var obj = { a: 5, b: { c: 6, d: { e: 2 } } };
  const x = Object.keys(obj);
  const y = Object.values(obj);
  const z = Object.entries(obj);


  const x1 = { a: 1, b: 4, c: 8, d: 2, f: 3 };
  const v1 = Math.max(...Object.values(x1));
  const v2 = Math.max(...[[1,2],3,4].flat());
  const v3 = Math.max(1,2,3,4);
</pre>
<pre>
  <b>Rest Operator</b>
  const user = { id: 1, name: "Alice", age: 30 };
  const { name, ...rest } = user;
  console.log(name); // "Alice"
  console.log(rest); // { id: 1, age: 30 }


  <b>Spread Operator</b>
  const arr = [1, 2, 3];
  const newArr = [...arr, 4, 5];
  console.log(newArr); // [1, 2, 3, 4, 5]
</pre>

<pre>
  <b>Event</b>
  const users     = {};
  const app       = require('express')();
  const eventData = new (require('events'))();

  eventData.on('hello',(data)=>{
      const cnt   = Object.keys(users).length
      users[cnt]  = data;
      console.log('Event Hello Received : ', data);
  });

  app.get('/event/hello/:txt',(req, res)=>{
      console.log('Event Hello Emited');
      eventData.emit('hello', req.params.txt);
      res.json('Event Created Successfully!')
  });
</pre>
</div></li>
              
              
              
<li data-id="q122"><span class="faq-question">
Type vs Object
</span><div class="answer">
<pre>
  <b>üß™ Example: Using both</b>
  type Car is a type definition
  myCar is an object at runtime</b>
  
  type Car = {  brand: string;  year: number; };
  const myCar: Car = {  brand: "Toyota",  year: 2022  };
  console.log(myCar.brand); // Toyota
</pre>

<pre>
  <b>Type (TypeScript only)</b>
  Used to define custom types
  Exists only at <strong>compile time</strong>
  Helps with static type checking  
</pre>
<pre>
  <b>Object (JavaScript + TypeScript)</b>
  A runtime data structure
  Used to store key-value pairs
</pre>
              
                <h2>üîç Key Differences</h2>
              
                <table>
                  <thead>
                    <tr>
                      <th>Feature</th>
                      <th><b>type</b> (TypeScript)</th>
                      <th><b>object</b> (JS/TS)</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Exists at</td>
                      <td>Compile time only</td>
                      <td>Runtime</td>
                    </tr>
                    <tr>
                      <td>Purpose</td>
                      <td>Type safety</td>
                      <td>Data storage</td>
                    </tr>
                    <tr>
                      <td>Used for</td>
                      <td>Defining data shape</td>
                      <td>Storing key-value pairs</td>
                    </tr>
                    <tr>
                      <td>Can hold data?</td>
                      <td>No</td>
                      <td>Yes</td>
                    </tr>
                    <tr>
                      <td>Example syntax</td>
                      <td><code>type Car = { ... }</code></td>
                      <td><code>const car = { ... }</code></td>
                    </tr>
                  </tbody>
                </table>
              


</div></li>
              
              <li data-id="q122"><span class="faq-question">
                Monolithic vs Microservices
                </span><div class="answer">
              
                
                <p>Here‚Äôs a clear and practical comparison between <strong>Monolithic</strong> and <strong>Microservices</strong> architectures ‚Äî especially useful from a backend/full-stack perspective.</p>
              
                <h2>üß± MONOLITHIC ARCHITECTURE</h2>
              
                <h3>üîπ What Is It?</h3>
                <p>A single unified codebase that handles everything: frontend, backend, database logic, etc.</p>
              
                <h3>‚úÖ Example:</h3>
                <p>All modules like Auth, Product, Billing live in one Node.js/Express app or NestJS app.</p>
              
                <pre class="code-block">
              app/
              ‚îú‚îÄ‚îÄ controllers/
              ‚îú‚îÄ‚îÄ services/
              ‚îú‚îÄ‚îÄ models/
              ‚îî‚îÄ‚îÄ server.js
                </pre>
              
                <h3>‚úÖ Pros:</h3>
                <table>
                  <thead>
                    <tr>
                      <th>Advantage</th>
                      <th>Description</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>‚úÖ Simple</td>
                      <td>Easier to build, test, and deploy initially</td>
                    </tr>
                    <tr>
                      <td>‚úÖ Fast Dev Cycle</td>
                      <td>Local dev and debugging are straightforward</td>
                    </tr>
                    <tr>
                      <td>‚úÖ Performance</td>
                      <td>Function calls instead of inter-service HTTP</td>
                    </tr>
                    <tr>
                      <td>‚úÖ No DevOps Needed</td>
                      <td>Minimal infrastructure setup</td>
                    </tr>
                  </tbody>
                </table>
              
                <h3>‚ùå Cons:</h3>
                <table>
                  <thead>
                    <tr>
                      <th>Disadvantage</th>
                      <th>Description</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>‚ùå Scaling Pain</td>
                      <td>Hard to scale one feature independently</td>
                    </tr>
                    <tr>
                      <td>‚ùå Tight Coupling</td>
                      <td>Change in one module can break others</td>
                    </tr>
                    <tr>
                      <td>‚ùå Big Deployments</td>
                      <td>Any small change requires full redeployment</td>
                    </tr>
                    <tr>
                      <td>‚ùå Tech Lock-in</td>
                      <td>Difficult to mix languages/tools</td>
                    </tr>
                    <tr>
                      <td>‚ùå Harder to Onboard</td>
                      <td>Large codebase = steep learning curve</td>
                    </tr>
                  </tbody>
                </table>
              
                <hr />
              
                <h2>üß© MICROSERVICES ARCHITECTURE</h2>
              
                <h3>üîπ What Is It?</h3>
                <p>A collection of small, independently deployable services that each focus on a specific business domain.</p>
              
                <h3>‚úÖ Example:</h3>
                <ul>
                  <li><code>auth-service</code> (NestJS)</li>
                  <li><code>product-service</code> (Express)</li>
                  <li><code>order-service</code> (Go or Python)</li>
                  <li>Communicate via REST, gRPC, or Kafka</li>
                </ul>
              
                <pre class="code-block">
              services/
              ‚îú‚îÄ‚îÄ auth/
              ‚îú‚îÄ‚îÄ products/
              ‚îú‚îÄ‚îÄ orders/
              ‚îî‚îÄ‚îÄ gateway/  &lt;-- API Gateway (optional)
                </pre>
              
                <h3>‚úÖ Pros:</h3>
                <table>
                  <thead>
                    <tr>
                      <th>Advantage</th>
                      <th>Description</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>‚úÖ Independent Scaling</td>
                      <td>Scale each service based on need (e.g., product &gt; auth)</td>
                    </tr>
                    <tr>
                      <td>‚úÖ Tech Flexibility</td>
                      <td>Use best-fit language (Go for compute, Node.js for I/O)</td>
                    </tr>
                    <tr>
                      <td>‚úÖ Fault Isolation</td>
                      <td>One service crash ‚â† whole app crash</td>
                    </tr>
                    <tr>
                      <td>‚úÖ Faster Deployment</td>
                      <td>Deploy only the changed service</td>
                    </tr>
                    <tr>
                      <td>‚úÖ Easier CI/CD</td>
                      <td>Small, focused pipelines</td>
                    </tr>
                  </tbody>
                </table>
              
                <h3>‚ùå Cons:</h3>
                <table>
                  <thead>
                    <tr>
                      <th>Disadvantage</th>
                      <th>Description</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>‚ùå Complexity</td>
                      <td>Infrastructure, communication, observability</td>
                    </tr>
                    <tr>
                      <td>‚ùå DevOps Intensive</td>
                      <td>Needs Docker, Kubernetes, service discovery</td>
                    </tr>
                    <tr>
                      <td>‚ùå Data Consistency</td>
                      <td>Requires eventual consistency, transactions are tricky</td>
                    </tr>
                    <tr>
                      <td>‚ùå Latency</td>
                      <td>HTTP/gRPC calls between services = slower than in-memory calls</td>
                    </tr>
                    <tr>
                      <td>‚ùå Debugging Difficulties</td>
                      <td>Tracing across services needs observability tools</td>
                    </tr>
                  </tbody>
                </table>
              
                <hr />
              
                <h2>‚öñÔ∏è Comparison Table</h2>
              
                <table>
                  <thead>
                    <tr>
                      <th>Feature</th>
                      <th>Monolithic</th>
                      <th>Microservices</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Codebase</td>
                      <td>Single repo</td>
                      <td>Multiple repos/modules</td>
                    </tr>
                    <tr>
                      <td>Deployment</td>
                      <td>One artifact</td>
                      <td>Many deployable services</td>
                    </tr>
                    <tr>
                      <td>Scaling</td>
                      <td>Entire app</td>
                      <td>Per service</td>
                    </tr>
                    <tr>
                      <td>Fault Isolation</td>
                      <td>Poor</td>
                      <td>Strong</td>
                    </tr>
                    <tr>
                      <td>Tech Stack Flexibility</td>
                      <td>Limited</td>
                      <td>Flexible per service</td>
                    </tr>
                    <tr>
                      <td>Team Structure</td>
                      <td>Centralized</td>
                      <td>Decentralized, cross-functional</td>
                    </tr>
                    <tr>
                      <td>Best for</td>
                      <td>Small/medium projects</td>
                      <td>Large, scalable systems</td>
                    </tr>
                  </tbody>
                </table>
              
                <hr />
              
                <h2>üõ†Ô∏è When to Use What?</h2>
              
                <table>
                  <thead>
                    <tr>
                      <th>Situation</th>
                      <th>Recommendation</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>MVP, startup project</td>
                      <td>‚úÖ <strong>Monolithic</strong></td>
                    </tr>
                    <tr>
                      <td>Small team, tight deadlines</td>
                      <td>‚úÖ <strong>Monolithic</strong></td>
                    </tr>
                    <tr>
                      <td>Large team, distributed ownership</td>
                      <td>‚úÖ <strong>Microservices</strong></td>
                    </tr>
                    <tr>
                      <td>Independent scaling of services</td>
                      <td>‚úÖ <strong>Microservices</strong></td>
                    </tr>
                    <tr>
                      <td>Need high availability and fault isolation</td>
                      <td>‚úÖ <strong>Microservices</strong></td>
                    </tr>
                  </tbody>
                </table>
              
                <p>Let me know if you'd like a <strong>NestJS-based microservices demo</strong>, or how to <strong>break a monolith into microservices</strong>.</p>
              
              </div></li>
              
              
<li data-id="q53337">
  <span class="faq-question green">Security Practices in Node.js?***</span>
  <div class="answer">
    <ol class="subul">
      <li><strong>Validate input:</strong> Always validate and sanitize user input to prevent injection attacks (e.g., SQL injection, XSS).</li>
      <li><strong>Use HTTPS:</strong> Serve your app over HTTPS to encrypt data in transit.</li>
      <li><strong>Manage dependencies:</strong> Regularly update and audit npm packages to avoid known vulnerabilities.</li>
      <li><strong>Environment variables:</strong> Store secrets and credentials securely using environment variables or secrets managers.</li>
      <li><strong>Limit privileges:</strong> Run Node.js processes with the least privileges needed.</li>
      <li><strong>Prevent DOS attacks:</strong> Use rate limiting and request throttling.</li>
      <li><strong>Use security headers:</strong> Implement headers like Content Security Policy (CSP), X-Content-Type-Options, and others.</li>
      <li><strong>Handle errors securely:</strong> Don‚Äôt expose stack traces or sensitive info in error responses.</li>
      <li><strong>Authentication & Authorization:</strong> Use proven libraries (e.g., Passport.js, JWT) and implement proper access controls.</li>
      <li><strong>Secure cookies:</strong> Use HttpOnly, Secure, and SameSite flags on cookies.</li>
      <li><strong>Keep Node.js updated:</strong> Use the latest stable Node.js version with security patches.</li>
    </ol>
<pre>
  app.use(rateLimit({
    windowMs: 1 * 60 * 1000, // 1 minute
    max: 5, // limit each IP to 5 requests per windowMs
    message: "Too many requests, try again later.",
  }));
</pre>
  </div>
</li>
              
<li data-id="q58">
  <span class="faq-question">What is Helmet in Node.js and how does it improve security?</span>
  <div class="answer">
    Helmet is a middleware for Express.js that helps secure your app by setting various HTTP headers. It protects against common vulnerabilities like:
    <code>
      <ol class="subul">
        <li><strong>Clickjacking</strong> with the <b>X-Frame-Options</b> header</li>
        <li><strong>XSS attacks</strong> with <b>X-XSS-Protection</b></li>
        <li><strong>MIME sniffing</strong> with <b>X-Content-Type-Options</b></li>
        <li><strong>Enforces HTTPS</strong> with <b>Strict-Transport-Security</b></li>
        <li><strong>Content Security Policy</strong> to control allowed resources</li>
        <li><strong>app.use(require('helmet')())</strong></li>
      </ol>
    </code>
    
  </div>
</li>
              
              
              
              
<ul class="faq">
<li data-id="q124">
<span class="faq-question">Shallow copy vs Deep copy?</span>
<div class="answer">
<pre>  
In Node.js (and JavaScript), copying an object or array can be done in two ways: <strong>shallow copy</strong> and <strong>deep copy</strong>.

<strong>Shallow Copy:</strong>
1. Copies only the top-level properties of an object.
2. Nested objects are still referenced, not copied.
3. Changes to nested objects in the copy affect the original.


<strong>Example:</strong>
const original = { name: 'Dev', address: { city: 'Kolkata' } };
const shallow = { ...original };

shallow.address.city = 'Delhi';
console.log(original.address.city); // Output: 'Delhi' (original is affected)
</pre>


<pre>
<strong>Deep Copy:</strong>
1. Creates a full, independent copy of the object and all nested objects.
2. Changes to the copy do not affect the original.


<strong>Example (using JSON):</strong>
const original = { name: 'Dev', address: { city: 'Kolkata' } };
const deep = JSON.parse(JSON.stringify(original));

deep.address.city = 'Delhi';
console.log(original.address.city); // Output: 'Kolkata' (original not affected)


<strong>Note:</strong> JSON method doesn‚Äôt handle functions, Dates, undefined, RegExp, etc.

<strong>Advanced Deep Copy (using lodash):</strong>
const _ = require('lodash');
const deep = _.cloneDeep(original);

</pre>

<strong>Summary:</strong>
<table border="1" cellpadding="5">
<tr><th>Type</th><th>Nested Objects</th><th>Use Case</th></tr>
<tr><td>Shallow Copy</td><td>Referenced</td><td>Simple or flat objects</td></tr>
<tr><td>Deep Copy</td><td>Copied recursively</td><td>Complex or nested objects</td></tr>
</table>
</div>
</li>
</ul>
              
              
  <ul class="faq">
    <li data-id="q127">
      <span class="faq-question">Buffer?</span>
      <div class="answer">
        
  
  <code>
    A <strong>Buffer</strong> in Node.js is a built-in class that allows you to work with raw binary data directly in memory, especially useful when dealing with streams, file systems, TCP sockets, etc. It represents a fixed-size chunk of memory allocated outside the V8 heap.
    <br />
    <br />
  <b>Buffers are not resizable. </b><br />If you need a resizable array of binary data, consider using <b>Uint8Array or Streams with chunks.</b>
    
  <br><br><strong>Why Buffers?</strong>
  <ol>
    <li>JavaScript strings are Unicode and not ideal for binary data.</li>
    <li>Buffers allow handling binary data (e.g., images, files, sockets) directly.</li>
  </ol>
  <br />
    
  <strong>Use Cases:</strong>
  <ol>
  <li>Reading and writing files</li>
  <li>Handling stream data (e.g. TCP, HTTP)</li>
  <li>Binary data manipulation (e.g. image processing, encryption)</li>
  </ol>
  
  </code>
              
              
              
              
                    
<pre>
<strong>Create a Buffer:</strong>
  const buf = Buffer.from('hello');
  console.log(buf);           // &lt;Buffer 68 65 6c 6c 6f&gt;
  console.log(buf.toString()); // hello
</pre>
                    
<code>
  <strong>Buffer Methods:</strong>
  <ol>
  <li>Buffer.from() ‚Äì creates buffer from string/array/arrayBuffer</li>
  <li>Buffer.alloc(size) ‚Äì creates a zero-filled buffer of given size</li>
  <li>Buffer.concat([buf1, buf2]) ‚Äì joins multiple buffers</li>
  <li>buf.toString() ‚Äì converts buffer to human-readable string</li>
  <li>buf.length ‚Äì gets size of buffer in bytes</li>
  </ol>
</code>
              
<pre>
  <strong>Example ‚Äì Buffer concatenation:</strong>
  const a = Buffer.from('Node');
  const b = Buffer.from('JS');
  const combined = Buffer.concat([a, b]);
  console.log(combined.toString()); // NodeJS
</pre>
              
                    
    </div>
  </li>
</ul>
              
              
<ul class="faq">
<li data-id="q125">
<span class="faq-question">Stream?</span>
<div class="answer">
  A <strong>Stream</strong> in Node.js is an abstract interface for working with streaming data. Streams are used to handle large data efficiently by processing it in chunks instead of loading it all into memory at once.
  <br />



  
    Streams are objects for reading or writing data continuously. They include readable, writable, duplex, and transform streams. Streams are memory-efficient and used for processing large data like files.
    



  <br />
  <strong>Why use Streams?</strong>
<code>
  <ul>
    <li>Efficient memory usage for large files or data.</li>
    <li>Non-blocking, event-driven architecture.</li>
    <li>Used internally in many Node.js APIs (e.g., HTTP, file system, process).</li>
  </ul>
</code>
  <br /><br>
  <strong>Types of Streams:</strong>
  <code>
  <ul>
    <li><strong>Readable:</strong> For reading data (e.g., fs.createReadStream()).</li>
    <li><strong>Writable:</strong> For writing data (e.g., fs.createWriteStream()).</li>
    <li><strong>Duplex:</strong> Can read and write (e.g., TCP sockets).</li>
    <li><strong>Transform:</strong> Duplex stream that can modify or transform data (e.g., zlib.createGzip()).</li>
  </ul>
  </code>

  <br />

  <strong>Common stream events:</strong>
  <code>
  <ul>
    <li>data ‚Äì emitted when data is available to read.</li>
    <li>end ‚Äì no more data</li>
    <li>error ‚Äì error occurred</li>
    <li>finish ‚Äì finished writing</li>
  </ul>
  </code>
  <br />
              
<strong>Basic Example (File Stream):</strong>
<pre>
    const fs = require('fs');
    const readable = fs.createReadStream('input.txt');
    const writable = fs.createWriteStream('output.txt');
    readable.pipe(writable);
    -------------------------------------
    
    readable.on('data', chunk => {
      console.log('Chunk:', chunk.toString());
    });
    
    readable.on('end', () => {
      console.log('Finished reading.');
    });
    </pre>
  </div>
</li>
</ul>
              
<ul class="faq">
  <li data-id="q126">
    <span class="faq-question">Pipe?</span>
    <div class="answer">
      <code>In Node.js, .pipe() is a method used to connect the output of a <strong>readable stream</strong> to the input of a <strong>writable stream</strong>. It allows data to flow automatically from source to destination, handling backpressure internally.</code>
      <br />
<pre>
Syntax: readableStream.pipe(writableStream);
Why use pipe()?
  1. Simplifies stream handling.
  2. Automatically manages flow control (backpressure).
  3. Used for reading/writing large files, zipping, HTTP responses, etc.
</pre>
              

<pre>
  <strong>Basic Example:</strong>
  const fs = require('fs');
  const readable = fs.createReadStream('input.txt');
  const writable = fs.createWriteStream('output.txt');
  readable.pipe(writable);

  Behind the Scenes: 
  pipe() listens for data, end, error events, and handles flow control ‚Äî pausing the readable stream when the writable stream can't keep up.
</pre>
              

<pre>
<strong>Chaining Pipes (with transform stream):</strong>
  const zlib = require('zlib');
  const fs = require('fs');
  
  fs.createReadStream('file.txt')
    .pipe(zlib.createGzip())              // compress the stream
    .pipe(fs.createWriteStream('file.txt.gz')); // write compressed file
</pre>
              
                    <strong>Real-World Use Cases:</strong>
                    <ul>
                      <li>File copy or backup utilities.</li>
                      <li>Compression/decompression (Gzip, Brotli).</li>
                      <li>Video/audio streaming servers.</li>
                      <li>Streaming data from a file to an HTTP response.</li>
                    </ul>
              
                    <strong>Note:</strong> Use <code>pipeline()</code> from <code>stream</code> module for better error handling in complex piping:
                    <pre><code>
              const { pipeline } = require('stream');
              pipeline(
                fs.createReadStream('a.txt'),
                fs.createWriteStream('b.txt'),
                (err) => { if (err) console.error('Pipeline failed:', err); }
              );
                    </code></pre>
                  </div>
                </li>
              </ul>
              
              
              <ul class="faq">
                <li data-id="q128">
                  <span class="faq-question green">Buffer vs Stream vs Pipe?</span>
                  <div class="answer">
                    These three concepts are commonly used in Node.js for handling data ‚Äî especially large or binary data ‚Äî but they serve different purposes.
              
                    <br><code><strong>üîπ Buffer:</strong>
                    <ol>
                      <li>A <strong>Buffer</strong> holds binary data in memory as a fixed-size chunk.</li>
                      <li>Best for small/medium-sized data you want to work with all at once.</li>
                      <li>Can become memory-intensive for large files.</li>
                      <li>Example: const buf = Buffer.from('hello');</li>
                    </ol>
                    </code>
              <br />
                    <code>
                    <strong>üîπ Stream:</strong>
                    <ol>
                      <li>A <strong>Stream</strong> is an event-based abstraction for continuous data flow.</li>
                      <li>Processes data in <strong>chunks</strong>, without loading the entire content in memory.</li>
                      <li>Efficient for large files, real-time data (e.g., file I/O, HTTP requests).</li>
                      <li>Types: Readable, Writable, Duplex, Transform</li>
                      <li>Example:
                        <pre>
              const fs = require('fs');
              const stream = fs.createReadStream('file.txt');
              stream.on('data', chunk => console.log(chunk.toString()));
                        </pre>
                      </li>
                    </ol>
                  </code>
              <br />
                    <code>
                    <strong>üîπ Pipe:</strong>
                    <ol>
                      <li><strong>pipe()</strong> is a helper method used to connect two streams: readable ‚Üí writable.</li>
                      <li>Transfers data automatically while managing flow control (backpressure).</li>
                      <li>Common for file copy, compression, HTTP response streaming, etc.</li>
                      <li>Example:
                        <pre><code>
              fs.createReadStream('input.txt')
                .pipe(fs.createWriteStream('output.txt'));
                        </code></pre>
                      </li>
                    </ol>
                  </code>
                  <br />
              
                    <strong>üü© Summary Table:</strong>
                    <table border="1" cellpadding="5">
                      <tr>
                        <th>Feature</th><th>Buffer</th><th>Stream</th><th>Pipe</th>
                      </tr>
                      <tr>
                        <td>Purpose</td>
                        <td>Store binary data in memory</td>
                        <td>Read/write data in chunks</td>
                        <td>Connect readable to writable stream</td>
                      </tr>
                      <tr>
                        <td>Memory Usage</td>
                        <td>High for large files</td>
                        <td>Low (chunked)</td>
                        <td>Depends on stream</td>
                      </tr>
                      <tr>
                        <td>Speed</td>
                        <td>Fast for small data</td>
                        <td>Efficient for large data</td>
                        <td>Efficient & automated</td>
                      </tr>
                      <tr>
                        <td>Use Case</td>
                        <td>Binary operations</td>
                        <td>Large file/network I/O</td>
                        <td>Chaining streams</td>
                      </tr>
                    </table>
              <pre>
              <br><strong>Conclusion:</strong>
              <b>Buffer</b> for small chunks of binary data, 
              <b>Stream</b> when dealing with large or continuous data, and 
              <b>pipe()</b> to connect and automate stream workflows.
              </pre>
                  </div>
                </li>
              </ul>
              
              <ul class="faq">
                <li data-id="q129">
                  <span class="faq-question green">Sharding in Databases?</span>
                  <div class="answer">
                    <strong>Sharding</strong> is a database architecture pattern used to horizontally partition large datasets across multiple databases (shards). Each shard holds a subset of the data, and all shards together form a complete dataset. <br />
              
                    <strong>Conclusion:</strong>
                    Sharding enables horizontal scalability for databases by breaking big data into smaller, manageable parts. It‚Äôs powerful but requires careful planning and design.
              
                    <br><br>
                  <code>
                    <strong>Why use Sharding?</strong>
                    <ol>
                      <li>Improves performance and scalability by distributing load.</li>
                      <li>Reduces contention and I/O bottlenecks on a single server.</li>
                      <li>Enables handling of large datasets that exceed a single machine's capacity.</li>
                    </ol>
                    <br />
                    <strong>How it works:</strong>
                    <ol>
                      <li>Data is split based on a <strong>shard key</strong> (e.g., user ID, region).</li>
                      <li>Each shard can be hosted on a different physical or logical server.</li>
                      <li>The application or a routing layer determines where to read/write data.</li>
                    </ol>
                  <br />
              
                    <strong>Example:</strong>
                    <ol>
                      <li>Instead of storing 100 million user records in one DB, you shard them across 10 databases, each storing 10 million.</li>
                      <li>User IDs 1-10M ‚Üí Shard 1, 10M-20M ‚Üí Shard 2, etc.</li>
                    </ol>
              
                  </code>
              
                  <code>
                    <strong>Sharding Strategies:</strong>
                    <ol>
                      <li><strong>Range-based:</strong> Divide data based on value ranges (e.g., date, ID).</li>
                      <li><strong>Hash-based:</strong> Apply a hash function on the shard key.</li>
                      <li><strong>Geo-based:</strong> Partition by location (e.g., country, region).</li>
                    </ol>
                  </code>
                  <br />
                    <code>
                    <strong>Challenges:</strong>
                    <ol>
                      <li>Cross-shard joins and transactions are complex or inefficient.</li>
                      <li>Resharding (changing shard strategy) can be hard.</li>
                      <li>Requires good shard key design to avoid hotspots.</li>
                    </ol>
                  </code>
                    <br />
                    <code>
                    <strong>Databases that support sharding:</strong>
                    <ol>
                      <li>MongoDB ‚Äì Native sharding support</li>
                      <li>Cassandra ‚Äì Automatically partitions data</li>
                      <li>PostgreSQL/MySQL ‚Äì Via manual partitioning or middleware (e.g., Citus, Vitess)</li>
                    </ol>
                    </code>
              
              <pre>
              
                // NestJS Sharding Example with MySQL (manual routing by user ID)
              
                // 1. DatabaseConfigService - handles connections to multiple shards
                @Injectable()
                export class DatabaseConfigService {
                  private shardConnections: Record<string, DataSource> = {};
                
                  constructor() {
                    // Simulate 2 shards for example
                    this.shardConnections["shard1"] = new DataSource({
                      type: "mysql",
                      host: "localhost",
                      port: 3306,
                      username: "root",
                      password: "password",
                      database: "user_shard_1",
                      entities: [User],
                      synchronize: true,
                    });
                
                    this.shardConnections["shard2"] = new DataSource({
                      type: "mysql",
                      host: "localhost",
                      port: 3306,
                      username: "root",
                      password: "password",
                      database: "user_shard_2",
                      entities: [User],
                      synchronize: true,
                    });
                  }
                
                  async initConnections() {
                    for (const shard of Object.values(this.shardConnections)) {
                      if (!shard.isInitialized) await shard.initialize();
                    }
                  }
                
                  getShard(userId: number): DataSource {
                    return userId % 2 === 0 ? this.shardConnections["shard1"] : this.shardConnections["shard2"];
                  }
                
                  getAllShards(): DataSource[] {
                    return Object.values(this.shardConnections);
                  }
                }
                
                // 2. User Entity
                @Entity()
                export class User {
                  @PrimaryGeneratedColumn()
                  id: number;
                
                  @Column()
                  name: string;
                
                  @Column()
                  email: string;
                }
                
                // 3. UserService - routes DB calls to the correct shard
                @Injectable()
                export class UserService {
                  constructor(private dbService: DatabaseConfigService) {}
                
                  async findAll(userId: number): Promise<User[]> {
                    const shard = this.dbService.getShard(userId);
                    const userRepo = shard.getRepository(User);
                    return userRepo.find();
                  }
                
                  async create(userId: number, dto: { name: string; email: string }): Promise<User> {
                    const shard = this.dbService.getShard(userId);
                    const userRepo = shard.getRepository(User);
                    const user = userRepo.create(dto);
                    return userRepo.save(user);
                  }
                
                  async findByEmail(email: string): Promise<User | null> {
                    for (const shard of this.dbService.getAllShards()) {
                      const userRepo = shard.getRepository(User);
                      const user = await userRepo.findOne({ where: { email } });
                      if (user) return user;
                    }
                    return null;
                  }
                
                  async findById(id: number): Promise<User | null> {
                    for (const shard of this.dbService.getAllShards()) {
                      const userRepo = shard.getRepository(User);
                      const user = await userRepo.findOne({ where: { id } });
                      if (user) return user;
                    }
                    return null;
                  }
                
                  async findByName(name: string): Promise<User[]> {
                    const results: User[] = [];
                    for (const shard of this.dbService.getAllShards()) {
                      const userRepo = shard.getRepository(User);
                      const users = await userRepo.find({ where: { name } });
                      results.push(...users);
                    }
                    return results;
                  }
                }
                
                // 4. UserController
                @Controller('users')
                export class UserController {
                  constructor(private userService: UserService) {}
                
                  @Get(':userId')
                  async getUsers(@Param('userId', ParseIntPipe) userId: number) {
                    return this.userService.findAll(userId);
                  }
                
                  @Post(':userId')
                  async createUser(@Param('userId', ParseIntPipe) userId: number, @Body() body) {
                    return this.userService.create(userId, body);
                  }
                
                  @Get('email/:email')
                  async getUserByEmail(@Param('email') email: string) {
                    return this.userService.findByEmail(email);
                  }
                
                  @Get('id/:id')
                  async getUserById(@Param('id', ParseIntPipe) id: number) {
                    return this.userService.findById(id);
                  }
                
                  @Get('name/:name')
                  async getUserByName(@Param('name') name: string) {
                    return this.userService.findByName(name);
                  }
                }
                
                // 5. AppModule
                @Module({
                  imports: [],
                  controllers: [UserController],
                  providers: [UserService, DatabaseConfigService],
                })
                export class AppModule {
                  constructor(private dbService: DatabaseConfigService) {}
                
                  async onModuleInit() {
                    await this.dbService.initConnections();
                  }
                }
                
                
              </pre>
              
              
              
                  </div>
                </li>
              </ul>
              
              
              
              


<li data-id="q_promise"><span class="faq-question">
Promise?
</span><div class="answer">

<code>
A <strong>Promise</strong> is an object representing the eventual completion or failure of an asynchronous operation. <br />
It's has 3 states: 
<b>
  Pending, Fulfilled, Rejected
</b>
</code>


<code>

<br />
<strong>Advanced Promise Topics:</strong><br>
‚Ä¢ <b>Promise.all()</b>: Waits for all promises to resolve or any to reject.<br>
‚Ä¢ <b>Promise.race()</b>: Resolves/rejects as soon as one of the promises does.<br>
‚Ä¢ <b>Promise.allSettled()</b>: Waits for all promises to settle (resolve or reject).<br>
‚Ä¢ <b>Promise.any()</b>: Resolves as soon as one promise fulfills (ignores rejections).<br>
‚Ä¢ <b>Chaining</b>: Linking multiple <b>.then()</b> calls for sequential execution.<br>
‚Ä¢ <b>Error handling</b>: Using <b>.catch()</b> and <b>finally()</b> for robust flows.<br>
‚Ä¢ <b>Async/Await</b>: Syntactic sugar over promises for cleaner asynchronous code.<br><br>

Mastering Promises is essential for handling async operations in modern JavaScript.

</code>
<pre>
  Basic usage:
  const promise = new Promise((resolve, reject) => {
    setTimeout(() => resolve("Done!"), 1000);
  });

  promise.then(result => console.log(result)).catch(err => console.error(err));
</pre>
<pre>
  <b> 1. Promise.all</b>
  Promise.all([delay(1000, 'A'), delay(1500, 'B'), delay(500, 'C')])
          .then(results => { 
            console.log('Promise.all:', results); // ['A', 'B', 'C']
          })
          .catch(err => {
            console.error('Promise.all error:', err);
          });
  
</pre>
<pre>
  <b> 1. Promise.all</b>
  const p1 = Promise.resolve(1);
  const p2 = Promise.reject(2);
  const p3 = Promise.resolve(3);
  
  Promise.all([p1, p2, p3])
    .then(results => {
      console.log("All success: " + results);
    })
    .catch(err => {
      console.log("One failed: " + err);
    });
</pre>

<pre>
  <b> 1. Promise.all</b>
  async function fetchData() {
    try {
      const results = await Promise.all([p1, p2, p3]);
      console.log("All success1: " + results);
    } catch (err) {
      console.log("One failed1: " + err);
    }
  }
  
  fetchData();
</pre>


<hr />
<pre><code>
    // Sample async function returning a promise
    const delay = (time, value, shouldReject = false) => {
      return new Promise((resolve, reject) => {
        setTimeout(() => {
          shouldReject ? reject(`Error: ${value}`) : resolve(value);
        }, time);
      });
    };



    // 2. Promise.race
    Promise.race([
      delay(1000, 'X'),
      delay(500, 'Y'),
      delay(2000, 'Z')
    ]).then(result => {
      console.log('Promise.race:', result); // 'Y'
    }).catch(err => {
      console.error('Promise.race error:', err);
    });

    // 3. Promise.allSettled
    Promise.allSettled([
      delay(1000, 'Success1'),
      delay(800, 'Fail1', true),
      delay(1200, 'Success2')
    ]).then(results => {
      console.log('Promise.allSettled:', results);
    });

    // 4. Promise.any
    Promise.any([
      delay(1000, 'Pass1', true),
      delay(800, 'Pass2', true),
      delay(1200, 'Winner')
    ]).then(result => {
      console.log('Promise.any:', result); // 'Winner'
    }).catch(err => {
      console.error('Promise.any error:', err); // Only if all fail
    });

    // 5. Chaining with .then()
    delay(1000, 'Start')
      .then(result => {
        console.log('Chaining 1:', result);
        return delay(1000, 'Step 2');
      })
      .then(result => {
        console.log('Chaining 2:', result);
        return delay(1000, 'Step 3');
      })
      .then(result => {
        console.log('Chaining 3:', result);
      });

    // 6. Error handling
    delay(1000, 'Oops', true)
      .then(result => {
        console.log('Will not run:', result);
      })
      .catch(error => {
        console.error('Caught error:', error); // 'Error: Oops'
      });

    </code></pre>



</div></li>

<li data-id="q_hoisting"><span class="faq-question">
Hoisting?
</span><div class="answer">
Hoisting is JavaScript's default behavior of moving declarations to the top of their scope before code execution. <br />
It applies to <b>var</b> declarations and function declarations.<br /><br />

Variables declared with <b>var</b> are hoisted and initialized with <b>undefined</b>, <br />
whereas <b>let</b> and <b>const</b> are hoisted but <b>not initialized</b> 
They are in a <b>"temporal dead zone"</b> until declaration.

Example:
<pre>
console.log(x); // undefined
var x = 5;

foo(); // Works
function foo() {
  console.log("Hello");
}
</pre>
Hoisting can lead to unexpected results if not understood properly.
</div></li>



<li data-id="q_closure"><span class="faq-question">
Closure?
</span><div class="answer">
A closure in Node.js (and JavaScript) is a function that "remembers" its lexical scope even when executed outside of that scope. It allows inner functions to access variables from their outer function even after the outer function has returned.

Closures are useful for data encapsulation, private variables, and maintaining state between function calls.

Example:
<pre>
function outer() {
  let count = 0;
  return function inner() {
    count++;
    return count;
  };
}
const counter = outer();
console.log(counter()); // 1
console.log(counter()); // 2


Here, <b>count</b> persists because of closure.
</pre>
</div></li>




<li data-id="q_middleware_interceptor_filter"><span class="faq-question">
Middleware Vs Interceptor Vs Filter?
</span><div class="answer">
<strong>Middleware</strong>, <strong>Interceptor</strong>, and <strong>Filter</strong> are all mechanisms for handling requests/responses, but they differ by context and use-case:
<br />
<strong>Middleware (Express.js/Node.js):</strong><br>
- Functions executed before reaching route handlers.<br>
- Used for logging, authentication, parsing, etc.<br>
- Can modify request/response objects.<br>
- Example:
<pre>
app.use((req, res, next) => {
  console.log('Middleware');
  next();
});
</pre>

<strong>Interceptor (NestJS, Angular, etc.):</strong><br>
- Wraps around method execution (before & after).<br>
- Often used to modify input/output, add headers, transform responses.<br>
- Ideal for logging, caching, error handling.<br>

<strong>Filter (NestJS, Java, etc.):</strong><br>
- Specifically handles exceptions/errors.<br>
- Catches thrown errors and returns formatted responses.<br>
- Ideal for global error responses, logging exceptions.
<br /><br />
<strong>Summary:</strong><br>
- <strong>Middleware</strong>: Handles requests early (e.g., auth, body parsing).<br>
- <strong>Interceptor</strong>: Wraps execution, ideal for transforming results or adding behaviors.<br>
- <strong>Filter</strong>: Catches and handles exceptions.
</div></li>

<li data-id="q_guards_vs_auth"><span class="faq-question">
Guards Vs Authentication? JWT
</span><div class="answer">
<strong>Authentication</strong> and <strong>Guards</strong> are both related to security but serve different purposes:
<Br />
<strong>Authentication:</strong><br>
- The process of verifying a user's identity (e.g., via username/password, token).<br>
- Determines ‚ÄúWho are you?‚Äù<br>
- Implemented using strategies like JWT, OAuth, sessions, etc.<br>
- Example: Decoding a JWT token to validate a user.
<Br />
<strong>Guards (e.g., in NestJS):</strong><br>
- A mechanism to protect routes based on authentication or authorization logic.<br>
- Executes before a route is handled.<br>
- Determines ‚ÄúAre you allowed to access this?‚Äù<br>
- Used to allow/deny access to certain endpoints based on roles, permissions, or login status.
<Br />
<strong>Summary:</strong><br>
- <strong>Authentication</strong> confirms user identity.<br>
- <strong>Guards</strong> control access after authentication.

<hr />

  <h4>Common JWT Security Mistakes :<br /> jwt.sign(payload, secret, { algorithm: 'HS256' });</h4>

  <div class="mistake">
    <strong>1. Use <b>none</b> as the algorithm (Never do this!)</strong><br>
    Attackers can forge tokens if verification is bypassed.
    <div class="tip">‚úÖ Always validate the algorithm and enforce a known one like <b>HS256</b> or <b>RS256</b>.</div>
  </div>

  <div class="mistake">
    <strong>2. Store JWTs in <b>localStorage</b></strong><br>
    Vulnerable to XSS attacks.
    <div class="tip">‚úÖ Prefer <b>HttpOnly</b> cookies when possible.</div>
  </div>

  <div class="mistake">
    <strong>3. Don‚Äôt Set Expiration (<b>exp</b>)</strong><br>
    Tokens without expiry can be used indefinitely.
    <div class="tip">‚úÖ Always set an expiry like <b>1h</b>, <b>15m</b>, etc.</div>
  </div>

  <div class="mistake">
    <strong>4. Exposing the secret key</strong><br>
    If your secret key leaks, all tokens are compromised.
    <div class="tip">‚úÖ Keep secrets safe using environment variables or secure secret managers.</div>
  </div>

  <div class="mistake">
    <strong>5. Not using HTTPS</strong><br>
    JWTs sent over HTTP can be intercepted.
    <div class="tip">‚úÖ Always use <b>HTTPS</b> to prevent MITM (Man-In-The-Middle) attacks.</div>
  </div>






</div></li>

<li data-id="q_dependency_injection"><span class="faq-question">
Dependency Injection (DI)?
</span><div class="answer">
<strong>Dependency Injection (DI)</strong> is a design pattern where an object or function receives its dependencies from an external source rather than creating them internally.

It promotes loose coupling, testability, and better code structure.
<br /><br />
In frameworks like <strong>NestJS</strong>, DI is a core feature. Services, repositories, or other providers are injected into classes (like controllers) through constructors.

Example (NestJS):
<pre><code>
@Injectable()
export class UserService {
constructor(private readonly userRepo: UserRepository) {}
}
</code></pre>

Here, <code>UserRepository</code> is automatically injected by NestJS‚Äôs DI container.

DI improves modularity, makes mocking easy for testing, and encourages best practices.
</div></li>


<li data-id="q_decorator"><span class="faq-question">
a Decorator in TypeScript?
</span><div class="answer">
A <strong>decorator</strong> is a special kind of declaration in TypeScript that can be attached to classes, methods, properties, or parameters to modify their behavior at runtime.

Decorators are functions prefixed with <code>@</code> and are widely used in frameworks like <strong>NestJS</strong> and <strong>Angular</strong>.

Types of decorators:
- <strong>Class Decorators</strong>
- <strong>Method Decorators</strong>
- <strong>Property Decorators</strong>
- <strong>Parameter Decorators</strong>

Example:
<pre><code>
function Logger(constructor: Function) {
console.log("Class created:", constructor.name);
}

@Logger
class MyClass {}
</code></pre>

In NestJS:
<pre><code>
@Controller('users')
export class UserController {}
</code></pre>

Decorators add metadata or change behavior, helping with clean and declarative code.
</div></li>
<li data-id="q_get_decorator"><span class="faq-question">
Is @Get() a decorator in NestJS?
</span><div class="answer">
Yes, <code>@Get()</code> is a method decorator in <strong>NestJS</strong> used to define a route handler for HTTP GET requests. It is part of the <code>@nestjs/common</code> package and maps the decorated method to a specific endpoint.

Example:
<pre><code>
@Controller('users')
export class UserController {
@Get()
findAll() {
return ['user1', 'user2'];
}

@Get(':id')
findOne(@Param('id') id: string) {
return `User ${id}`;
}
}
</code></pre>

Here:
- <code>@Get()</code> maps to <code>/users</code>
- <code>@Get(':id')</code> maps to <code>/users/:id</code>

These decorators help build clean, declarative REST APIs.
</div></li>

<li data-id="q_module_decorator"><span class="faq-question">
Is @Module() a decorator in NestJS?
</span><div class="answer">
Yes, <code>@Module()</code> is a class decorator in NestJS. It defines a module, which is a fundamental building block organizing related components like controllers, providers, and imports.

Example:
<pre><code>
import { Module } from '@nestjs/common';
import { UsersController } from './users.controller';
import { UsersService } from './users.service';

@Module({
controllers: [UsersController],
providers: [UsersService],
imports: [],
})
export class UsersModule {}
</code></pre>

The <code>@Module()</code> decorator accepts metadata that tells NestJS how to assemble the module, enabling dependency injection and modular architecture.
</div></li>



<li data-id="q_node_event"><span class="faq-question green">
Event? Event-Driven Programming? EventEmitter
</span>
<div class="answer">
  Event-driven programming is a design paradigm where the flow of the program is determined by events like user actions, messages, or I/O operations. In Node.js, this model allows the application to respond asynchronously to events using the <b>EventEmitter</b> class. It enables non-blocking I/O by listening for events and executing callbacks when events occur, improving scalability and performance.
  
  This approach helps Node.js efficiently handle multiple operations concurrently without waiting, making it ideal for real-time apps and servers.
  </div>


<div class="answer">
In Node.js, an event is a signal emitted by objects to indicate that something has happened, such as a user action or system occurrence. <br />
Node uses the class to handle events, allowing objects to emit named events and listeners to respond asynchronously.  <br /> <br />
This event-driven architecture enables efficient, non-blocking I/O operations, making Node.js suitable for scalable applications.

<pre>
const EventEmitter = require('events');
const emitter = new EventEmitter();

emitter.on('message', (data) =&gt; console.log('Received:', data));
emitter.emit('message', 'Hello Node.js!');
</pre>
</div>
</li>


<li data-id="q2"><span class="faq-question green">
Event loop? Event loop phases? Handle concurrency if it's single-threaded?
</span>



<div class="answer">
The event loop is a mechanism that handles asynchronous callbacks. <br />
It allows Node.js to perform non-blocking I/O operations by offloading tasks to the system kernel and executing their callbacks when ready, enabling efficient single-threaded concurrency.
<br />
<br />
Node.js uses the event loop and asynchronous I/O via the libuv library. Heavy tasks are delegated to worker threads or the OS, enabling multiple tasks to be processed concurrently.
</div>
<div class="answer">
  
  Phases include:  <br />
  <b>
  1. timers  <br />
  2. pending callbacks  <br />
  3. idle/prepare  <br />
  4. poll  <br />
  5. check (for `setImmediate`)  <br />
  6. close callbacks  <br />
  Each handles specific queued callbacks.
</b>
  </div>
</li>

<li data-id="q63">
  <span class="faq-question">Can you give an example of each phase of the Node.js Event Loop?</span>
  <div class="answer">
    These phases repeat as long as there are operations to perform.
<pre>
<b>1. Timers:</b> Executed by <b>setTimeout</b> or <b>setInterval</b>.
    <b>setTimeout(() =&gt; console.log('Timer Phase'), 0);</b>

<b>2. Pending Callbacks:</b> Rare, triggered by certain I/O like TCP errors.
    <b>// Not commonly used directly; internal libuv I/O error callbacks land here.</b>
      
<b>3. Idle/Prepare:</b> Used internally by Node.js (not directly accessible).
    <b>// No direct example ‚Äî internal phase.</b>

<b>4. Poll:</b> Retrieves new I/O events; where most I/O callbacks execute.
      const fs = require('fs');
      fs.readFile(__filename, () =&gt; console.log('Poll Phase (I/O)')); 

<b>5. Check:</b> Executes <b>setImmediate</b> callbacks.
      setImmediate(() =&gt; console.log('Check Phase (setImmediate)'));
    
<b>6. Close Callbacks:</b> Runs close event callbacks like <b>socket.on('close')</b>
      const net = require('net');
      const server = net.createServer();
      server.on('connection', (socket) =&gt; {
        socket.on('close', () =&gt; console.log('Close Callback'));
        socket.end();
      });
      server.listen(3000, () =&gt; {
        const client = net.connect(3000);
      });
</pre>

    
  </div>
</li>
<li data-id="q64">
  <span class="faq-question">What is Callback Hell in Node.js?</span>
  <div class="answer">
<pre>
<b>Callback Hell</b> refers to the situation where multiple nested callbacks make code hard to read and maintain. 
It usually occurs in asynchronous code when callbacks are nested within callbacks.

<b>Solution:</b> Use Promises or <b>async/await</b> to flatten the structure:


fs.readFile('file1.txt', 'utf8', (err, data1) =&gt; {
  if (err) throw err;
  fs.readFile('file2.txt', 'utf8', (err, data2) =&gt; {
    if (err) throw err;
    fs.readFile('file3.txt', 'utf8', (err, data3) =&gt; {
      if (err) throw err;
      console.log(data1, data2, data3);
    });
  });
});


<hr />
async function readFiles() {
  try {
    const data1 = await fs.promises.readFile('file1.txt', 'utf8');
    const data2 = await fs.promises.readFile('file2.txt', 'utf8');
    const data3 = await fs.promises.readFile('file3.txt', 'utf8');
    console.log(data1, data2, data3);
  } catch (err) {
    console.error(err);
  }
}
readFiles();
    </pre>
    <strong>Conclusion:</strong> Avoid callback hell with Promises or async/await for better readability and maintainability.
  </div>
</li>





<ul class="faq">
  <li data-id="q122">
    <span class="faq-question green  ">Higher order function / Callback function?</span>
    <div class="answer">
      A callback is a function passed as an argument to another function. It‚Äôs executed after the completion of an asynchronous operation, allowing non-blocking behavior in Node.js.
      </div>
    <div class="answer">
      A <strong>higher-order function</strong> is a function that either:
      <ul>
        <li>Takes one or more functions as arguments (callbacks), or</li>
        <li>Returns a function as its result.</li>
      </ul>
      These are a key part of JavaScript and Node.js functional programming style.

      <br><br><strong>Example:</strong>
      <pre>
function greet(name) {
  return `Hello, ${name}`;
}

function higherOrder(fn, value) {
  return fn(value);
}

console.log(higherOrder(greet, 'Node.js')); // Output: Hello, Node.js
      </pre>

      <strong>Common higher-order functions in Node.js:</strong>
      <ul>
        <li><code>Array.prototype.map()</code></li>
        <li><code>Array.prototype.filter()</code></li>
        <li><code>Array.prototype.reduce()</code></li>
        <li>Custom middleware functions in Express.js</li>
      </ul>
    </div>
  </li>
</ul>


<li data-id="q56">
  <span class="faq-question">What is the difference between <b>~</b> and <b>^</b> in <b>package.json</b> dependencies?</span>
  <div class="answer">
    <ul>
      <li><b>^1.2.3</b> allows updates to any minor or patch version, e.g., <b>1.x.x</b> but not <b>2.0.0</b>.</li>
      <li><b>~1.2.3</b> allows updates only to patch versions, e.g., <b>1.2.x</b> but not <b>1.3.0</b>.</li>
      <li>In short, <b>^</b> is more permissive (minor + patch), <b>~</b> is more restrictive (patch only).</li>
    </ul>
  </div>
</li>





<li data-id="q13"><span class="faq-question">
Worker threads?
</span><div class="answer">
Worker threads enable running JavaScript in parallel threads. Unlike the main thread, they can handle CPU-intensive tasks without blocking the event loop, improving performance.
</div>
<div class="answer">
<pre>
Worker threads enable parallel execution in Node.js for heavy tasks, keeping the main thread non-blocking.
Worker threads are a way to run JavaScript code in parallel on multiple threads in Node.js. 

While Node.js is single-threaded by default (using an event loop), 
Worker Threads enable CPU-intensive tasks to be executed without blocking the main event loop, improving performance for compute-heavy operations.

Introduced in Node.js v10.5.0 (stable since v12), the <b>worker_threads</b> module allows you to create and manage threads that run scripts independently. 
Each worker has its own event loop, memory, and execution context, enabling true parallelism.

Use cases include heavy computations, data processing, or any synchronous tasks that would otherwise block the main thread and degrade app responsiveness.

Communication between the main thread and worker threads happens via messaging using <b>postMessage()</b> and listening to <b>message</b> events. 
Workers can share memory efficiently using <b>SharedArrayBuffer</b>.


<b>Example usage:</b>
<code>
  const { Worker }  = require('worker_threads');
  const worker      = new Worker('./workerScript.js');
  worker.on('message', msg =&gt; console.log('From worker:', msg));
  worker.postMessage('start');
  <hr />
  const { Worker }  = require('worker_threads');
  const path        = require('path');
  const worker      = new Worker(path.resolve(__dirname, './workerScript.js'));

  worker.on('message',  (msg)   => {  console.log('From worker:', msg);     });
  worker.on('error',    (err)   => {  console.error('Worker error:', err);  });
  worker.on('exit',     (code)  => {  console.log(`Worker exited with code ${code}`); });
  
  // Simulate sending a large JSON string for processing
  const largeJson   = JSON.stringify({  users: Array.from({ length: 100000 }, (_, i) => ({ id: i, name: `User${i}` }))  });
  worker.postMessage(largeJson);
  <hr />
  const { parentPort } = require('worker_threads');
  parentPort.on('message', (jsonString) => {
    try {
      const data = JSON.parse(jsonString);

      // Do some CPU-heavy processing
      const transformed = data.users.map(user => ({
        id: user.id,
        name: user.name.toUpperCase(), // Example transformation
      }));

      // Send back just a summary
      parentPort.postMessage({
        status: 'success',
        count: transformed.length,
        sample: transformed.slice(0, 5) // send first 5 records
      });
    } catch (error) {
      parentPort.postMessage({ status: 'error', message: error.message });
    }
  });


</code>

</pre>
</div></li>
<li data-id="q_package_lock"><span class="faq-question">
Package-lock.json?
</span><div class="answer">
<code>package-lock.json</code> is automatically generated by npm when installing dependencies. It locks the exact versions of installed packages and their sub-dependencies to ensure consistency across different environments. While <code>package.json</code> defines dependency ranges (e.g., <code>^1.2.3</code>), <code>package-lock.json</code> stores the exact versions (e.g., <code>1.2.3</code>) used during installation.<br><br>

This ensures that every developer or deployment environment installs the same dependency tree, avoiding bugs caused by version differences. It also improves performance by caching dependency metadata. This file should be committed to version control in most projects.
</div></li>




<li data-id="q_node_error_handling"><span class="faq-question">
Error handling?
</span><div class="answer">

<pre>
Error handling in Node.js is critical for building reliable applications.
Proper error handling helps maintain app stability and improves debugging.
Common strategies include:<br />

<strong>1. Try-Catch:</strong> Used for synchronous code and <b>async/await</b> blocks.
  try {
    const data = await getData();
  } 
  catch (err) {
    console.error(err.message);
  }


<strong>2. Error-First Callbacks:</strong> Standard Node pattern where the first parameter is an error object.
fs.readFile('file.txt', (err, data) => {
  if (err) return console.error(err);
    console.log(data.toString());
});


<strong>3. Global Error Handling:</strong> Catch unhandled exceptions or promise rejections.
process.on('uncaughtException',   (err)     => {  console.error('Unhandled Exception:', err); });
process.on('unhandledRejection',  (reason)  => {  console.error('Unhandled Rejection:', reason);});


<strong>4. Express Middleware:</strong> Use error-handling middleware in Express.
app.use((err, req, res, next) => {  res.status(500).json({ message: err.message }); });

</pre>
</div></li>

<li data-id="q14oth"><span class="faq-question green">üéØ Abstraction in Object-Oriented Programming (OOP)</h1>
</span><div class="answer">

  <div class="section">
    <h2>What is Abstraction?</h2>
    <p><strong>Abstraction</strong> is the concept of hiding complex implementation details and showing only the essential features of an object.</p>
    <p>It helps reduce complexity by exposing only what is necessary.</p>
  </div>

  <div class="section">
    <h2>Real-World Example</h2>
    <p>When you drive a car, you interact with the steering wheel, pedals, and gear. You don‚Äôt need to know how the engine works internally ‚Äî that's abstraction.</p>
  </div>

  <div class="section">
    <h2>How It Works in OOP</h2>
    <ul>
      <li>Achieved using <strong>abstract classes</strong> and <strong>interfaces</strong>.</li>
      <li>Only relevant operations are exposed through public methods.</li>
      <li>Internal logic is hidden from the user of the object.</li>
    </ul>
  </div>

  <div class="section">
    <h2>Example in Java</h2>
    <pre><code>abstract class Animal {
  abstract void makeSound();
}

class Dog extends Animal {
  void makeSound() {
    System.out.println("Bark");
  }
}

public class Main {
  public static void main(String[] args) {
    Animal a = new Dog();
    a.makeSound();  // Output: Bark
  }
}</code></pre>
    <p>Here, the user of the <code>Animal</code> class knows it has a <code>makeSound()</code> method, but not how it is implemented.</p>
  </div>

  <div class="section">
    <h2>Benefits of Abstraction</h2>
    <ul>
      <li>Improves code readability and maintainability</li>
      <li>Hides unnecessary details from the user</li>
      <li>Supports loose coupling and high cohesion</li>
      <li>Makes the application more secure by exposing only relevant parts</li>
    </ul>
  </div>
  <h1>üîç Abstraction vs Interface in OOP</h1>

  <div class="section">
    <h2>Definition</h2>
    <p><strong>Abstraction</strong> is the concept of hiding implementation details and exposing only essential features. It can be implemented using <code>abstract classes</code> or <code>interfaces</code>.</p>
    <p><strong>Interface</strong> is a contract that specifies what methods a class should implement, without defining how they are implemented.</p>
  </div>

  <div class="section">
    <h2>Comparison Table</h2>
    <table>
      <thead>
        <tr>
          <th>Feature</th>
          <th>Abstract Class</th>
          <th>Interface</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Purpose</td>
          <td>Used for partial abstraction and shared code.</td>
          <td>Used to define a full contract for implementing classes.</td>
        </tr>
        <tr>
          <td>Method Implementation</td>
          <td>Can have both abstract and concrete methods.</td>
          <td>Cannot have implementation (except default/static in modern languages).</td>
        </tr>
        <tr>
          <td>Multiple Inheritance</td>
          <td>Not supported in many languages (e.g., Java).</td>
          <td>Can implement multiple interfaces.</td>
        </tr>
        <tr>
          <td>Constructors</td>
          <td>Can have constructors.</td>
          <td>Cannot have constructors.</td>
        </tr>
        <tr>
          <td>Access Modifiers</td>
          <td>Can use public, protected, private, etc.</td>
          <td>Methods are public by default.</td>
        </tr>
        <tr>
          <td>Use Case</td>
          <td>When classes share common behavior with differences.</td>
          <td>When you want to enforce a common API without shared code.</td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="section">
    <h2>Example in Java</h2>

    <h3>Abstract Class</h3>
    <pre><code>abstract class Animal {
  abstract void sound();

  void breathe() {
    System.out.println("Breathing...");
  }
}</code></pre>

    <h3>Interface</h3>
    <pre><code>interface Flyable {
  void fly();
}

class Bird implements Flyable {
  public void fly() {
    System.out.println("Flying...");
  }
}</code></pre>
  </div>

  <div class="section">
    <h2>Quick Summary</h2>
    <ul>
      <li><strong>Abstraction</strong> is a broader concept; an abstract class is one way to implement it.</li>
      <li><strong>Interface</strong> is a pure abstraction tool used for enforcing contracts between classes.</li>
    </ul>
  </div>

</div></li>
<li data-id="q14oth"><span class="faq-question green">
  üîê OAuth 2.0 Overview
</span><div class="answer">
  <div class="section">
    <h2>What is OAuth 2.0?</h2>
    <p>OAuth 2.0 is an <strong>authorization framework</strong> that allows third-party applications to obtain limited access to a user's resources without exposing their credentials.</p>
  </div>

  <div class="section">
    <h2>Roles in OAuth 2.0</h2>
    <ul>
      <li><strong>Resource Owner:</strong> The user who owns the data.</li>
      <li><strong>Client:</strong> The application requesting access to the resource.</li>
      <li><strong>Authorization Server:</strong> Issues access tokens after authenticating the user.</li>
      <li><strong>Resource Server:</strong> Hosts the protected resources and validates the token.</li>
    </ul>
  </div>

  <div class="section">
    <h2>OAuth 2.0 Grant Types</h2>
    <ul>
      <li><strong>Authorization Code:</strong> Used for server-side applications. Secure and most commonly used.</li>
      <li><strong>Implicit:</strong> Used for public clients like single-page apps. Less secure (now discouraged).</li>
      <li><strong>Resource Owner Password Credentials:</strong> User provides credentials directly. Used in trusted apps.</li>
      <li><strong>Client Credentials:</strong> Used for machine-to-machine communication.</li>
    </ul>
  </div>

  <div class="section">
    <h2>OAuth 2.0 Flow: Authorization Code Grant</h2>
    <ol>
      <li>User is redirected to Authorization Server to log in.</li>
      <li>User grants permission to the app.</li>
      <li>Authorization Server redirects back with an <code>authorization code</code>.</li>
      <li>App exchanges the code for an <code>access token</code>.</li>
      <li>App uses the token to access protected resources.</li>
    </ol>
  </div>

  <div class="section">
    <h2>Access & Refresh Tokens</h2>
    <ul>
      <li><strong>Access Token:</strong> Used to access protected resources. Short-lived.</li>
      <li><strong>Refresh Token:</strong> Used to obtain a new access token when it expires. Long-lived.</li>
    </ul>
  </div>

  <div class="section highlight">
    <h2>Security Tips</h2>
    <ul>
      <li>Use HTTPS for all communication.</li>
      <li>Never expose client secrets in frontend apps.</li>
      <li>Use PKCE with public clients (e.g., mobile apps, SPAs).</li>
      <li>Use short-lived access tokens and refresh tokens securely.</li>
    </ul>
  </div>
  

</div></li>

<li data-id="q14"><span class="faq-question green">
Middleware? Types of middleware
</span><div class="answer">
Middleware in Express.js is a function that processes requests and responses during the request-response cycle. <Br />
It has access to the <b>req</b> and <b>res</b> objects and the next middleware function in the stack via the <b>next()</b> callback.<Br /><Br />
Middleware functions can perform tasks like:
<ol class="subul">
<li>Executing code</li>
<li>Modifying <b>req</b> and <b>res</b> objects</li>
<li>Ending the request-response cycle</li>
<li>Calling the next middleware</li>
</ol>
<br />
<b class="green">Types of middleware :</b>
<ol class="subul">
  <li><strong>Application-level:</strong> Bound to an Express app using <b>app.use()</b> or route methods.</li>
  <li><strong>Router-level:</strong> Bound to an instance of <b>express.Router()</b>.</li>
  <li><strong>Error-handling:</strong> Special middleware with four arguments <b>(err, req, res, next)</b> to catch errors.</li>
  <li><strong>Built-in:</strong> Provided by Express, e.g., <b>express.json()</b>, <b>express.static()</b>.</li>
  <li><strong>Third-party:</strong> Such as <b>cors</b>, <b>helmet</b>, <b>morgan</b>.</li>
</ol>

Example:

<pre><code>app.use((req, res, next) =&gt; {
console.log('Request URL:', req.url);
next(); // Pass control to next middleware
});
</code></pre>

Middleware enables modular, reusable, and organized handling of HTTP requests, essential for building scalable Express.js applications.
</div></li>


<li data-id="q19"><span class="faq-question">
Circular Dependencies in react
</span><div class="answer">
A circular dependency in a React project happens when two or more modules (components, hooks, utils, contexts, etc.) depend on each other, creating a loop.
<br />

1. Restructure your code : Move shared logic to a new module both can import.<br />
2. Use dependency injection : Pass dependencies as arguments rather than importing them.<br />
<code>
  // a.js
  module.exports = (b) => {
    console.log('Using B in A');
  };   
</code><br />
3. Use dynamic import (or require) inside functions : Delay the import until the function is called.<br />
<code>
  function getB() {
    const b = require('./b');
    b();
  }  
</code>
<br />
<code>
# Install : npm install -g madge
<br />
# Run : madge --circular src/
</code>

<h5>How to Fix Circular Dependencies in React</h5>
1. Split Shared Logic into a Separate File<br />
2. Use Lazy Loading / Code Splitting<br />
Use React.lazy() to defer loading of components.<br />
<code>const Navbar = React.lazy(() => import('./Navbar'));</code>

4. Avoid Cross-Component Imports<br />
If ComponentA and ComponentB both use each other:<br />
Move shared UI into a new SubComponent<br />
Or lift shared state to the parent<br />

</div></li>



<li data-id="q19"><span class="faq-question green">
Cluster vs Worker*** cluster.fork()
</span><div class="answer">
  In Node.js, both Cluster and Worker Threads are used for parallel processing, but they serve different purposes and have distinct architectures.  
<br />
<a href="/doctor/cluster.html" target="_blank" style="color: blue; font-weight: bold;">Read More</a><br /><br />

<ol class="subul">
  <li>
    The cluster module allows you to create child processes (workers) that share the same server port. <br />
    It's used to take advantage of multi-core systems to handle concurrent requests efficiently.<br />
    It is used to utilize multiple CPU cores, improving performance for concurrent requests.<br />
    const cluster = require('cluster');<br /><br />
  </li>
  <li>
      The worker_threads module allows JavaScript code to run in parallel on multiple threads. <br />
      Useful for CPU-intensive tasks (like hashing, image processing) without blocking the main event loop.<br />
      A **worker** is an individual child process created by the cluster. <br />
      Each worker runs its own Node.js instance and handles a portion of the server load. <br />
      They can communicate with the master process via IPC (inter-process communication).<br />
      <span class="green">A **worker** is an individual child process created by the cluster. </span><br />
      Each worker runs its own Node.js instance and handles a portion of the server load. <br />
      They can communicate with the master process via IPC (inter-process communication).<br />
      const { Worker, isMainThread, parentPort, workerData } = require('worker_threads');
    </li>
</ol>
<hr />
<br />

<span class="green">
Node.js is single-threaded by default. Using the cluster module allows your app to : Handle more requests concurrently.
</span>
<ol class="subul">
  <li>Avoid a single point of failure (if one worker crashes, others keep running).</li>
  <li>Use all CPU cores on a server.</li>
  <li>All workers share the same server port.</li>
  <li>Each worker is a separate Node.js process (not thread).</li>
  <li>Workers don‚Äôt share memory ‚Äì use IPC or external stores (like Redis) for shared state.</li>
</ol>
<br />


<hr />
  
  
    <div class="section">
      <br />
      <div class="title">üîÑ Cluster vs Worker Comparison</div>
      <table class="table">
        <thead>
          <tr>
            <th>Aspect</th>
            <th>Cluster</th>
            <th>Worker</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Definition</td>
            <td>Main controller module to spawn child processes</td>
            <td>Individual child process spawned by the cluster</td>
          </tr>
          <tr>
            <td>Role</td>
            <td>Manages multiple workers</td>
            <td>Handles incoming requests or tasks</td>
          </tr>
          <tr>
            <td>Code Location</td>
            <td>Master process</td>
            <td>Worker process</td>
          </tr>
          <tr>
            <td>Use Case</td>
            <td>Load balancing and CPU core utilization</td>
            <td>Actual request processing</td>
          </tr>
          <tr>
            <td>Communication</td>
            <td>Interacts with workers via IPC</td>
            <td>Communicates with master via IPC</td>
          </tr>
        </tbody>
      </table>
    </div>
  
<hr />

<h2>üîç Comparison: Manual cluster vs PM2</h2>

<table>
  <tr>
    <th>Feature</th>
    <th>Manual cluster</th>
    <th>PM2</th>
  </tr>
  <tr>
    <td>Setup</td>
    <td>Manual coding required</td>
    <td class="yes">Easy CLI-based</td>
  </tr>
  <tr>
    <td>Load balancing</td>
    <td class="yes">Handled via cluster</td>
    <td class="yes">Built-in</td>
  </tr>
  <tr>
    <td>Process Monitoring</td>
    <td class="no">Not built-in</td>
    <td class="yes">Dashboard + CLI</td>
  </tr>
  <tr>
    <td>Crash Recovery</td>
    <td class="no">Manual restart</td>
    <td class="yes">Automatic restart</td>
  </tr>
  <tr>
    <td>Logging</td>
    <td class="no">Requires setup</td>
    <td class="yes">Built-in logging</td>
  </tr>
  <tr>
    <td>Production Readiness</td>
    <td class="no">Not ideal alone</td>
    <td class="yes">‚úÖ Highly recommended</td>
  </tr>
</table>



</div></li>



<li data-id="q19"><span class="faq-question">
Clustering? & cluster vs worker*** cluster.fork()
</span><div class="answer">

Clustering enables using multiple CPU cores by spawning worker processes that share the same server port, improving performance and load handling.
</div>
<div class="answer">
Clustering in Node.js is a technique to create multiple child processes (workers) that share the same server port, allowing you to take advantage of multi-core CPU systems. Since Node.js runs on a single thread by default, clustering helps improve performance and reliability by distributing incoming requests across several worker processes.

The core module cluster enables spawning of worker processes. Each worker runs its own event loop and instance of the Node.js runtime, enabling parallel processing of requests.
<br />
Key benefits:
<ul>
<li><strong>Improved Performance:</strong> Utilizes multiple CPU cores to handle more concurrent connections.</li>
<li><strong>Fault Tolerance:</strong> If one worker crashes, the master process can spawn a new worker, improving app resilience.</li>
<li><strong>Load Balancing:</strong> The master process balances incoming requests between workers.</li>
</ul>

Basic usage example:

<pre><code>const cluster = require('cluster');
const http = require('http');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
  cluster.on('exit', (worker) => {
    console.log(`Worker ${worker.process.pid} died, spawning a new one.`);
    cluster.fork();
  });
} 
else {
  http.createServer((req, res) =&gt; {
    res.end('Hello from worker ' + process.pid);
  }).listen(8000);
}
</code></pre>

Clustering boosts Node.js scalability but requires careful management of shared resources and state.
</div>

</li>


<li data-id="q28"><span class="faq-question green">
Performance?
</span><div class="answer">
Use clustering, caching (Redis), async operations, database indexing, code profiling, monitoring (e.g., New Relic), and limit synchronous code. Minimize memory leaks and optimize queries.
</div>
<div class="answer">
Optimizing performance in large-scale Node.js applications involves multiple strategies:
<br />
<strong>1. Use Asynchronous Code:</strong> Always prefer non-blocking async operations to avoid blocking the event loop.<br>

<strong>2. Load Balancing & Clustering:</strong> Use the cluster module or external load balancers to utilize multiple CPU cores.<br>

<strong>3. Caching:</strong> Cache frequent data using in-memory stores like Redis or Memcached to reduce database load.<br>

<strong>4. Database Optimization:</strong> Use indexing, connection pooling, and optimized queries to improve database interaction.<br>

<strong>5. Avoid Memory Leaks:</strong> Monitor heap usage, manage object lifecycles carefully, and use profiling tools like Chrome DevTools or Clinic.js.<br>

<strong>6. Use Streams:</strong> Process large data efficiently with streams to minimize memory footprint.<br>

<strong>7. Efficient Logging:</strong> Use asynchronous logging libraries and avoid excessive logging in production.<br>

<strong>8. Minimize Dependencies:</strong> Avoid bloated or unused npm packages to reduce startup time.<br>

<strong>9. Profiling & Monitoring:</strong> Continuously profile your app using tools like New Relic, Datadog, or built-in profilers.<br>

<strong>10. Use CDN & Compression:</strong> Serve static assets via CDN and compress responses with gzip or brotli.<br>

Regular code reviews, performance testing, and keeping dependencies up-to-date help maintain high performance.
</div>

</li>

<li data-id="q12"><span class="faq-question">
Difference between process.nextTick() and setImmediate()?
</span><div class="answer">
<b class="green">process.nextTick()</b> schedules a callback to execute immediately after the current operation completes, before the event loop continues. It has higher priority and runs before any I/O events or timers.
<br />
<b class="green">setImmediate()</b> schedules a callback to run on the next iteration (tick) of the event loop, after I/O events callbacks.
<br /><br />
In short,
<code>process.nextTick() : runs before any I/O tasks, can starve I/O, blocking the event loop.</code> 
<code>setImmediate() :  runs after I/O events in the event loop.</code>
 
</div>

</li>

<li data-id="q24"><span class="faq-question">
How do you secure a Node.js application?
</span><div class="answer">
Securing a Node.js application involves multiple layers of protection:<br />

<strong>1. HTTP Headers:</strong> Use <code>helmet</code> middleware to set secure HTTP headers and prevent common attacks like XSS, clickjacking, and MIME-sniffing.<br>

<strong>2. Rate Limiting:</strong> Implement request throttling using <code>express-rate-limit</code> to protect against brute-force and DDoS attacks.<br>

<strong>3. Input Validation & Sanitization:</strong> Use libraries like <code>express-validator</code> or <code>Zod</code> to validate and sanitize incoming data to avoid injection attacks.<br>

<strong>4. Authentication & Authorization:</strong> Use secure token-based auth like <code>JWT</code>. Never store sensitive info in plain text‚Äîalways hash passwords with <code>bcrypt</code>.<br>

<strong>5. Use HTTPS:</strong> Encrypt communication using SSL certificates to secure data in transit.<br>

<strong>6. Avoid Eval & Unsafe Code:</strong> Never use <code>eval()</code> or <code>Function()</code> with untrusted data. These can lead to RCE (Remote Code Execution).<br>

<strong>7. Dependency Management:</strong> Use <code>npm audit</code> and tools like <code>snyk</code> to identify and fix vulnerable packages.<br>

<strong>8. Secure Cookies:</strong> Use <code>HttpOnly</code>, <code>Secure</code>, and <code>SameSite</code> flags on cookies.<br>

<strong>9. Environment Variables:</strong> Keep secrets and configs in <code>.env</code> files. Never hard-code credentials.<br>

<strong>10. Logging & Monitoring:</strong> Monitor with tools like <code>Winston</code>, <code>Morgan</code>, or services like Datadog or New Relic.

Regularly update Node.js and dependencies to stay protected.
</div></li>


<li data-id="q20"><span class="faq-question">
Explain how Buffer works in Node.js.
</span><div class="answer">
`Buffer` is a global object used to handle binary data directly. It's useful for working with streams, files, and network protocols without converting to strings.
</div></li>







<li data-id="q_ts"><span class="faq-question green">
TypeScript?
</span><div class="answer">
TypeScript is a strongly typed superset of JavaScript developed by Microsoft.<br /> 
It adds <span class="green">static typing, interfaces, enums, and advanced tooling features to JavaScript, 
helping developers catch errors at compile time instead of runtime.</span> 
TypeScript code compiles down to plain JavaScript, making it compatible with any environment that runs JS. It improves code quality, readability, and maintainability, especially for large-scale applications. TypeScript integrates well with modern frameworks like Angular, React, and Node.js, and offers excellent support in popular editors like VS Code with features like autocompletion and refactoring.
</div></li>

<li data-id="q_gql"><span class="faq-question">
GraphQL?
</span><div class="answer">
GraphQL offers several advantages over traditional REST APIs:
<ul>
<li><strong>Flexible Queries:</strong> Clients can request exactly the data they need, reducing over-fetching and under-fetching.</li>
<li><strong>Single Endpoint:</strong> All data queries and mutations happen through one endpoint, simplifying API management.</li>
<li><strong>Strongly Typed Schema:</strong> The schema defines the types and relationships, enabling better validation and tooling.</li>
<li><strong>Efficient Data Loading:</strong> Supports batching and caching to minimize redundant data fetching.</li>
<li><strong>Improved Developer Experience:</strong> Introspection and auto-generated documentation make development faster and easier.</li>
<li><strong>Real-time Data:</strong> Supports subscriptions for live updates.</li>
</ul>
These features make GraphQL ideal for complex, evolving APIs and frontend-driven development.
</div></li>





<li data-id="q_design_patterns"><span class="faq-question">
What are design patterns in Node.js?
</span><div class="answer">
Design patterns are reusable solutions to common software design problems. In Node.js, popular patterns include:<br />

<strong>1. Singleton:</strong> Ensures a class has only one instance (e.g., database connection).<br>
<strong>2. Factory:</strong> Creates objects without exposing the instantiation logic.<br>
<strong>3. Observer:</strong> Implements pub-sub mechanisms (e.g., <code>EventEmitter</code>).<br>
<strong>4. Middleware:</strong> Common in Express apps for request handling.<br>
<strong>5. Module Pattern:</strong> Uses closures to encapsulate logic.

Using design patterns improves code organization, reusability, and maintainability in scalable Node.js applications.
</div></li>
<li data-id="q_design_patterns_more"><span class="faq-question">
Explain Singleton, Factory, Observer, Middleware, and Module patterns in Node.js
</span><div class="answer">
<strong>Singleton:</strong> Restricts a class to one instance. Useful for shared resources like DB connections. Ensures consistent state across the app.<br><br>

<strong>Factory:</strong> Creates objects without specifying exact classes. It abstracts object creation, allowing flexible and interchangeable products.<br><br>

<strong>Observer:</strong> Implements event-driven communication where objects subscribe to events and get notified on changes. Node‚Äôs <code>EventEmitter</code> is a classic example.<br><br>

<strong>Middleware:</strong> Functions that intercept requests in a chain to process or modify them. Common in Express.js for logging, authentication, or error handling.<br><br>

<strong>Module Pattern:</strong> Uses closures to encapsulate private variables and expose a public API. Helps in organizing code into reusable, maintainable parts.<br><br>

These patterns help write modular, scalable, and maintainable Node.js applications.
</div></li>
<li data-id="q_solid"><span class="faq-question">
SOLID in software development?
</span><div class="answer">
SOLID is a set of five design principles aimed at making software designs more understandable, flexible, and maintainable:<br><br>

<strong>S</strong> - Single Responsibility Principle: A class should have only one reason to change.<br>
<strong>O</strong> - Open/Closed Principle: Software entities should be open for extension but closed for modification.<br>
<strong>L</strong> - Liskov Substitution Principle: Subclasses should be replaceable by their base classes without affecting correctness.<br>
<strong>I</strong> - Interface Segregation Principle: Clients should not be forced to depend on interfaces they don‚Äôt use.<br>
<strong>D</strong> - Dependency Inversion Principle: High-level modules should not depend on low-level modules but on abstractions.<br><br>

Applying SOLID improves code quality and eases maintenance.
</div></li>

<li data-id="q_datatypes"><span class="faq-question green">
  Data types in JavaScript?
  </span><div class="answer">
  JavaScript has two main types of data types:<br><br>
  
  <strong>1. Primitive Types:</strong><br>
  - <b>String</b>: e.g., "hello"<br>
  - <b>Number</b>: e.g., 123, 3.14<br>
  - <b>Boolean</b>: true or false<br>
  - <b>Undefined</b>: a variable declared but not assigned<br>
  - <b>Null</b>: intentional absence of any value<br>
  - <b>Symbol</b>: unique and immutable value<br>
  - <b>BigInt</b>: for large integers beyond Number limits<br><br>
  
  <strong>2. Non-Primitive (Reference) Types:</strong><br>
  - <b>Object</b>: includes arrays, functions, dates, etc.<br><br>
  
  Primitive types are compared by value, while objects are compared by reference.
  </div></li>


  <li data-id="q64446">

    <span class="faq-question">What is the difference between <b>var</b>, <b>let</b>, and <b>const</b> in JavaScript?</span>
    <div class="answer">
      These three keywords are used to declare variables in JavaScript but differ in scope, hoisting, and mutability.
      
      <h4>1. var</h4>
      <ul>
        <li><strong>Scope:</strong> Function-scoped</li>
        <li><strong>Hoisting:</strong> Hoisted and initialized with <b>undefined</b></li>
        <li><strong>Re-declaration:</strong> Allowed</li>
        <li><strong>Use:</strong> Considered outdated; avoid in modern code</li>
      </ul>
      <pre><code>
  function test() {
    var x = 1;
    if (true) {
      var x = 2;
      console.log(x); // 2
    }
    console.log(x); // 2
  }
      </code></pre>
  
      <h4>2. let</h4>
      <ul>
        <li><strong>Scope:</strong> Block-scoped</li>
        <li><strong>Hoisting:</strong> Hoisted but not initialized (temporal dead zone)</li>
        <li><strong>Re-declaration:</strong> Not allowed in same scope</li>
        <li><strong>Use:</strong> For variables that will change</li>
      </ul>
      <pre><code>
  let x = 1;
  x = 2; // Allowed
      </code></pre>
  
      <h4>3. const</h4>
      <ul>
        <li><strong>Scope:</strong> Block-scoped</li>
        <li><strong>Hoisting:</strong> Hoisted but not initialized</li>
        <li><strong>Re-assignment:</strong> Not allowed</li>
        <li><strong>Use:</strong> For variables that shouldn't change (e.g., constants)</li>
      </ul>
      <pre><code>
  const y = 10;
  y = 20; // ‚ùå Error
  const obj = { a: 1 };
  obj.a = 2; // ‚úÖ Allowed (reference not reassigned)
      </code></pre>
  
      <h4>Summary Table:</h4>
      <table border="1" cellpadding="6" cellspacing="0">
        <tr>
          <th>Keyword</th>
          <th>Scope</th>
          <th>Hoisted</th>
          <th>Re-declarable</th>
          <th>Re-assignable</th>
        </tr>
        <tr>
          <td><b>var</b></td>
          <td>Function</td>
          <td>Yes (undefined)</td>
          <td>Yes</td>
          <td>Yes</td>
        </tr>
        <tr>
          <td><b>let</b></td>
          <td>Block</td>
          <td>Yes (but TDZ)</td>
          <td>No</td>
          <td>Yes</td>
        </tr>
        <tr>
          <td><b>const</b></td>
          <td>Block</td>
          <td>Yes (but TDZ)</td>
          <td>No</td>
          <td>No (but object props mutable)</td>
        </tr>
      </table>
    </div>
  </li>
  





<li data-id="q_currying"><span class="faq-question">
Currying?
</span><div class="answer">
Currying is a functional programming technique where a function is transformed into a sequence of functions, each taking a single argument. Instead of taking all arguments at once, a curried function takes them one by one.

It improves code reusability and function composition.

Example:
<pre><code>
// Normal function
function add(a, b) {
return a + b;
}

// Curried version
function curriedAdd(a) {
return function(b) {
return a + b;
};
}

console.log(curriedAdd(2)(3)); // 5
</code></pre>
Currying is useful for creating customizable and reusable function pipelines.
</div></li>

<li data-id="q_oauth2"><span class="faq-question green">
OAuth 2.0?
</span><div class="answer">
OAuth 2.0 is an authorization framework that enables third-party applications to obtain limited access to user resources on a server without exposing user credentials.

It works by issuing access tokens after user consent, which the application uses to access protected resources.
<br />
Key roles:<br />
- <strong class="green">Resource Owner:</strong> User granting access<br />
- <strong>Client:</strong> Application requesting access<br />
- <strong>Authorization Server:</strong> Issues tokens<br />
- <strong>Resource Server:</strong> Hosts protected resources<br />

Common grant types:<br />
- Authorization Code<br />
- Implicit<br />
- Resource Owner Password Credentials<br />
- Client Credentials<br />

OAuth 2.0 improves security by decoupling authentication and authorization, widely used in APIs and social logins.
</div></li>


<li data-id="q_token_vs_session"><span class="faq-question">
the difference between Token and Session?
</span><div class="answer">
<strong>Session:</strong><br>
- Server stores user state and session ID.<br>
- Client holds session ID in cookies.<br>
- Requires server-side memory or storage.<br>
- Easier to invalidate on logout.<br>

<strong>Token (e.g., JWT):</strong><br>
- Self-contained, stateless authentication.<br>
- Token holds user info, signed by server.<br>
- Stored client-side (localStorage/cookies).<br>
- Scales better, no server memory needed.<br>

<strong>Summary:</strong><br>
Sessions are server-managed; tokens are client-managed. Tokens are popular for APIs and stateless apps; sessions suit traditional web apps.
</div></li>



<li data-id="q_aws_api_gateway"><span class="faq-question">
AWS API Gateway?
</span><div class="answer">
AWS API Gateway is a fully managed service that enables developers to create, publish, maintain, monitor, and secure APIs at any scale.

It acts as a front door for applications to access backend services like AWS Lambda, EC2, or external endpoints.

Key features:<br>
- Supports RESTful and WebSocket APIs.<br>
- Handles request routing, throttling, authorization, and monitoring.<br>
- Integrates with AWS services for security (Cognito, IAM).<br>
- Enables caching to improve performance.<br>

API Gateway simplifies building scalable, secure, and reliable APIs with minimal infrastructure management.
</div></li>









    
<li data-id="q_redux_formatted" class="yellow">
  <span class="faq-question">Zod with NodeJS</span>
  <div class="answer">
    <pre>
&lt;!-- Node.js backend validation with Zod and Express.js --&gt;
&lt;code&gt;
const express = require('express');
const { z } = require('zod');

const app = express();
app.use(express.json());

// Define Zod schema for Contact Us data
const contactSchema = z.object({
  name: z.string().min(2, "Name must be at least 2 characters"),
  email: z.string().email("Invalid email address"),
  message: z.string().min(5, "Message must be at least 5 characters"),
});

// POST /contact route with Zod validation
app.post('/contact', (req, res) =&gt; {
  const parseResult = contactSchema.safeParse(req.body);

  if (!parseResult.success) {
    // Validation failed
    return res.status(400).json({
      success: false,
      errors: parseResult.error.errors.map(err =&gt; ({
        field: err.path[0],
        message: err.message,
      })),
    });
  }

  // If valid, process data here
  const validData = parseResult.data;

  res.json({
    success: true,
    message: "Contact form submitted successfully",
    data: validData,
  });
});

const PORT = 3000;
app.listen(PORT, () =&gt; {
  console.log(`Server running on http://localhost:${PORT}`);
});
&lt;/code&gt;
    </pre>
  </div>
</li>


<li data-id="q_redux_formatted"><span class="faq-question">
  Class Validator & Zod Type Validations with Examples
  </span>
  <div class="answer">


<pre>import { z } from "zod";</pre>

<h3>1. String</h3>
<pre>const stringSchema = z.string();

stringSchema.parse("hello");          // ‚úÖ valid
// stringSchema.parse(123);           // ‚ùå throws error

// String with min/max length
const limitedString = z.string().min(5).max(10);
limitedString.parse("abcdef");       // ‚úÖ valid
// limitedString.parse("abc");       // ‚ùå too short
</pre>

<h3>2. Number</h3>
<pre>const numberSchema = z.number();

numberSchema.parse(123);              // ‚úÖ valid
// numberSchema.parse("123");         // ‚ùå throws error

// Number with min/max
const rangedNumber = z.number().min(10).max(100);
rangedNumber.parse(50);               // ‚úÖ valid
// rangedNumber.parse(5);             // ‚ùå too small
</pre>

<h3>3. Integer</h3>
<pre>const intSchema = z.number().int();

intSchema.parse(10);                  // ‚úÖ valid
// intSchema.parse(10.5);             // ‚ùå not an integer
</pre>

<h3>4. Boolean</h3>
<pre>const boolSchema = z.boolean();

boolSchema.parse(true);               // ‚úÖ valid
// boolSchema.parse("true");          // ‚ùå throws error
</pre>

<h3>5. Date</h3>
<pre>const dateSchema = z.date();

dateSchema.parse(new Date());         // ‚úÖ valid
// dateSchema.parse("2021-01-01");    // ‚ùå throws error, use z.string() with .refine for date strings
</pre>

<h3>6. Array</h3>
<pre>const arraySchema = z.array(z.string());

arraySchema.parse(["a", "b", "c"]);   // ‚úÖ valid
// arraySchema.parse(["a", 1]);       // ‚ùå mixed types
</pre>

<h3>7. Tuple</h3>
<pre>const tupleSchema = z.tuple([z.string(), z.number()]);

tupleSchema.parse(["abc", 123]);      // ‚úÖ valid
// tupleSchema.parse([123, "abc"]);   // ‚ùå wrong order/types
</pre>

<h3>8. Object</h3>
<pre>const objSchema = z.object({
  name: z.string(),
  age: z.number().int().positive(),
});

objSchema.parse({ name: "John", age: 30 }); // ‚úÖ valid
// objSchema.parse({ name: "John" });       // ‚ùå missing age
</pre>

<h3>9. Enum</h3>
<pre>const colorEnum = z.enum(["Red", "Green", "Blue"]);

colorEnum.parse("Red");                // ‚úÖ valid
// colorEnum.parse("Yellow");          // ‚ùå invalid enum value
</pre>

<h3>10. Literal</h3>
<pre>const literalSchema = z.literal("specificValue");

literalSchema.parse("specificValue"); // ‚úÖ valid
// literalSchema.parse("other");       // ‚ùå not matching literal
</pre>

<h3>11. Union</h3>
<pre>const unionSchema = z.union([z.string(), z.number()]);

unionSchema.parse("hello");            // ‚úÖ valid
unionSchema.parse(123);                // ‚úÖ valid
// unionSchema.parse(true);            // ‚ùå invalid type
</pre>

<h3>12. Intersection</h3>
<pre>const base = z.object({ id: z.string() });
const extension = z.object({ age: z.number() });

const intersectionSchema = base.and(extension);

intersectionSchema.parse({ id: "abc", age: 25 }); // ‚úÖ valid
// intersectionSchema.parse({ id: "abc" });       // ‚ùå missing age
</pre>

<h3>13. Optional and Nullable</h3>
<pre>const optionalSchema = z.string().optional();
optionalSchema.parse(undefined);      // ‚úÖ valid
optionalSchema.parse("hello");         // ‚úÖ valid

const nullableSchema = z.string().nullable();
nullableSchema.parse(null);            // ‚úÖ valid
nullableSchema.parse("world");         // ‚úÖ valid
</pre>

<h3>14. Default</h3>
<pre>const defaultSchema = z.string().default("defaultValue");

defaultSchema.parse(undefined);       // "defaultValue"
defaultSchema.parse("input");          // "input"
</pre>

<h3>15. Record</h3>
<pre>// Object with string keys and number values
const recordSchema = z.record(z.number());

recordSchema.parse({ a: 1, b: 2 });   // ‚úÖ valid
// recordSchema.parse({ a: "one" });   // ‚ùå invalid value type
</pre>

<h3>16. Custom Validation</h3>
<pre>const customSchema = z.string().refine(val => val.startsWith("A"), {
  message: "Must start with 'A'",
});

customSchema.parse("Apple");           // ‚úÖ valid
// customSchema.parse("Banana");       // ‚ùå validation error
</pre>
</div>
</li>

<li data-id="q_redux_formatted"><span class="faq-question">
  Zod Validation Examples in Node.js
  </span><div class="answer">
  
  <pre>
    import { z } from "zod";
    
    function runValidationExamples() {
      try {
        // 1. String
        const stringSchema = z.string();
        console.log("String:", stringSchema.parse("hello"));
    
        // String with min/max length
        const limitedString = z.string().min(5).max(10);
        console.log("Limited String:", limitedString.parse("abcdef"));
    
        // 2. Number
        const numberSchema = z.number();
        console.log("Number:", numberSchema.parse(123));
    
        // Number with min/max
        const rangedNumber = z.number().min(10).max(100);
        console.log("Ranged Number:", rangedNumber.parse(50));
    
        // 3. Integer
        const intSchema = z.number().int();
        console.log("Integer:", intSchema.parse(10));
    
        // 4. Boolean
        const boolSchema = z.boolean();
        console.log("Boolean:", boolSchema.parse(true));
    
        // 5. Date
        const dateSchema = z.date();
        console.log("Date:", dateSchema.parse(new Date()));
    
        // 6. Array
        const arraySchema = z.array(z.string());
        console.log("Array:", arraySchema.parse(["a", "b", "c"]));
    
        // 7. Tuple
        const tupleSchema = z.tuple([z.string(), z.number()]);
        console.log("Tuple:", tupleSchema.parse(["abc", 123]));
    
        // 8. Object
        const objSchema = z.object({
          name: z.string(),
          age: z.number().int().positive(),
        });
        console.log("Object:", objSchema.parse({ name: "John", age: 30 }));
    
        // 9. Enum
        const colorEnum = z.enum(["Red", "Green", "Blue"]);
        console.log("Enum:", colorEnum.parse("Red"));
    
        // 10. Literal
        const literalSchema = z.literal("specificValue");
        console.log("Literal:", literalSchema.parse("specificValue"));
    
        // 11. Union
        const unionSchema = z.union([z.string(), z.number()]);
        console.log("Union (string):", unionSchema.parse("hello"));
        console.log("Union (number):", unionSchema.parse(123));
    
        // 12. Intersection
        const base = z.object({ id: z.string() });
        const extension = z.object({ age: z.number() });
        const intersectionSchema = base.and(extension);
        console.log(
          "Intersection:",
          intersectionSchema.parse({ id: "abc", age: 25 })
        );
    
        // 13. Optional and Nullable
        const optionalSchema = z.string().optional();
        console.log("Optional (undefined):", optionalSchema.parse(undefined));
        console.log("Optional (string):", optionalSchema.parse("hello"));
    
        const nullableSchema = z.string().nullable();
        console.log("Nullable (null):", nullableSchema.parse(null));
        console.log("Nullable (string):", nullableSchema.parse("world"));
    
        // 14. Default
        const defaultSchema = z.string().default("defaultValue");
        console.log("Default (undefined):", defaultSchema.parse(undefined));
        console.log("Default (input):", defaultSchema.parse("input"));
    
        // 15. Record
        const recordSchema = z.record(z.number());
        console.log("Record:", recordSchema.parse({ a: 1, b: 2 }));
    
        // 16. Custom validation
        const customSchema = z.string().refine((val) => val.startsWith("A"), {
          message: "Must start with 'A'",
        });
        console.log("Custom validation:", customSchema.parse("Apple"));
      } catch (e) {
        if (e instanceof z.ZodError) {
          console.error("Validation error:", e.errors);
        } else {
          console.error(e);
        }
      }
    }
    
    runValidationExamples();
  </pre>
  </div></li>

  <li data-id="q122"><span class="faq-question">
    Input Validation
    </span><div class="answer">
    
      
      <p>Input validation is the process of verifying user input to ensure it meets the expected format, type, or value constraints before further processing.</p>
      
      <h2>2. Zod Validation Example</h2>
      <p><strong>Install:</strong> <code>npm install zod</code></p>
      
      <pre><code>import { z } from "zod";
      
      const userSchema = z.object({
        username: z.string().min(3),
        age: z.number().int().positive(),
      });
      
      const result = userSchema.safeParse({
        username: "JohnDoe",
        age: 25,
      });
      
      if (!result.success) {
        console.log(result.error.format());
      } else {
        console.log("Valid:", result.data);
      }
      </code></pre>
      
      <h3>‚úÖ Pros of Zod:</h3>
      <ul>
        <li>Functional and immutable</li>
        <li>Type-safe with TypeScript</li>
        <li>No decorators needed</li>
      </ul>
      
      <h3>üö´ Cons of Zod:</h3>
      <ul>
        <li>Not decorator-based (if you prefer that style)</li>
      </ul>
      
      <hr>
      
      <h2>3. Class Validator Example</h2>
      <p><strong>Install:</strong> <code>npm install class-validator class-transformer</code></p>
      
      <pre><code>import { IsString, IsInt, MinLength, IsPositive } from "class-validator";
      import { plainToInstance } from "class-transformer";
      
      class CreateUserDto {
        @IsString()
        @MinLength(3)
        username: string;
      
        @IsInt()
        @IsPositive()
        age: number;
      }
      
      const input = { username: "JohnDoe", age: 25 };
      const user = plainToInstance(CreateUserDto, input);
      
      import { validate } from "class-validator";
      
      validate(user).then(errors => {
        if (errors.length > 0) {
          console.log("Validation failed:", errors);
        } else {
          console.log("Valid:", user);
        }
      });
      </code></pre>
      
      <h3>‚úÖ Pros of Class Validator:</h3>
      <ul>
        <li>Decorator-based (OOP-friendly)</li>
        <li>Widely used in NestJS</li>
        <li>Supports class-transformer for parsing/transforming inputs</li>
      </ul>
      
      <h3>üö´ Cons of Class Validator:</h3>
      <ul>
        <li>More verbose setup</li>
        <li>Requires decorators and class-based code</li>
      </ul>
      
      <hr>
      
      <h2>4. When to Use Which?</h2>
      <ul>
        <li><strong>Zod:</strong> Best for functional programming, schema-first validation, and fast prototyping.</li>
        <li><strong>Class Validator:</strong> Ideal for OOP-style architecture and NestJS applications.</li>
      </ul>
      
      <h2>5. Summary Table</h2>
      <table border="1" cellpadding="6">
        <thead>
          <tr>
            <th>Feature</th>
            <th>Zod</th>
            <th>Class Validator</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Style</td>
            <td>Functional</td>
            <td>OOP / Decorator-based</td>
          </tr>
          <tr>
            <td>TypeScript Support</td>
            <td>Excellent (type inference)</td>
            <td>Good (requires class definitions)</td>
          </tr>
          <tr>
            <td>Integration</td>
            <td>Framework-agnostic</td>
            <td>Popular in NestJS</td>
          </tr>
          <tr>
            <td>Dependencies</td>
            <td>Lightweight</td>
            <td>Requires decorators & class-transformer</td>
          </tr>
        </tbody>
      </table>
      
    </div></li>


<li data-id="q_redux_formatted"><span class="faq-question">
Zod
</span>
<div class="answer">
    
    <form id="contactForm" novalidate>
      <label for="name">Name *</label>
      <input type="text" id="name" name="name" />
      <div id="error-name" class="error"></div>
    
      <label for="email">Email *</label>
      <input type="email" id="email" name="email" />
      <div id="error-email" class="error"></div>
    
      <label for="message">Message *</label>
      <textarea id="message" name="message" rows="5"></textarea>
      <div id="error-message" class="error"></div>
    
      <button type="submit">Submit</button>
      <div id="formSuccess" class="success"></div>
    </form>

<pre>
    
    https://cdn.jsdelivr.net/npm/zod@3.23.2/lib/index.umd.min.js

      const { z } = window.zod;
    
      // Define schema for validation
      const contactSchema = z.object({
        name: z.string().min(2, "Name must be at least 2 characters"),
        email: z.string().email("Invalid email address"),
        message: z.string().min(5, "Message must be at least 5 characters"),
      });
    
      const form = document.getElementById("contactForm");
      const successDiv = document.getElementById("formSuccess");
    
      form.addEventListener("submit", function (e) {
        e.preventDefault();
    
        // Clear previous errors
        ["name", "email", "message"].forEach(id => {
          document.getElementById(`error-${id}`).textContent = "";
        });
        successDiv.textContent = "";
    
        // Collect form data
        const formData = {
          name: form.name.value.trim(),
          email: form.email.value.trim(),
          message: form.message.value.trim(),
        };
    
        // Validate
        const result = contactSchema.safeParse(formData);
    
        if (!result.success) {
          // Show errors
          result.error.errors.forEach(err => {
            const el = document.getElementById(`error-${err.path[0]}`);
            if (el) el.textContent = err.message;
          });
        } else {
          // Valid submission
          successDiv.textContent = "Thank you for contacting us!";
          form.reset();
        }
      });
    </pre>   


</div>
</li>













<li data-id="q32" class="yellow"><span class="faq-question">
----------------------------------------------------------------------------------
</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">
------------------------------------TypeScript------------------------------------
</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">
----------------------------------------------------------------------------------
</span></li>
    





  <li data-id="typescriptqq" class="yellow"><span class="faq-question">
    TypeScript Question
  </span><div class="answer">
    <ol>
      <li><b>Basic TypeScript Questions</b>
  
          <li>What is TypeScript? How is it different from JavaScript?</li>
          <li>What are the benefits of using TypeScript?</li>
          <li>How do you compile TypeScript to JavaScript?</li>
          <li>What is the tsconfig.json file?</li>
          <li>What are basic types in TypeScript?</li>
          <li>What is type inference?</li>
          <li>What is the difference between any, unknown, and never?</li>
          <li>How do you define arrays in TypeScript?</li>
          <li>How do you define a tuple in TypeScript?</li>
          <li>What is the difference between interface and type?</li>
          <li>How do enums work in TypeScript?</li>
          <li>What is a union type?</li>
          <li>What is an intersection type?</li>
          <li>What is a literal type?</li>
          <li>What are optional and default parameters?</li>
  
  
    
      <li><strong>Intermediate TypeScript Questions</strong>
       
          <li>How do you define and use generics in TypeScript?</li>
          <li>What are generic constraints?</li>
          <li>What is a mapped type?</li>
          <li>What is a conditional type?</li>
          <li>What is a utility type? Give examples like Partial, Pick, Omit.</li>
          <li>What is the difference between readonly and const?</li>
          <li>How does keyof work in TypeScript?</li>
          <li>What is type assertion?</li>
          <li>What is type narrowing?</li>
          <li>What are declaration files (.d.ts) and when are they used?</li>
          <li>How do you use third-party libraries in TypeScript?</li>
          <li>What is the as keyword used for?</li>
          <li>How do you handle dynamic object keys in TypeScript?</li>
          <li>What is the difference between private, public, and protected modifiers?</li>
          <li>How does TypeScript support abstract classes?</li>
        
  
    
      <li><strong>Advanced TypeScript Questions</strong>
       
          <li>What is structural typing?</li>
          <li>What is type compatibility in TypeScript?</li>
          <li>How does TypeScript perform compile-time vs runtime checks?</li>
          <li>What is module augmentation?</li>
          <li>How do you merge interfaces?</li>
          <li>What are declaration merging and function overloading?</li>
          <li>How do you create custom utility types?</li>
          <li>What is the infer keyword used for in conditional types?</li>
          <li>What are recursive types?</li>
          <li>How do you write a type-safe React component with TypeScript?</li>
          <li>How does TypeScript support mixins?</li>
          <li>What are discriminated unions and how do they work?</li>
          <li>How do you model JSON APIs in TypeScript types?</li>
          <li>How can TypeScript be used for functional programming?</li>
          <li>What are template literal types?</li>
        
   
    
      <li><strong>TypeScript + Tools/Frameworks</strong>
       
          <li>How do you integrate TypeScript with Node.js?</li>
          <li>How is TypeScript used with Express?</li>
          <li>What are the benefits of using TypeScript with React?</li>
          <li>How do you type props and state in React components?</li>
          <li>How does Next.js handle TypeScript?</li>
          <li>How do you use TypeScript in a monorepo (e.g., with Turborepo or Nx)?</li>
          <li>How does TypeScript work with Jest or testing libraries?</li>
          <li>What is the role of ESLint and Prettier with TypeScript?</li>
          <li>How does Webpack/Babel handle TypeScript?</li>
          <li>What are best practices for organizing TypeScript codebases?</li>
        
    
    </ol>
  
    </div></li>




    <li data-id="q1ddd">
      <span class="faq-question">What is TypeScript? How is it different from JavaScript?</span>
      <div class="answer">
        TypeScript is a statically typed superset of JavaScript that adds type safety and other powerful features like interfaces, enums, and generics. Unlike JavaScript, TypeScript code must be compiled to JavaScript before it runs in the browser or Node.js.
      </div>
    </li>
    
    <li data-id="q2">
      <span class="faq-question">What are the benefits of using TypeScript?</span>
      <div class="answer">
        TypeScript improves code quality and maintainability by enabling type safety, better IDE support, early error detection, and features from modern JavaScript (ES6+) before they‚Äôre fully supported in all environments.
      </div>
    </li>
    
    <li data-id="q3">
      <span class="faq-question">How do you compile TypeScript to JavaScript?</span>
      <div class="answer">
        <code>
        You compile TypeScript to JavaScript using the <b>tsc</b> (TypeScript compiler) command in the terminal: <b>tsc filename.ts</b>. <br />
        It generates a <b>.js</b> file from the <b>.ts</b> source.
      </code>
      </div>
    </li>
    
    <li data-id="q4">
      <span class="faq-question">What is the <b>tsconfig.json</b> file?</span>
      <div class="answer">
        <code>tsconfig.json : is a configuration file used by the TypeScript compiler to define compiler options, root files, and module resolution settings. It enables easy project-wide compilation and setup.
        </code>
      </div>
    </li>
    
    <li data-id="q5">
        <span class="faq-question green ">What are basic types in TypeScript?</span>
        <div class="answer">
          <code>
          These types provide static typing to variables and function return values.<br />
          Basic types in TypeScript include 
          <ol>
              <li>number</li>
              <li>string</li>
              <li>boolean</li>
              <li>null</li>
              <li>undefined</li>
              <li>symbol</li>
              <li>bigint</li>
            </ol> 
          </code>
        </div>
      </li>
      
      <li data-id="q6">
        <span class="faq-question">What is type inference?</span>
        <div class="answer">
          <code>
          Type inference is TypeScript‚Äôs ability to automatically determine the type of a variable when no explicit type is provided. For example, <br>
          let x = 5; : infers that <b class="green">x is of type number</b>.
        </code>
        </div>
      </li>
      
      <li data-id="q7">
        <span class="faq-question">What is the difference between <b>any</b>, <b>unknown</b>, and <b>never</b>?</span>
        <div class="answer">
          <ol>
            <li><strong>any</strong>: Turns off type checking. Use with caution.</li>
            <li><strong>unknown</strong>: Similar to <b>any</b>, but safer ‚Äî you must perform type checks before using it.</li>
            <li><strong>never</strong>: Represents values that never occur, such as functions that throw errors or infinite loops.</li>
          </ol>
        </div>
      </li>
      
      <li data-id="q8">
        <span class="faq-question">How do you define arrays in TypeScript?</span>
        <div class="answer">
          Arrays can be defined in two ways: Both declare an array of numbers.
          <code>
            let arr: number[] = [1, 2, 3];<br />
            let arr: Array&lt;number&gt; = [1, 2, 3];
          </code> 
        </div>
      </li>
      <li data-id="q9">
        <span class="faq-question">How do you define a tuple in TypeScript?</span>
        <div class="answer">
          A tuple in TypeScript is an array with fixed number of elements and specific types at each position. Example: 
          <code>let user: [string, number] = ["Alice", 30];</code>
        </div>
      </li>
      
      <li data-id="q10">
        <span class="faq-question green ">
          What is the difference between <b>interface</b> and <b>type</b>?
        </span>
        <div class="answer">
          <code>
            Both interface and type can define the shape of an object
            <br />
            Interface : is extendable and better for object-oriented design. <br />
            Interfaces support declaration merging
            <br /><br />
            Type is more flexible for unions, intersections, and primitives.<br>
            Type  do not support declaration merging
          </code>
<pre>
  // interface: Good for defining object/class shapes
  interface User {
    id: number;
    name: string;
  }
  
  // type: Good for combining types, union, or primitives
  type Status = 'active' | 'inactive';
  
  type Product = {
    id: number;
    price: number;
  };
  
</pre>          
        </div>
      </li>
      
      <li data-id="q11">
        <span class="faq-question">How do enums work in TypeScript?</span>
        <div class="answer">
          Enums allow you to define a set of named constants. Example:
          <pre><code>enum Direction { Up, Down, Left, Right }</code></pre>
          By default, they are auto-incremented numbers, but can also be assigned specific values (e.g., strings).
        </div>
      </li>
      
      <li data-id="q12">
        <span class="faq-question">What is a union type?</span>
        <div class="answer">
          A union type allows a variable to hold more than one type. Example:
          <code>let value: string | number;</code> means <code>value</code> can be either a string or a number.
        </div>
      </li>
    
      
      <li data-id="q13">
        <span class="faq-question">What is an intersection type?</span>
        <div class="answer">
          An intersection type combines multiple types into one. The resulting type has all properties from the intersected types. Example: 
<pre>
  type Admin      = { role: string };
  type User       = { name: string }; 
  type AdminUser  = Admin & User;
</pre>
        </div>
      </li>
      
      <li data-id="q14">
        <span class="faq-question">What is a literal type?</span>
        <div class="answer">
<pre>
  A literal type allows a variable to accept only a specific value. Example: <br />
  let direction: "up" | "down"; ‚Äî the variable can only be <b>"up"</b> or <b>"down"</b>
</pre>
          
        </div>
      </li>
      
      <li data-id="q15">
        <span class="faq-question">What are optional and default parameters?</span>
        <div class="answer">
          Optional parameters are marked with a <b>?</b> and may be omitted when calling the function. Default parameters provide a fallback value. <br /><br />
          Example: <br />
          <b>function greet(name: string = "Guest") { console.log("Hello, " + name); }</b>
        </div>
      </li>
      
      <li data-id="q16">
        <span class="faq-question">How do you define and use generics in TypeScript?</span>
        <div class="answer">
          Generics allow you to create reusable components that work with any type. Example:
          <code>function identity&lt;T&gt;(arg: T): T { return arg; }</code> ‚Äî Here, <code>T</code> is a placeholder for any type passed when the function is called.
        </div>
      </li>
      
    
      <li data-id="q17">
        <span class="faq-question">What are generic constraints?</span>
        <div class="answer">
          Generic constraints restrict the kinds of types that can be used as generic arguments. You use <code>extends</code> to define a constraint. Example:
          <code>function getLength&lt;T extends { length: number }&gt;(item: T): number { return item.length; }</code>
        </div>
      </li>
      
      <li data-id="q18">
        <span class="faq-question">What is a mapped type?</span>
        <div class="answer">
          A mapped type creates new types by transforming properties of an existing type. Example:
          <code>type Readonly&lt;T&gt; = { readonly [K in keyof T]: T[K] }</code> ‚Äî this makes all properties of <code>T</code> readonly.
        </div>
      </li>
      
      <li data-id="q19">
        <span class="faq-question">What is a conditional type?</span>
        <div class="answer">
          A conditional type uses the <code>extends</code> keyword to choose one type over another. Example:
          <code>type IsString&lt;T&gt; = T extends string ? "Yes" : "No";</code> ‚Äî evaluates to <code>"Yes"</code> if <code>T</code> is a string, otherwise <code>"No"</code>.
        </div>
      </li>
      



      <li data-id="q40">
        <span class="faq-question green">What is a utility type? Give examples like <b>Partial</b>, <b>Pick</b>, and <b>Omit</b>? &nbsp; &nbsp;    **********</span>
        <div class="answer">
          <p><strong>Utility types</strong> in TypeScript are built-in generic types that help transform or construct new types from existing ones. They simplify type manipulation and increase code reusability.</p>
      
<h4>üß∞ Common Utility Types</h4>
<pre>
  1. <b>Partial&lt;T&gt;</b>
  Makes all properties in <b>T</b> optional.
  
  interface User {
    id: number;
    name: string;
    email: string;
  }
  
  const updateUser = (user: Partial&lt;User&gt;) =&gt; {
    // user may have any subset of User fields
  };
</pre>


<pre>

  2. <b>Pick&lt;T, K&gt;</b>
  Constructs a type by picking a set of properties <b>K</b> from <b>T</b>.

  <b>type UserSummary = Pick&lt;User, 'id' | 'name'&gt;;</b>
  const summary: UserSummary = {
    id: 1,
    name: "Alice"
  };
  
</pre>      

<pre>
  3. <b>Omit&lt;T, K&gt;</b>
  Constructs a type by omitting property keys <b>K</b> from type <b>T</b>.

  <b>type UserWithoutEmail = Omit&lt;User, 'email'&gt;;</b>
  const user: UserWithoutEmail = {
    id: 1,
    name: "Bob"
  };
</pre>
  
      <h4>üß† Other Utility Types</h4>
      <ul>
        <li><b>Readonly&lt;T&gt;</b> ‚Äì Makes all properties readonly.</li>
        <li><b>Record&lt;K, T&gt;</b> ‚Äì Constructs an object type with keys of type <b>K</b> and values of type <b>T</b>.</li>
        <li><b>Required&lt;T&gt;</b> ‚Äì Makes all properties required.</li>
        <li><b>Exclude&lt;T, U&gt;</b> ‚Äì Excludes from <b>T</b> those types that are assignable to <b>U</b>.</li>
        <li><b>Extract&lt;T, U&gt;</b> ‚Äì Extracts from <b>T</b> those types that are assignable to <b>U</b>.</li>
      </ul>
  
      <h4>üìå Summary</h4>
      <ul>
        <li>Utility types are part of TypeScript‚Äôs standard library.</li>
        <li>They simplify working with types and reduce boilerplate.</li>
        <li>Ideal for creating flexible, reusable interfaces.</li>
      </ul>
      
      <p>Use utility types to write clean, DRY, and maintainable type-safe code in TypeScript.</p>



          
        </div>
      </li>
      


      <li data-id="q21">
        <span class="faq-question green ">What is the difference between <b>readonly</b> and <b>const</b>?</span>
        <div class="answer">
<pre>
  <b>const</b> is used for variables to prevent reassignment, 
  <b>const</b> applies to bindings

  <b>readonly</b> is used on properties of objects or classes to prevent them from being changed after initialization. 
  <b>readonly</b> applies to object members.
</pre>
        </div>
      </li>
      
      <li data-id="q22">
        <span class="faq-question">How does <b>keyof</b> work in TypeScript?</span>
        <div class="answer">
<pre>
  <b>keyof</b> is a type operator that returns a union of all property names of a type. Example: 
  <b>type Person = { name: string; age: number }; type Keys = keyof Person;</b> results in <b>"name" | "age"</b>.
</pre>
        </div>
      </li>
      
      <li data-id="q23">
        <span class="faq-question">What is type assertion?</span>
        <div class="answer">
          Type assertion tells the compiler to treat a value as a specific type, without changing its runtime behavior. Syntax: <code>&lt;Type&gt;value</code> or <code>value as Type</code>. Example: <code>let name = value as string;</code>
        </div>
      </li>
      
      <li data-id="q24">
        <span class="faq-question">What is type narrowing?</span>
        <div class="answer">
          Type narrowing is the process of refining a variable's type within a conditional block using checks like <code>typeof</code>, <code>instanceof</code>, or equality checks. It helps TypeScript infer a more specific type.
        </div>
      </li>
      
      <li data-id="q25">
        <span class="faq-question">What are declaration files (.d.ts) and when are they used?</span>
        <div class="answer">
          Declaration files provide type information about JavaScript code, allowing TypeScript to understand the shape of non-TypeScript libraries. They're used when consuming JavaScript or third-party modules without native TypeScript support.
        </div>
      </li>
      
      <li data-id="q26">
        <span class="faq-question">How do you use third-party libraries in TypeScript?</span>
        <div class="answer">
          Install the library and its type definitions using <code>npm install library-name</code> and <code>npm install --save-dev @types/library-name</code>. Then import it normally in your TypeScript file.
        </div>
      </li>
      
      <li data-id="q27">
        <span class="faq-question green  ">What is the <b>as</b> keyword used for?</span>
        <div class="answer">
  The <b>as</b> keyword is used for type assertions to explicitly tell the TypeScript compiler the type of a variable. <br /> <br />
  Example: <b>let value = input as string;</b>
        </div>
      </li>
      
      <li data-id="q28">
        <span class="faq-question">How do you handle dynamic object keys in TypeScript?</span>
        <div class="answer">
          Use index signatures or mapped types to type dynamic keys. Example: <code>{ [key: string]: number }</code> allows any string key with number values.
        </div>
      </li>
      
      <li data-id="q29">
        <span class="faq-question">What is the difference between private, public, protected modifiers?</span>
        <div class="answer">
          <ul>
            <li><strong>public</strong>: Members are accessible from anywhere (default).</li>
            <li><strong>private</strong>: Members are accessible only within the class.</li>
            <li><strong>protected</strong>: Members are accessible within the class and its subclasses.</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q30">
        <span class="faq-question">How does TypeScript support abstract classes?</span>
        <div class="answer">
          TypeScript allows defining abstract classes using the <code>abstract</code> keyword. These classes cannot be instantiated directly and may contain abstract methods that must be implemented by subclasses.
        </div>
      </li>
      
      <li data-id="q31">
        <span class="faq-question">What is structural typing?</span>
        <div class="answer">
          Structural typing means that type compatibility is based on the shape (structure) of types, not their explicit declarations. If two objects have the same shape, they're considered the same type.
        </div>
      </li>
      
      <li data-id="q32">
        <span class="faq-question">What is type compatibility in TypeScript?</span>
        <div class="answer">
          Type compatibility determines whether one type can be assigned to another. TypeScript uses structural typing to check compatibility ‚Äî if one type has all the required properties of another, it is considered compatible.
        </div>
      </li>
      
      <li data-id="q33">
        <span class="faq-question green ">How does TypeScript perform compile-time vs runtime checks?</span>
        <div class="answer">
          <p><strong>TypeScript</strong> focuses <strong>heavily on compile-time checks</strong> and <strong>does not perform runtime checks by default</strong>. Here's a clear breakdown:</p>
      
          <h4>‚úÖ Compile-Time Checks (Static Type Checking)</h4>
          <p>TypeScript performs <strong>static type checking</strong> during development, before the code runs.</p>
          <ul>
            <li>Checks for type mismatches</li>
            <li>Ensures correct property access</li>
            <li>Validates function signatures</li>
            <li>Supports type inference, interfaces, generics, etc.</li>
          </ul>
          <pre><code>let age: number = "30"; // ‚ùå Compile-time error</code></pre>
      
          <h4>‚ùå Runtime Checks</h4>
          <p>TypeScript <strong>does not enforce types at runtime</strong>. The compiled JavaScript contains no type information.</p>
          <pre><code>function add(a: number, b: number) {
        return a + b;
      }
      
      add("5", "10"); // Compiles but can cause issues at runtime if type checks are bypassed
      </code></pre>
          <p>To enforce runtime checks, you must add them manually:</p>
          <pre><code>function add(a: any, b: any) {
        if (typeof a !== 'number' || typeof b !== 'number') {
          throw new Error('Invalid input');
        }
        return a + b;
      }</code></pre>
      
          <h4>üîÑ Summary: Compile-Time vs Runtime</h4>
          <table border="1" cellpadding="4" cellspacing="0">
            <thead>
              <tr>
                <th>Feature</th>
                <th>Compile-Time (TypeScript)</th>
                <th>Runtime (JavaScript)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Type checking</td>
                <td>‚úÖ Yes</td>
                <td>‚ùå No</td>
              </tr>
              <tr>
                <td>Catches early errors</td>
                <td>‚úÖ Yes</td>
                <td>‚ùå No</td>
              </tr>
              <tr>
                <td>Code emitted</td>
                <td>üö´ No types</td>
                <td>‚úÖ Pure JS</td>
              </tr>
              <tr>
                <td>Performance impact</td>
                <td>‚ùå None</td>
                <td>‚úÖ If checks added</td>
              </tr>
              <tr>
                <td>Needs extra libs?</td>
                <td>‚ùå No</td>
                <td>‚úÖ Yes (e.g. zod, io-ts)</td>
              </tr>
            </tbody>
          </table>
      
          <h4>üõ†Ô∏è Optional Runtime Type Checking Tools:</h4>
          <ul>
            <li><a href="https://github.com/colinhacks/zod" target="_blank">zod</a></li>
            <li><a href="https://github.com/gcanti/io-ts" target="_blank">io-ts</a></li>
            <li><a href="https://github.com/pelotom/runtypes" target="_blank">runtypes</a></li>
          </ul>
      
          <p>Example using <code>zod</code>:</p>
          <pre><code>import { z } from "zod";
      
      const userSchema = z.object({
        name: z.string(),
        age: z.number(),
      });
      
      userSchema.parse({ name: "John", age: "30" }); // ‚ùå Throws at runtime</code></pre>
        </div>
      </li>
      
      
      <li data-id="q34">
        <span class="faq-question">What is module augmentation?</span>
        <div class="answer">
          Module augmentation allows you to extend existing modules by adding new declarations (like interfaces, functions) without modifying the original module code, using <code>declare module</code> syntax.
        </div>
      </li>
      

      

      <li data-id="q33">
        <span class="faq-question  green">How do you merge interfaces?</span>
        <div class="answer">
          <p><strong>TypeScript</strong> supports <strong>interface merging</strong>, which allows you to declare the same interface name multiple times, and TypeScript will automatically merge their members.</p>
      
          <h4>üîß Syntax Example</h4>
          <pre><code>interface User {
        name: string;
      }
      
      interface User {
        age: number;
      }
      
      const person: User = {
        name: "Alice",
        age: 30,
      };</code></pre>
          <p>‚úÖ The <code>User</code> interface now has both <code>name</code> and <code>age</code> fields after merging.</p>
      
          <h4>üìå Key Rules of Interface Merging</h4>
          <ul>
            <li><strong>Properties are combined</strong>: different members are merged.</li>
            <li><strong>Conflicting property types cause an error</strong>:</li>
          </ul>
          <pre><code>interface A {
        id: number;
      }
      
      interface A {
        id: string; // ‚ùå Error: Duplicate identifier 'id'
      }</code></pre>
      
          <ul>
            <li><strong>Function overloads are merged in order</strong>: the last declared comes first in overload list.</li>
          </ul>
          <pre><code>interface Logger {
        log(message: string): void;
      }
      
      interface Logger {
        log(message: string, level: string): void;
      }
      
      const logger: Logger = {
        log(message: string, level?: string) {
          console.log(level ? `[${level}] ${message}` : message);
        },
      };</code></pre>
      
          <h4>üì¶ Use Cases</h4>
          <ul>
            <li>Merging declarations from external libraries</li>
            <li>Extending DOM or NodeJS types (e.g., <code>Window</code>, <code>Request</code>)</li>
            <li>Spreading interface definitions across modular files</li>
          </ul>
      
          <h4>‚ùó Notes</h4>
          <ul>
            <li>Only <code>interface</code> declarations support merging. <code>type</code> aliases do <strong>not</strong>.</li>
            <li>For module-based merging, use <strong>module augmentation</strong>.</li>
          </ul>
        </div>
      </li>
      


      <li data-id="q36">
        <span class="faq-question">What are declaration merging and function overloading?</span>
        <div class="answer">
          <ul>
            <li><strong>Declaration merging</strong>: Combining multiple declarations (interfaces, namespaces) with the same name into one.</li>
            <li><strong>Function overloading</strong>: Defining multiple function signatures for a single implementation to handle different argument types.</li>
          </ul>
        </div>
      </li>
    
      
      <li data-id="q37">
        <span class="faq-question">How do you create custom utility types?</span>
        <div class="answer">
          You create custom utility types using TypeScript‚Äôs advanced type features like mapped types, conditional types, and type inference. For example, to create a type that makes all properties readonly except a few:
          <pre><code>type MyReadonly&lt;T, K extends keyof T&gt; = { readonly [P in Exclude&lt;keyof T, K&gt;]: T[P] } &amp; { [P in K]: T[P] };</code></pre>
        </div>
      </li>
      
      <li data-id="q38">
        <span class="faq-question green">What is the infer keyword used for in conditional types?</span>
        <div class="answer">
          <p>The <b>infer</b> keyword in TypeScript is used within <strong>conditional types</strong> to declare a type variable that you can extract from another type. It's useful for <strong>type inference</strong> when you want to extract part of a type inside a conditional expression.</p>
      
          <h4>üìò Syntax</h4>
          <pre><code>type Example&lt;T&gt; = T extends SomeType&lt;infer U&gt; ? U : never;</code></pre>
      
          <h4>üîç Example: Extract Return Type</h4>
          <pre><code>type GetReturnType&lt;T&gt; = T extends (...args: any[]) =&gt; infer R ? R : never;
      
      type MyFunc = (x: number) =&gt; string;
      
      type Result = GetReturnType&lt;MyFunc&gt;; // Result is string</code></pre>
      
          <p>In this example, <b>infer R</b> captures the return type of the function type <b>T</b>.</p>
      
          <h4>üîß Another Example: Extract Array Element Type</h4>
          <pre><code>type ElementType&lt;T&gt; = T extends (infer U)[] ? U : T;
      
      type A = ElementType&lt;string[]&gt;; // A = string
      type B = ElementType&lt;number&gt;;   // B = number</code></pre>
      
          <h4>üìå Summary</h4>
          <ul>
            <li><b>infer</b> is only used within conditional types.</li>
            <li>It allows you to extract and work with parts of complex types.</li>
            <li>It's commonly used to create utility types like <b>ReturnType&lt;&gt;</b> or <b>Parameters&lt;&gt;</b>.</li>
          </ul>
      
          <p>The <b>infer</b> keyword provides powerful type manipulation capabilities, enabling advanced type-level programming in TypeScript.</p>
        </div>
      </li>
      
      
      <li data-id="q39">
        <span class="faq-question">What are recursive types?</span>
        <div class="answer">
          Recursive types are types that refer to themselves in their own definition, useful for modeling nested or hierarchical data structures. Example:
          <pre><code>type JSONValue = string | number | boolean | JSONObject | JSONArray;
      type JSONObject = { [key: string]: JSONValue };
      type JSONArray = JSONValue[];</code></pre>
        </div>
      </li>
      <li data-id="q39">
        <span class="faq-question green">What are recursive types?</span>
        <div class="answer">
          <p><strong>Recursive types</strong> in TypeScript are types that reference themselves. They are useful for representing data structures that are inherently recursive, such as trees, JSON, or linked lists.</p>
      
          <h4>üîÅ Why use recursive types?</h4>
          <p>Recursive types enable modeling of nested or hierarchical data where the same shape repeats within itself.</p>
      
          <h4>üå≤ Example: Tree Structure</h4>
          <pre><code>type TreeNode = {
        value: string;
        children?: TreeNode[]; // Reference to the same type
      };</code></pre>
      
          <h4>üìÑ Sample Usage</h4>
          <pre><code>const tree: TreeNode = {
        value: 'Root',
        children: [
          { value: 'Child 1' },
          { 
            value: 'Child 2', 
            children: [
              { value: 'Grandchild' }
            ] 
          }
        ]
      };</code></pre>
      
          <h4>üîÅ Example: Recursive JSON Type</h4>
          <pre><code>type JSONValue =
        | string
        | number
        | boolean
        | null
        | JSONValue[]
        | { [key: string]: JSONValue };</code></pre>
      
          <p>This <code>JSONValue</code> type is a recursive type that mimics valid JSON data.</p>
      
          <h4>üìå Key Points</h4>
          <ul>
            <li>Recursive types are types that refer to themselves directly or indirectly.</li>
            <li>They are powerful for modeling tree-like or nested data structures.</li>
            <li>Be cautious of infinite recursion‚ÄîTypeScript can hit complexity limits if the nesting is too deep.</li>
          </ul>
      
          <p>Recursive types unlock advanced typing capabilities in TypeScript, making your code safer and more expressive when dealing with complex data.</p>
        </div>
      </li>
      
      <li data-id="q40">
        <span class="faq-question">How do you write a type-safe React component with TypeScript?</span>
        <div class="answer">
          Define prop types using interfaces or types and use them in function components. Example:
          <pre><code>interface ButtonProps { label: string; onClick: () =&gt; void; }
      const Button: React.FC&lt;ButtonProps&gt; = ({ label, onClick }) =&gt; (&lt;button onClick={onClick}&gt;{label}&lt;/button&gt;);</code></pre>
        </div>
      </li>
      
    
      <li data-id="q41">
        <span class="faq-question">How does TypeScript support mixins?</span>
        <div class="answer">
          TypeScript supports mixins by allowing classes to be composed from multiple base classes using functions that extend a class with additional properties or methods. Example pattern:
          <pre><code>function Timestamped&lt;T extends Constructor&gt;(Base: T) {
        return class extends Base {
          timestamp = Date.now();
        };
      }</code></pre>
        </div>
      </li>
      
      <li data-id="q42">
        <span class="faq-question">What are discriminated unions and how do they work?</span>
        <div class="answer">
          Discriminated unions combine multiple types into one union type with a common literal property (the discriminant) to safely narrow the type. Example:
          <pre><code>type Shape =
        | { kind: "circle"; radius: number }
        | { kind: "square"; size: number };
      
      function area(s: Shape) {
        if (s.kind === "circle") return Math.PI * s.radius ** 2;
        else return s.size ** 2;
      }</code></pre>
        </div>
      </li>
      
      <li data-id="q43">
        <span class="faq-question">How do you model JSON APIs in TypeScript types?</span>
        <div class="answer">
          You define interfaces or types matching the API‚Äôs JSON schema, often using recursive and optional properties to reflect nested or partial data. Tools like <code>quicktype</code> can generate these automatically.
        </div>
      </li>
      
      <li data-id="q44">
        <span class="faq-question">How can TypeScript be used for functional programming?</span>
        <div class="answer">
          TypeScript‚Äôs strong typing supports functional programming by enabling typed higher-order functions, immutability, algebraic data types, and pure functions, improving safety and maintainability.
        </div>
      </li>
      
    
      <li data-id="q45">
        <span class="faq-question">What are template literal types?</span>
        <div class="answer">
          Template literal types allow creating string literal types by embedding unions inside string templates. They enable powerful string type manipulations. Example:
          <pre><code>type Greeting = `Hello, ${string}!`;</code></pre>
        </div>
      </li>
      
      <li data-id="q46">
        <span class="faq-question">How do you integrate TypeScript with Node.js?</span>
        <div class="answer">
          You set up a <code>tsconfig.json</code>, write TypeScript code, compile it to JavaScript using <code>tsc</code>, and run with Node.js. Tools like <code>ts-node</code> allow running TypeScript directly during development.
        </div>
      </li>

      <li data-id="q33">
        <span class="faq-question green">How to build a TypeScript Book CRUD API with routes?</span>
        <div class="answer">
<pre>
  This example demonstrates a basic REST API using <strong>Express.js</strong> and <strong>TypeScript</strong>.
  To perform CRUD operations on a <b>Book</b> object (with <b>id</b> and <b>title</b>).
  This setup provides a full-featured Book CRUD API using TypeScript and Express, with type-safe request and response handling.

  <b>üì¶ Install Dependencies</b>
  npm install express
  npm install -D typescript ts-node @types/express @types/node
      
  <b>‚öôÔ∏è tsconfig.json (minimal)</b>
  {
    "compilerOptions": {
      "target": "ES6",
      "module": "commonjs",
      "rootDir": "./src",
      "outDir": "./dist",
      "esModuleInterop": true,
      "strict": true
    }
  }

      
  <b>üöÄ Express Routes (src/index.ts)</b>
  import express, { Request, Response } from 'express';

  const app = express();
  app.use(express.json());
      
  interface Book {
    id: number;
    title: string;
  }
  
  let books: Book[] = [];
  let nextId = 1;
  
  // Create
  app.post('/books', (req: Request, res: Response) => {
    const { title } = req.body;
    const book: Book = { id: nextId++, title };
    books.push(book);
    res.status(201).json(book);
  });
  
  // Read All
  app.get('/books', (req: Request, res: Response) => {
    res.json(books);
  });
  
  // Read by ID
  app.get('/books/:id', (req: Request, res: Response) => {
    const book = books.find(b => b.id === Number(req.params.id));
    if (!book) return res.status(404).send('Book not found');
    res.json(book);
  });
  
  // Update
  app.put('/books/:id', (req: Request, res: Response) => {
    const book = books.find(b => b.id === Number(req.params.id));
    if (!book) return res.status(404).send('Book not found');
    book.title = req.body.title;
    res.json(book);
  });
  
  // Delete
  app.delete('/books/:id', (req: Request, res: Response) => {
    const index = books.findIndex(b => b.id === Number(req.params.id));
    if (index === -1) return res.status(404).send('Book not found');
    books.splice(index, 1);
    res.sendStatus(204);
  });
  
  const PORT = 3000;
  app.listen(PORT, () => console.log(`üöÄ Server running on http://localhost:${PORT}`));
</pre>
<pre>
  <b>üß™ Test Using curl or Postman</b>
  # Create a book
  curl -X POST http://localhost:3000/books -H "Content-Type: application/json" -d '{"title":"TypeScript Handbook"}'

  # Get all books
  curl http://localhost:3000/books

  # Update a book
  curl -X PUT http://localhost:3000/books/1 -H "Content-Type: application/json" -d '{"title":"Updated Title"}'

  # Delete a book
  curl -X DELETE http://localhost:3000/books/1

</pre>
</div>
<div class="answer">
<pre>
  This example demonstrates a simple in-memory CRUD (Create, Read, Update, Delete) for <strong>Book</strong> objects in <strong>TypeScript</strong>. 
  Each book has an <b>id</b> and <b>title</b>. This basic CRUD structure is ideal for learning TypeScript's type safety with object manipulation. 
  In a real app, you'd replace the in-memory store with a database.

  <b>üìò Book Interface</b>
  interface Book {
    id: number;
    title: string;
  }


  <b>üìö In-Memory Book Store</b>
  let books: Book[] = []; // Simulated database
  let nextId = 1;


  <b>‚úÖ Create a Book</b>
  function createBook(title: string): Book {
    const book: Book = { id: nextId++, title };
    books.push(book);
    return book;
  }


  <b>üìñ Read All Books</b>
  function getAllBooks(): Book[] {
    return books;
  }


  <b>üîç Read a Book by ID</b>
  function getBookById(id: number): Book | undefined {
    return books.find(book => book.id === id);
  }


  <b>‚úèÔ∏è Update a Book</b>
  function updateBook(id: number, newTitle: string): Book | undefined {
    const book = books.find(b => b.id === id);
    if (book) {
      book.title = newTitle;
    }
    return book;
  }

  <b>üóëÔ∏è Delete a Book</b>
  function deleteBook(id: number): boolean {
    const index = books.findIndex(b => b.id === id);
    if (index !== -1) {
      books.splice(index, 1);
      return true;
    }
    return false;
  }

  <b>‚ñ∂Ô∏è Example Usage</b>
  createBook("The Hobbit");
  createBook("1984");
  console.log(getAllBooks());
  updateBook(1, "The Hobbit: Revised Edition");
  console.log(getBookById(1));
  deleteBook(2);
  console.log(getAllBooks());
</pre>

          
        </div>
      </li>
      




      
      <li data-id="q47">
        <span class="faq-question">How is TypeScript used with Express?</span>
        <div class="answer">
          TypeScript enhances Express apps by adding type safety to request, response, and middleware objects. Install <code>@types/express</code> for typings and write route handlers with typed parameters.
        </div>
      </li>
      
      <li data-id="q33">
        <span class="faq-question green">How is TypeScript used with Express?</span>
        <div class="answer">
          <p><strong>TypeScript</strong> is used with <strong>Express.js</strong> to add static typing and improve developer experience. It helps catch errors at compile time, enables better IntelliSense, and improves code maintainability.</p>
      
          <h4>üöÄ Key Benefits</h4>
          <ul>
            <li>Type-safe request/response handling</li>
            <li>Autocomplete and error checking in IDEs</li>
            <li>Clear interfaces and types for middleware, routes, and data</li>
          </ul>
      
          <h4>üîß Basic Setup Steps</h4>
          <ol>
            <li>Initialize project:
              <pre><code>npm init -y</code></pre>
            </li>
            <li>Install dependencies:
              <pre><code>npm install express
      npm install -D typescript ts-node @types/node @types/express</code></pre>
            </li>
            <li>Create a <code>tsconfig.json</code>:
              <pre><code>{
        "compilerOptions": {
          "target": "ES6",
          "module": "commonjs",
          "rootDir": "./src",
          "outDir": "./dist",
          "esModuleInterop": true,
          "strict": true
        }
      }</code></pre>
            </li>
            <li>Write Express app in TypeScript:</li>
          </ol>
      
          <h4>üìÑ <code>src/index.ts</code></h4>
          <pre><code>import express, { Request, Response } from 'express';
      
      const app = express();
      const PORT = 3000;
      
      app.get('/', (req: Request, res: Response) => {
        res.send('Hello from TypeScript & Express!');
      });
      
      app.listen(PORT, () => {
        console.log(`Server is running at http://localhost:${PORT}`);
      });</code></pre>
      
          <h4>‚ñ∂Ô∏è Run the app:</h4>
          <pre><code>npx ts-node src/index.ts</code></pre>
      
          <h4>üß† Notes</h4>
          <ul>
            <li>Use <code>@types/express</code> for full type definitions.</li>
            <li>Use interfaces to type request bodies, params, and query strings for stronger typing.</li>
            <li>Optionally compile to JavaScript using <code>tsc</code> and run with Node.js.</li>
          </ul>
      
          <h4>üì¶ Common Patterns</h4>
          <ul>
            <li>Using <code>interface</code> for typed request bodies</li>
            <li>Typed middleware functions</li>
            <li>Separating route handlers into modules with types</li>
          </ul>
        </div>
      </li>
      




      <li data-id="q48">
        <span class="faq-question">What are the benefits of using TypeScript with React?</span>
        <div class="answer">
          Benefits include type safety for props and state, better IDE autocompletion, earlier error detection, and improved maintainability and refactoring support.
        </div>
      </li>
    
      
      <li data-id="q49">
        <span class="faq-question">How do you type props and state in React components?</span>
        <div class="answer">
          You define interfaces or types for props and state, then use them in function or class components. Example for function components:
          <pre><code>interface Props { title: string; }
      const MyComponent: React.FC&lt;Props&gt; = ({ title }) =&gt; &lt;div&gt;{title}&lt;/div&gt;;</code></pre>
        </div>
      </li>
      
      <li data-id="q50">
        <span class="faq-question">How does Next.js handle TypeScript?</span>
        <div class="answer">
          Next.js has built-in TypeScript support. Adding a <code>tsconfig.json</code> and installing TypeScript dependencies automatically configures the project to use TypeScript, including page and API route typings.
        </div>
      </li>
      
      <li data-id="q51">
        <span class="faq-question">How do you use TypeScript in a monorepo (e.g., with Turborepo or Nx)?</span>
        <div class="answer">
          Monorepos use shared <code>tsconfig.json</code> base configs with project references to manage multiple packages or apps, enabling incremental builds and type safety across the repo.
        </div>
      </li>
      
      <li data-id="q52">
        <span class="faq-question">How does TypeScript work with Jest or testing libraries?</span>
        <div class="answer">
          Install <code>ts-jest</code> to enable Jest to transpile TypeScript. Write tests with TypeScript for typed test code, and use type definitions for Jest to get autocompletion and type safety.
        </div>
      </li>
      
    
    
      <li data-id="q53">
        <span class="faq-question">What is the role of ESLint and Prettier with TypeScript?</span>
        <div class="answer">
          ESLint analyzes TypeScript code to find and fix problems using rules, while Prettier formats code consistently. Together they ensure code quality, style consistency, and catch bugs early.
        </div>
      </li>
      
      <li data-id="q54">
        <span class="faq-question">How does Webpack/Babel handle TypeScript?</span>
        <div class="answer">
          Webpack uses loaders like <code>ts-loader</code> or Babel with <code>@babel/preset-typescript</code> to transpile TypeScript into JavaScript, integrating type-checking in the build process.
        </div>
      </li>

      <li data-id="q33">
        <span class="faq-question green">How does Webpack/Babel handle TypeScript?</span>
        <div class="answer">
          <p><strong>Webpack</strong> and <strong>Babel</strong> can work together to handle <strong>TypeScript</strong>, but they play different roles in the process.</p>
      
          <h4>üîß Webpack</h4>
          <p><strong>Webpack</strong> is a bundler. It doesn't process TypeScript by itself. Instead, it uses <code>loaders</code> (like <code>ts-loader</code> or <code>babel-loader</code>) to handle TypeScript files.</p>
      
          <h4>üß† Babel</h4>
          <p><strong>Babel</strong> is a JavaScript compiler. With the right preset, Babel can strip TypeScript types but <strong>does not perform type-checking</strong>.</p>
      
          <h4>‚öôÔ∏è Typical Setup Options</h4>
          <ul>
            <li><strong>Option 1: Webpack + ts-loader</strong> (uses TypeScript compiler)</li>
            <li><strong>Option 2: Webpack + Babel + @babel/preset-typescript</strong> (faster, no type-checking)</li>
          </ul>
      
          <h4>üìù Option 1 ‚Äì Using ts-loader (Full Type Checking)</h4>
          <pre><code>// webpack.config.js
      module.exports = {
        module: {
          rules: [
            {
              test: /\.tsx?$/,
              use: 'ts-loader',
              exclude: /node_modules/,
            },
          ],
        },
      };</code></pre>
          <p>This uses the TypeScript compiler directly. Type checking and transpilation are done by <code>tsc</code>.</p>
      
          <h4>‚ö° Option 2 ‚Äì Using Babel (Fast Build, No Type Checking)</h4>
          <pre><code>// webpack.config.js
      module.exports = {
        module: {
          rules: [
            {
              test: /\.tsx?$/,
              exclude: /node_modules/,
              use: {
                loader: 'babel-loader',
                options: {
                  presets: [
                    '@babel/preset-env',
                    '@babel/preset-typescript',
                    '@babel/preset-react'
                  ],
                },
              },
            },
          ],
        },
      };</code></pre>
          <p>This is faster, but it <strong>only removes types</strong>. You‚Äôll need to run <code>tsc --noEmit</code> separately for type checking.</p>
      
          <h4>üîç Summary</h4>
          <table border="1" cellpadding="4" cellspacing="0">
            <thead>
              <tr>
                <th>Tool</th>
                <th>Role</th>
                <th>Type Checking?</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Webpack</td>
                <td>Bundler</td>
                <td>‚ùå</td>
              </tr>
              <tr>
                <td>ts-loader</td>
                <td>Uses TypeScript Compiler (tsc)</td>
                <td>‚úÖ</td>
              </tr>
              <tr>
                <td>Babel + @babel/preset-typescript</td>
                <td>Strips types, transpiles to JS</td>
                <td>‚ùå</td>
              </tr>
            </tbody>
          </table>
      
          <h4>üõ†Ô∏è Tips</h4>
          <ul>
            <li>Use <code>ts-loader</code> for strict TS projects.</li>
            <li>Use <code>babel-loader</code> for faster builds (with separate type checking).</li>
            <li>Use <code>fork-ts-checker-webpack-plugin</code> if you want type-checking with Babel.</li>
          </ul>
        </div>
      </li>
      



      <li data-id="q55">
        <span class="faq-question">What are best practices for organizing TypeScript codebases?</span>
        <div class="answer">
          Use clear folder structures by feature or layer, leverage <code>tsconfig.json</code> paths for imports, keep types/interfaces in separate files, and maintain strict compiler options for better safety.
        </div>
      </li>
      


      <li data-id="q33">
        <span class="faq-question green">Webpack and Buble?</span>
        <div class="answer">
<pre>
  <b>Webpack</b> and <strong>Buble</strong> are both tools used in JavaScript development, but they serve different purposes:

  <strong>üîß Webpack</strong> is a powerful <em>module bundler</em>. 
  It bundles JavaScript files (and other assets like CSS, images) into a single file or multiple chunks for use in the browser.

  1. Supports plugins and loaders (e.g., Babel loader)
  2. Tree shaking and code splitting
  3. Development server, hot module replacement



  <b>‚ö° Buble</b> is a lightweight JavaScript compiler focused on transforming modern ES6+ code into ES5. 
  It's faster and simpler than Babel but less configurable.

  1. Faster than Babel for smaller projects
  2. No plugins system (limited feature set)
  3. Great for quick transpilation of modern syntax (e.g., arrow functions, classes)

</pre>
          <pre><code>// webpack.config.js example
      module.exports = {
        entry: './src/index.js',
        output: {
          filename: 'bundle.js',
          path: __dirname + '/dist',
        },
        module: {
          rules: [
            {
              test: /\.js$/,
              exclude: /node_modules/,
              use: 'babel-loader'
            }
          ]
        }
      };</code></pre>
      
      
          <pre><code>// Example Buble CLI usage
      buble input.js --output output.js</code></pre>
      
          <h4>üîç When to Use What?</h4>
          <ul>
            <li><strong>Use Webpack</strong> when you need module bundling, hot reloading, and advanced features.</li>
            <li><strong>Use Buble</strong> when you need a fast, minimal JavaScript transpiler with limited configuration.</li>
          </ul>
      
          <p>In practice, many teams use <strong>Webpack + Babel</strong>, but you could substitute <strong>Buble</strong> for Babel in simpler setups.</p>
        </div>
      </li>
      













  <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
    MySQL : INNER, LEFT & RIGHT-OUTER, FULL OUTER JOIN, CROSS JOIN, SELF JOIN
  </span><div class="answer">
  <ol class="subul">
    <li><b>FULL OUTER JOIN :</b>(MySQL does not support this natively)</li>
    <li><b>INNER JOIN :</b> Returns only matching rows from both tables.</li>
    <li><b>CROSS JOIN :</b> Returns the Cartesian product (all combinations) of the two tables.</li>
    <li><b>SELF JOIN :</b> A table joined to itself using aliases.</li>
    <li>
      <code>
        SELECT * FROM employees e <span class="green">LEFT JOIN</span> departments d ON e.department_id = d.id <br />
        <span class="green">UNION</span><br />
        SELECT * FROM employees e RIGHT JOIN departments d ON e.department_id = d.id; <br /><hr />
        SELECT * FROM employees <span class="green">CROSS JOIN</span> departments;<br /><hr />

        SELECT a.name AS employee, b.name AS manager FROM employees a JOIN employees b ON a.manager_id = b.id;
        
      </code>
    </li>
  </ol>
  </div></li>


  <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
    Advantages of Sequelize
  </span><div class="answer">




    
  
    <h2>‚úÖ 1. Supports Multiple SQL Databases</h2>
    <p>Sequelize supports:</p>
    <ul>
      <li>PostgreSQL</li>
      <li>MySQL</li>
      <li>MariaDB</li>
      <li>SQLite</li>
      <li>MSSQL</li>
    </ul>
  
    <h2>‚úÖ 2. Promise-based</h2>
    <p>Built on Promises, making it easy to use with async/await for clean asynchronous flow.</p>
  
    <h2>‚úÖ 3. Models & Associations</h2>
    <p>Define relationships using built-in methods:</p>
    <pre><code>User.hasMany(Post);
  Post.belongsTo(User);</code></pre>
  
    <h2>‚úÖ 4. Migrations & Seeders</h2>
    <p>Includes CLI tools to manage database schema versions and initial data.</p>
  
    <h2>‚úÖ 5. ORM & Raw SQL</h2>
    <p>Allows flexible querying with both ORM methods and raw SQL:</p>
    <pre><code>const users = await sequelize.query("SELECT * FROM Users", { type: QueryTypes.SELECT });</code></pre>
  
    <h2>‚úÖ 6. Hooks/Lifecycle Callbacks</h2>
    <p>Execute logic before/after events like save, update, delete:</p>
    <pre><code>User.beforeCreate(user => {
    user.createdAt = new Date();
  });</code></pre>
  
    <h2>‚úÖ 7. Eager & Lazy Loading</h2>
    <p>Supports both eager loading via <code>include</code> and lazy loading via functions.</p>
  
    <h2>‚úÖ 8. Transaction Support</h2>
    <p>Robust support for transactions:</p>
    <pre><code>await sequelize.transaction(async (t) => {
    await User.create({ name: 'John' }, { transaction: t });
  });</code></pre>
  
    <h2>‚úÖ 9. Validation & Constraints</h2>
    <p>Define validations, constraints, and default values at the model level.</p>
  
    <h2>‚úÖ 10. Community & Ecosystem</h2>
    <p>Widely used in production with great community and support.</p>

  
  </div></li>






  
  <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
  TypeORM
</span><div class="answer">

  <ul>
    <li>Object-Oriented design using decorators</li>
    <li>Supports Active Record & Data Mapper</li>
    <li>Works with various databases (MySQL, PostgreSQL, etc.)</li>
    <li>Built-in migration support</li>
    <li>Eager and lazy relation loading</li>
    <li>Repository and QueryBuilder APIs</li>
    <li>Easy configuration using decorators</li>
    <li>Great integration with NestJS</li>
  </ul>




  
    <h2>‚úÖ 1. TypeScript Support</h2>
    <p>Fully written in and optimized for TypeScript. Enables <strong>type safety</strong>, <strong>intellisense</strong>, and <strong>compile-time checks</strong>.</p>
  
    <h2>‚úÖ 2. Decorators-Based Syntax</h2>
    <p>Uses <strong>class decorators</strong> for defining entities, columns, and relationships‚Äîclean and declarative.</p>
    <pre><code>@Entity()
  export class User {
    @PrimaryGeneratedColumn()
    id: number;
  
    @Column()
    name: string;
  }</code></pre>
  
    <h2>‚úÖ 3. Supports Multiple Databases</h2>
    <p>Works with:</p>
    <ul>
      <li>MySQL</li>
      <li>PostgreSQL</li>
      <li>SQLite</li>
      <li>MariaDB</li>
      <li>MSSQL</li>
      <li>Oracle</li>
      <li>MongoDB (limited)</li>
    </ul>
  
    <h2>‚úÖ 4. Built-In Migrations</h2>
    <p>Supports schema migrations for database version control:</p>
    <pre><code>typeorm migration:create -n AddUserTable
  typeorm migration:run</code></pre>
  
    <h2>‚úÖ 5. Repository & Data Mapper Patterns</h2>
    <p>Supports both <strong>Active Record</strong> and <strong>Data Mapper</strong> patterns.</p>
  
    <h2>‚úÖ 6. Relationship Management</h2>
    <p>Easy to define and manage entity relationships:</p>
    <pre><code>@OneToMany(() => Post, post => post.user)
  posts: Post[];</code></pre>
  
    <h2>‚úÖ 7. Lazy & Eager Loading</h2>
    <p>Supports both <strong>lazy</strong> (via Promises) and <strong>eager</strong> loading of relations.</p>
  
    <h2>‚úÖ 8. Query Builder</h2>
    <p>Flexible query builder for complex queries:</p>
    <pre><code>const users = await dataSource
    .getRepository(User)
    .createQueryBuilder("user")
    .where("user.age > :age", { age: 18 })
    .getMany();</code></pre>
  
    <h2>‚úÖ 9. Integration with NestJS</h2>
    <p>Works seamlessly with NestJS via the <code>@nestjs/typeorm</code> package.</p>
  
    <h2>‚úÖ 10. Community & Ecosystem</h2>
    <p>Well-maintained and widely adopted in production apps.</p>

  


</div></li>



<li data-id="q3"><span class="faq-question">
Lazy vs Eager Loading
</span><div class="answer">

  <h2>‚úÖ Lazy Loading</h2>
  <p>Lazy loading delays the loading of data or resources until they are actually needed.</p>

  <h3>üîç Characteristics:</h3>
  <ul>
    <li>Data is fetched only <strong>when accessed</strong>.</li>
    <li>Reduces initial load time.</li>
    <li>Saves memory and network if the data is never used.</li>
    <li>Might introduce <strong>additional queries or requests</strong> during runtime.</li>
  </ul>

  <h3>üí° Examples:</h3>
  <div class="code-title">Backend (ORM):</div>
  <pre><code>@OneToMany(() =&gt; Post, post =&gt; post.user, { lazy: true })
posts: Promise&lt;Post[]&gt;;</code></pre>

  <div class="code-title">Frontend (React):</div>
  <pre><code>const LazyComponent = React.lazy(() =&gt; import('./MyComponent'));</code></pre>

  <h2>‚úÖ Eager Loading</h2>
  <p>Eager loading loads related data immediately when the initial query or request is made.</p>

  <h3>üîç Characteristics:</h3>
  <ul>
    <li>Data is <strong>pre-fetched</strong> along with the primary data.</li>
    <li>Useful when you know the related data will be needed.</li>
    <li>Reduces the number of queries at runtime (prevents N+1 problem).</li>
    <li>Increases initial load time.</li>
  </ul>

  <h3>üí° Examples:</h3>
  <div class="code-title">Backend (ORM):</div>
  <pre><code>@OneToMany(() =&gt; Post, post =&gt; post.user, { eager: true })
posts: Post[];</code></pre>

  <div class="code-title">Frontend (React/Angular):</div>
  <pre><code>// Importing all modules/components at once during the initial load</code></pre>

  <h2>üÜö Lazy vs Eager Loading ‚Äì Quick Comparison</h2>
  <table>
    <thead>
      <tr>
        <th>Feature</th>
        <th>Lazy Loading</th>
        <th>Eager Loading</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Timing</td>
        <td>On demand</td>
        <td>At initial load</td>
      </tr>
      <tr>
        <td>Performance Impact</td>
        <td>Lower initial cost, may slow runtime</td>
        <td>Higher initial cost, faster runtime</td>
      </tr>
      <tr>
        <td>Use Case</td>
        <td>Optional or rarely used data</td>
        <td>Essential or frequently accessed data</td>
      </tr>
      <tr>
        <td>Query Behavior</td>
        <td>Multiple small queries</td>
        <td>Single large query</td>
      </tr>
    </tbody>
  </table>

  <h2>üß† When to Use What?</h2>
  <ul>
    <li><strong>Lazy Loading</strong>: When the related data is large, rarely used, or optional.</li>
    <li><strong>Eager Loading</strong>: When you always need the related data and want to avoid N+1 queries.</li>
  </ul>

</div></li>

<li data-id="q3"><span class="faq-question green">
  TypeORM vs Sequelize ***
  </span><div class="answer">


    
      <h1>TypeORM vs Sequelize</h1>
    
      <h2>üî∂ Overview</h2>
      <table>
        <tr>
          <th>Feature</th>
          <th>TypeORM</th>
          <th>Sequelize</th>
        </tr>
        <tr>
          <td>Language</td>
          <td>TypeScript-first ORM</td>
          <td>JavaScript-first (TypeScript support)</td>
        </tr>
        <tr>
          <td>API Style</td>
          <td>Decorator-based OOP (like Java/C#)</td>
          <td>Promise-based functional API</td>
        </tr>
        <tr>
          <td>Supported DBs</td>
          <td>MySQL, PostgreSQL, SQLite, MSSQL, etc.</td>
          <td>MySQL, PostgreSQL, SQLite, MSSQL, etc.</td>
        </tr>
        <tr>
          <td>Learning Curve</td>
          <td>Steeper for beginners</td>
          <td>Easier, beginner-friendly</td>
        </tr>
        <tr>
          <td>Community</td>
          <td>Growing in TS community</td>
          <td>Mature and stable</td>
        </tr>
      </table>
    
      <h2>üî∂ Coding Style</h2>
    
      <h3>‚úÖ TypeORM</h3>
      <pre><code>@Entity()
    export class User {
      @PrimaryGeneratedColumn()
      id: number;
    
      @Column()
      name: string;
    
      @OneToMany(() => Post, post => post.user)
      posts: Post[];
    }</code></pre>
    
      <h3>‚úÖ Sequelize</h3>
      <pre><code>const User = sequelize.define('User', {
      name: {
        type: Sequelize.STRING
      }
    });
    
    User.hasMany(Post);</code></pre>
    
      <h2>üî∂ Feature Comparison</h2>
      <table>
        <tr>
          <th>Feature</th>
          <th>TypeORM</th>
          <th>Sequelize</th>
        </tr>
        <tr>
          <td>TypeScript Support</td>
          <td>Native, first-class support</td>
          <td>Good, but less idiomatic</td>
        </tr>
        <tr>
          <td>Decorators</td>
          <td>Yes</td>
          <td>No</td>
        </tr>
        <tr>
          <td>Migrations</td>
          <td>Supported (CLI-based)</td>
          <td>Supported (CLI-based)</td>
        </tr>
        <tr>
          <td>Query Builder</td>
          <td>Yes (powerful)</td>
          <td>Yes</td>
        </tr>
        <tr>
          <td>Active Record Support</td>
          <td>‚úÖ Yes</td>
          <td>‚úÖ Yes</td>
        </tr>
        <tr>
          <td>Data Mapper Support</td>
          <td>‚úÖ Yes</td>
          <td>‚úÖ Yes</td>
        </tr>
        <tr>
          <td>Hooks / Lifecycle Events</td>
          <td>Supported</td>
          <td>Supported</td>
        </tr>
        <tr>
          <td>Custom Repositories</td>
          <td>Supported</td>
          <td>Less structured</td>
        </tr>
        <tr>
          <td>Raw Queries</td>
          <td>Yes</td>
          <td>Yes</td>
        </tr>
        <tr>
          <td>Lazy Loading Support</td>
          <td>‚úÖ Yes (via proxies)</td>
          <td>‚ùå No</td>
        </tr>
        <tr>
          <td>Ecosystem Plugins</td>
          <td>Smaller</td>
          <td>Larger</td>
        </tr>
        <tr>
          <td>Performance</td>
          <td>Comparable, context-specific</td>
          <td>Comparable, context-specific</td>
        </tr>
      </table>
    
      <h2>üî∂ Pros & Cons</h2>
    
      <h3>‚úÖ TypeORM</h3>
      <ul>
        <li>Built for TypeScript from the ground up.</li>
        <li>Cleaner, OOP-style with decorators.</li>
        <li>Easy to manage entities and relations.</li>
        <li>Supports both Active Record & Data Mapper.</li>
        <li><strong>Cons:</strong> Can be buggy, poor error messages, slower dev pace.</li>
      </ul>
    
      <h3>‚úÖ Sequelize</h3>
      <ul>
        <li>Mature, stable, and widely used.</li>
        <li>Rich feature set with powerful associations and hooks.</li>
        <li>Easier to get started for beginners.</li>
        <li><strong>Cons:</strong> Less seamless TS support, no decorators, more verbose.</li>
      </ul>
    
      <h2>üî∂ When to Use What?</h2>
      <table>
        <tr>
          <th>Use Case</th>
          <th>Recommendation</th>
        </tr>
        <tr>
          <td>Full TypeScript project</td>
          <td>‚úÖ TypeORM</td>
        </tr>
        <tr>
          <td>Simple JavaScript project</td>
          <td>‚úÖ Sequelize</td>
        </tr>
        <tr>
          <td>OOP/decorator-based architecture</td>
          <td>‚úÖ TypeORM</td>
        </tr>
        <tr>
          <td>Large team with JavaScript experience</td>
          <td>‚úÖ Sequelize</td>
        </tr>
        <tr>
          <td>Lazy loading required</td>
          <td>‚úÖ TypeORM</td>
        </tr>
        <tr>
          <td>Rapid prototyping / MVP</td>
          <td>‚úÖ Sequelize</td>
        </tr>
      </table>
    
      <h2>üîö Final Thoughts</h2>
      <p>
        Use <strong>TypeORM</strong> if you're building a scalable TypeScript-based app and want an OOP approach with decorators.<br>
        Use <strong>Sequelize</strong> if you want fast setup, simplicity, and a mature JS ORM with wide community support.
      </p>
    

    
  </div></li>

<li data-id="q3"><span class="faq-question">
DB Indexing   
</span><div class="answer">

  

    <p><strong>Database indexing</strong> is a data structure technique used to quickly locate and access data in a database. It improves <strong>read</strong> performance (especially <b>SELECT</b> queries) by reducing the number of rows scanned.</p>
  
    <h2>üß† Analogy</h2>
    <p>Think of an index in a book. Instead of reading every page to find a topic, you look it up in the index ‚Üí it tells you the page number ‚Üí you go directly there.</p>
  
    <h2>‚öôÔ∏è How It Works</h2>
    <ul>
      <li>A <strong>B-Tree</strong> or <strong>Hash Table</strong> structure is used.</li>
      <li>Indexes are built on one or more <strong>columns</strong>.</li>
      <li>Query engine checks the index first instead of scanning the whole table.</li>
    </ul>
  
    <h2>üîç Types of Indexes</h2>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Primary Index</strong></td>
          <td>Automatically created on the primary key.</td>
        </tr>
        <tr>
          <td><strong>Unique Index</strong></td>
          <td>Ensures all values in the column(s) are unique.</td>
        </tr>
        <tr>
          <td><strong>Composite Index</strong></td>
          <td>An index on multiple columns (e.g., <code>(first_name, last_name)</code>).</td>
        </tr>
        <tr>
          <td><strong>Full-Text Index</strong></td>
          <td>Used for text searching (e.g., <code>LIKE</code> or <code>MATCH AGAINST</code>).</td>
        </tr>
        <tr>
          <td><strong>Spatial Index</strong></td>
          <td>For geometric or GIS data.</td>
        </tr>
        <tr>
          <td><strong>Partial Index</strong></td>
          <td>Indexes only rows that meet a condition (<code>WHERE</code> clause).</td>
        </tr>
        <tr>
          <td><strong>Covering Index</strong></td>
          <td>All columns required by a query are in the index ‚Üí no table access needed.</td>
        </tr>
      </tbody>
    </table>
  
    <h2>üí° Best Practices</h2>
    <ul>
      <li>Index columns used in <code>WHERE</code>, <code>JOIN</code>, <code>ORDER BY</code>, and <code>GROUP BY</code>.</li>
      <li>Avoid indexing columns that are frequently updated or contain many duplicate values.</li>
      <li>Don‚Äôt over-index ‚Äî it slows down <code>INSERT</code>, <code>UPDATE</code>, and <code>DELETE</code> operations.</li>
      <li>Use <strong>composite indexes</strong> for multi-column filters.</li>
    </ul>
  
    <h2>üß™ Example in MySQL/PostgreSQL</h2>
    <pre><code>-- Create a simple index
  CREATE INDEX idx_users_email ON users(email);
  
  -- Composite index
  CREATE INDEX idx_users_name ON users(first_name, last_name);
  
  -- Drop an index
  DROP INDEX idx_users_email;
  </code></pre>
  
    <h2>üß† Query Plan (Advanced)</h2>
    <p>Use <code>EXPLAIN</code> (MySQL) or <code>EXPLAIN ANALYZE</code> (PostgreSQL) to see if your query uses an index:</p>
    <pre><code>EXPLAIN SELECT * FROM users WHERE email = 'user@example.com';</code></pre>

  
</div></li>


<li data-id="redis-diff"><span class="faq-question green">
  üìä Redis vs RabbitMQ vs Kafka vs AWS SNS
  </span><div class="answer">
    
    
    <table>
      <tr>
        <th>Feature</th>
        <th>Redis</th>
        <th>RabbitMQ</th>
        <th>Apache Kafka</th>
        <th>AWS SNS</th>
      </tr>
    
      <tr>
        <td>Type</td>
        <td>In-memory data store & lightweight message broker</td>
        <td>Traditional message broker</td>
        <td>Distributed event streaming platform</td>
        <td>Managed pub/sub messaging service</td>
      </tr>
    
      <tr>
        <td>Use Case</td>
        <td>Caching, queues, lightweight pub/sub</td>
        <td>Reliable message queuing (task/job queues)</td>
        <td>High-throughput log/event streaming</td>
        <td>Fan-out messages to multiple AWS services or HTTP endpoints</td>
      </tr>
    
      <tr>
        <td>Persistence</td>
        <td>Optional (RDB, AOF)</td>
        <td>Yes (durable queues)</td>
        <td>Yes (retains logs)</td>
        <td>No built-in persistence (fire-and-forget)</td>
      </tr>
    
      <tr>
        <td>Ordering Guarantees</td>
        <td>Per-list, not global</td>
        <td>Per-queue</td>
        <td>Per-partition</td>
        <td>No strict guarantees</td>
      </tr>
    
      <tr>
        <td>Message Retention</td>
        <td>Until consumed or expired</td>
        <td>Until consumed or TTL expires</td>
        <td>Configurable retention (days/weeks)</td>
        <td>Delivers and discards</td>
      </tr>
    
      <tr>
        <td>Throughput</td>
        <td>High (in-memory)</td>
        <td>Medium</td>
        <td>Very High (sequential disk I/O, batching)</td>
        <td>Medium (event broadcast scale)</td>
      </tr>
    
      <tr>
        <td>Scalability</td>
        <td>Vertical (or Redis Cluster)</td>
        <td>Limited (clusters supported with plugins)</td>
        <td>Horizontal (Kafka Cluster, partitions)</td>
        <td>Fully managed and scalable</td>
      </tr>
    
      <tr>
        <td>Delivery Semantics</td>
        <td>At most once (by default)</td>
        <td>At least once (manual ack)</td>
        <td>At most once / At least once / Exactly once</td>
        <td>At most once (no retries by default)</td>
      </tr>
    
      <tr>
        <td>Protocol Support</td>
        <td>Custom RESP, Pub/Sub, Streams</td>
        <td>AMQP, MQTT, STOMP</td>
        <td>Kafka Protocol</td>
        <td>HTTPS, AWS SDK</td>
      </tr>
    
      <tr>
        <td>Built-in Retry</td>
        <td>No</td>
        <td>Yes</td>
        <td>Consumer responsibility</td>
        <td>No (use with Lambda, SQS for retries)</td>
      </tr>
    
      <tr>
        <td>Latency</td>
        <td>Low</td>
        <td>Low to Medium</td>
        <td>Low (with batching)</td>
        <td>Medium</td>
      </tr>
    
      <tr>
        <td>High Availability</td>
        <td>Redis Sentinel / Cluster</td>
        <td>Mirrored/Quorum Queues</td>
        <td>Built-in replication</td>
        <td>Managed by AWS</td>
      </tr>
    
      <tr>
        <td>Best For</td>
        <td>Simple queues, caching, pub/sub</td>
        <td>Decoupling microservices</td>
        <td>Event streaming, log processing</td>
        <td>Triggering distributed systems (fan-out)</td>
      </tr>
    
    </table>
    
    
</div></li>

<li data-id="redis-q"><span class="faq-question green">
  üêá Redis
  </span><div class="answer">

    
      <h1>üöÄ Redis Interview Questions</h1>
    
      <div class="question">1. What is Redis?</div>
      <div class="answer">Redis (Remote Dictionary Server) is an open-source, in-memory data structure store used as a database, cache, and message broker.</div>
    
      <div class="question">2. What are the main data types in Redis?</div>
      <div class="answer">
        - String<br>
        - List<br>
        - Set<br>
        - Sorted Set<br>
        - Hash<br>
        - Bitmap, HyperLogLog, Stream, and Geospatial Indexes
      </div>
    
      <div class="question">3. What is the default port for Redis?</div>
      <div class="answer">6379</div>
    
      <div class="question">4. Is Redis single-threaded or multi-threaded?</div>
      <div class="answer">Redis is single-threaded for commands, but supports multi-threaded I/O for performance since Redis 6.0.</div>
    
      <div class="question">5. What is the difference between Redis and Memcached?</div>
      <div class="answer">
        Redis supports complex data structures, persistence, and replication.<br>
        Memcached is limited to simple key-value pairs with no persistence or advanced structures.
      </div>
    
      <div class="question">6. What is a Redis keyspace?</div>
      <div class="answer">A Redis keyspace refers to all keys in a Redis database. Redis supports multiple databases (default is DB 0).</div>
    
      <div class="question">7. What is TTL in Redis?</div>
      <div class="answer">TTL (Time to Live) is the time (in seconds) a key will exist before being automatically deleted.</div>
    
      <div class="question">8. How do you persist data in Redis?</div>
      <div class="answer">
        Redis supports two types of persistence:<br>
        - RDB (point-in-time snapshot)<br>
        - AOF (Append-Only File that logs each write operation)
      </div>
    
      <div class="question">9. What is Redis replication?</div>
      <div class="answer">Redis supports master-slave replication to create read-only replicas for scalability and redundancy.</div>
    
      <div class="question">10. What is Redis Sentinel?</div>
      <div class="answer">Sentinel provides high availability by monitoring Redis instances, promoting a slave to master on failure.</div>
    
      <div class="question">11. What is Redis Cluster?</div>
      <div class="answer">Redis Cluster allows horizontal scaling by partitioning data across multiple nodes using hash slots.</div>
    
      <div class="question">12. What command is used to check TTL of a key?</div>
      <div class="answer"><code>TTL key</code></div>
    
      <div class="question">13. How can you delete all keys in Redis?</div>
      <div class="answer"><code>FLUSHALL</code> (for all DBs) or <code>FLUSHDB</code> (for current DB)</div>
    
      <div class="question">14. How do you make Redis threads safe?</div>
      <div class="answer">Redis is single-threaded and thread-safe by default for client connections. Use connection pooling in multi-threaded clients.</div>
    
      <div class="question">15. What is pipelining in Redis?</div>
      <div class="answer">Pipelining allows sending multiple commands without waiting for their replies, improving throughput.</div>
    
      <div class="question">16. What are pub/sub channels in Redis?</div>
      <div class="answer">Redis supports publish/subscribe messaging where messages sent to a channel are received by all subscribers.</div>
    
      <div class="question">17. What is the difference between SCAN and KEYS?</div>
      <div class="answer">
        - KEYS returns all matching keys and can block the server.<br>
        - SCAN is non-blocking and suitable for production usage.
      </div>
    
      <div class="question">18. What is the maximum size of a Redis key or value?</div>
      <div class="answer">The maximum key size is 512 MB. Same for values depending on data type and memory limits.</div>
    
      <div class="question">19. Can Redis be used for message queuing?</div>
      <div class="answer">Yes, using lists (RPUSH + LPOP/BRPOP), streams, or pub/sub for real-time messaging patterns.</div>
    
      <div class="question">20. How do you monitor Redis?</div>
      <div class="answer">Use commands like <code>INFO</code>, <code>MONITOR</code>, or external tools like RedisInsight, Prometheus, or Grafana.</div>
    
    </div></li>



<li data-id="rabbitmq"><span class="faq-question green">
  üêá RabbitMQ
  </span><div class="answer">


  <div class="question">1. What is RabbitMQ?</div>
  <div class="answer">RabbitMQ is an open-source message broker that enables applications to communicate asynchronously by sending messages via queues.</div>

  <div class="question">2. What messaging protocol does RabbitMQ use?</div>
  <div class="answer">RabbitMQ primarily uses AMQP (Advanced Message Queuing Protocol), but it also supports MQTT, STOMP, and HTTP via plugins.</div>

  <div class="question">3. What are the main components of RabbitMQ?</div>
  <div class="answer">
    - Producer<br>
    - Queue<br>
    - Consumer<br>
    - Exchange<br>
    - Binding
  </div>

  <div class="question">4. What is an exchange in RabbitMQ?</div>
  <div class="answer">An exchange routes messages to queues based on rules defined by bindings. Types: direct, topic, fanout, and headers.</div>

  <div class="question">5. What is a binding?</div>
  <div class="answer">A binding is a link between a queue and an exchange that defines how messages should be routed.</div>

  <div class="question">6. What is a routing key?</div>
  <div class="answer">A routing key is a string used by exchanges to determine how to route a message to queues.</div>

  <div class="question">7. What is the difference between direct and fanout exchanges?</div>
  <div class="answer">
    - Direct: Routes messages to queues with an exact matching routing key.<br>
    - Fanout: Broadcasts messages to all bound queues regardless of routing key.
  </div>

  <div class="question">8. What is a durable queue?</div>
  <div class="answer">A durable queue survives broker restarts. Messages must also be marked as persistent for durability.</div>

  <div class="question">9. What is the difference between persistent and transient messages?</div>
  <div class="answer">Persistent messages are stored to disk and survive broker restarts. Transient messages are stored in memory only.</div>

  <div class="question">10. What is a dead-letter exchange (DLX)?</div>
  <div class="answer">A DLX is used to route messages that are not deliverable or have expired (e.g., rejected, TTL expired).</div>

  <div class="question">11. What is message acknowledgment (ack)?</div>
  <div class="answer">Acknowledgment is a signal sent by the consumer to inform the broker that a message was successfully processed.</div>

  <div class="question">12. What happens if a message is not acknowledged?</div>
  <div class="answer">The message is requeued and redelivered unless auto-ack is enabled or the message is rejected.</div>

  <div class="question">13. What is prefetch count?</div>
  <div class="answer">Prefetch count limits the number of unacknowledged messages sent to a consumer. It‚Äôs used for fair dispatching.</div>

  <div class="question">14. How does RabbitMQ ensure message ordering?</div>
  <div class="answer">RabbitMQ ensures ordering within a single queue. Messages are delivered in the order they arrive.</div>

  <div class="question">15. What is the difference between a queue and an exchange?</div>
  <div class="answer">Queues hold messages. Exchanges route messages to queues based on bindings and routing keys.</div>

  <div class="question">16. How does RabbitMQ handle high availability?</div>
  <div class="answer">Using mirrored queues (classic) or quorum queues (recommended), RabbitMQ replicates messages across nodes.</div>

  <div class="question">17. What is a quorum queue?</div>
  <div class="answer">A quorum queue replicates messages across multiple nodes using the Raft consensus algorithm. It replaces mirrored queues.</div>

  <div class="question">18. Can RabbitMQ work with microservices?</div>
  <div class="answer">Yes. RabbitMQ is commonly used in microservice architectures for asynchronous communication between services.</div>

  <div class="question">19. How do you monitor RabbitMQ?</div>
  <div class="answer">Using the RabbitMQ Management Plugin (UI & REST API), Prometheus exporters, or CLI tools like <code>rabbitmqctl</code>.</div>

  <div class="question">20. What are common RabbitMQ client libraries?</div>
  <div class="answer">
    - Node.js: amqplib<br>
    - Python: pika<br>
    - Java: RabbitMQ Java Client<br>
    - .NET: RabbitMQ .NET Client
  </div>

</body>
</html>

</div></li>




<li data-id="kafka" class="yellow"><span class="faq-question">
  Kafka
  </span><div class="answer">

    <h1></h1>

    <div class="question">1. What is Apache Kafka?</div>
    <div class="answer">Kafka is a distributed event streaming platform used for high-performance data pipelines, streaming analytics, and event-driven applications.</div>
  
    <div class="question">2. What are the main components of Kafka?</div>
    <div class="answer">
      - Producer<br>
      - Consumer<br>
      - Broker<br>
      - Topic<br>
      - Partition<br>
      - Zookeeper (optional for newer versions)
    </div>
  
    <div class="question">3. What is a Kafka topic?</div>
    <div class="answer">A topic is a category/feed name to which records are published. Topics are split into partitions for parallel processing.</div>
  
    <div class="question">4. What is a Kafka partition?</div>
    <div class="answer">A partition is a sub-division of a topic. Each partition is an ordered, immutable sequence of records.</div>
  
    <div class="question">5. What ensures message ordering in Kafka?</div>
    <div class="answer">Kafka guarantees ordering only within a single partition.</div>
  
    <div class="question">6. What is a Kafka broker?</div>
    <div class="answer">A broker is a Kafka server that stores data and serves clients. A cluster has multiple brokers.</div>
  
    <div class="question">7. What is the role of Zookeeper in Kafka?</div>
    <div class="answer">Zookeeper manages Kafka‚Äôs metadata, broker coordination, and leader election (older versions). Kafka 2.8+ can run without Zookeeper.</div>
  
    <div class="question">8. What is Kafka Producer?</div>
    <div class="answer">A producer sends records (data) to a Kafka topic.</div>
  
    <div class="question">9. What is Kafka Consumer?</div>
    <div class="answer">A consumer reads records from Kafka topics.</div>
  
    <div class="question">10. What is a Consumer Group?</div>
    <div class="answer">A group of consumers that share the load of reading from topics. Each partition is read by only one consumer in the group.</div>
  
    <div class="question">11. How does Kafka ensure fault tolerance?</div>
    <div class="answer">Through replication: each partition has replicas. If the leader fails, a follower takes over.</div>
  
    <div class="question">12. What is Kafka's retention policy?</div>
    <div class="answer">Kafka retains messages for a configurable amount of time or until a storage size limit is reached, even if consumed.</div>
  
    <div class="question">13. How does Kafka achieve high throughput?</div>
    <div class="answer">Through sequential disk writes, zero-copy, batching, and compression.</div>
  
    <div class="question">14. What are Kafka delivery semantics?</div>
    <div class="answer">
      - At most once<br>
      - At least once<br>
      - Exactly once (since Kafka 0.11+)
    </div>
  
    <div class="question">15. What is idempotence in Kafka?</div>
    <div class="answer">It ensures the same message is not duplicated if sent multiple times. Enabled via idempotent producers.</div>
  
    <div class="question">16. What is a Kafka offset?</div>
    <div class="answer">A unique identifier of a record within a partition. Consumers track offsets to resume reading.</div>
  
    <div class="question">17. How is offset management done?</div>
    <div class="answer">Offsets can be committed automatically or manually, and are stored in Kafka‚Äôs __consumer_offsets topic.</div>
  
    <div class="question">18. What are Kafka Streams?</div>
    <div class="answer">Kafka Streams is a client library for building real-time applications using Kafka topics as input/output.</div>
  
    <div class="question">19. What is the difference between Kafka and a traditional message queue?</div>
    <div class="answer">
      Kafka stores data for a time period regardless of consumption and supports replaying messages.<br>
      Queues typically delete messages once consumed.
    </div>
  
    <div class="question">20. What is the role of schema registry in Kafka?</div>
    <div class="answer">Schema registry ensures that producers and consumers agree on data format (e.g., using Avro schemas).</div>
  
</div></li>


<li data-id="kafka"><span class="faq-question green">
  Is Kafka only a messaging tool?
  </span><div class="answer">


<p>Kafka is primarily known as a <strong>distributed event streaming platform</strong> and <strong>messaging system</strong>, but its capabilities go beyond just messaging. Here‚Äôs a quick overview of what Kafka is used for:</p>

<h3>Kafka is more than just a messaging tool:</h3>
<ol>
  <li>
    <strong>Messaging / Pub-Sub System:</strong><br>
    Like traditional messaging queues (e.g., RabbitMQ), Kafka allows producers to send messages to topics and consumers to read those messages. It supports <em>publish-subscribe</em> and <em>message queue</em> patterns.
  </li>
  <li>
    <strong>Event Streaming Platform:</strong><br>
    Kafka stores streams of records (events) in a durable, ordered, and distributed log. Applications can process these events in real-time, making Kafka ideal for <em>real-time data pipelines</em> and <em>event-driven architectures</em>.
  </li>
  <li>
    <strong>Data Integration and ETL Pipelines:</strong><br>
    Kafka is often used to collect and move data between systems. With tools like <code>Kafka Connect</code>, it can integrate databases, file systems, and other data sources into the event stream.
  </li>
  <li>
    <strong>Stream Processing:</strong><br>
    Kafka Streams (a library) and ksqlDB enable <em>real-time processing and transformation</em> of streaming data within Kafka itself.
  </li>
  <li>
    <strong>Durable Storage:</strong><br>
    Kafka retains data for a configurable period, allowing consumers to read data multiple times or rewind streams, unlike typical messaging queues where messages are removed once consumed.
  </li>
</ol>

<h3>Summary:</h3>
<p>
  Yes, Kafka is a messaging tool, but it‚Äôs more accurately described as a <strong>distributed event streaming platform</strong> that supports messaging, storage, and stream processing.<br>
  It‚Äôs designed for <em>high-throughput, fault-tolerant, scalable, and durable</em> event handling and real-time data processing.
</p>

    </div></li>


<li data-id="kafka"><span class="faq-question green">
  Kafka Example***
  </span><div class="answer">
    <h1>‚úÖ NestJS + KafkaJS with Online Kafka Server</h1>

    <h2>üì¶ Prerequisites</h2>
    <ul>
      <li>Install NestJS CLI:</li>
      <pre><code>npm i -g @nestjs/cli</code></pre>
      <li>Install KafkaJS:</li>
      <pre><code>npm install kafkajs</code></pre>
      <li>Kafka server: Use Confluent Cloud or CloudKarafka (free tiers work)</li>
    </ul>
  
    <h2>üìÅ Project Setup</h2>
    <pre><code>nest new kafka-nestjs-app
  cd kafka-nestjs-app
  npm install kafkajs</code></pre>
  
    <h2>üõ†Ô∏è Kafka Service File</h2>
    <p><code>src/kafka.service.ts</code></p>
    <pre><code>
  import { Injectable, OnModuleDestroy, OnModuleInit } from '@nestjs/common';
  import { Kafka, Producer, Consumer } from 'kafkajs';
  
  @Injectable()
  export class KafkaService implements OnModuleInit, OnModuleDestroy {
    private kafka: Kafka;
    private producer: Producer;
    private consumer: Consumer;
  
    async onModuleInit() {
      this.kafka = new Kafka({
        clientId: 'nestjs-client',
        brokers: ['&lt;BROKER_URL&gt;'], // e.g. pkc-xxxx.gcp.confluent.cloud:9092
        ssl: true,
        sasl: {
          mechanism: 'plain',
          username: '&lt;API_KEY&gt;',
          password: '&lt;API_SECRET&gt;',
        },
      });
  
      this.producer = this.kafka.producer();
      await this.producer.connect();
  
      this.consumer = this.kafka.consumer({ groupId: 'nestjs-group' });
      await this.consumer.connect();
      await this.consumer.subscribe({ topic: 'test-topic', fromBeginning: true });
  
      await this.consumer.run({
        eachMessage: async ({ topic, partition, message }) => {
          console.log(`Received: ${message.value.toString()}`);
        },
      });
    }
  
    async sendMessage(topic: string, message: any) {
      await this.producer.send({
        topic,
        messages: [{ value: JSON.stringify(message) }],
      });
    }
  
    async onModuleDestroy() {
      await this.producer.disconnect();
      await this.consumer.disconnect();
    }
  }
    </code></pre>
  
    <h2>üß© App Module</h2>
    <p><code>src/app.module.ts</code></p>
    <pre><code>
  import { Module } from '@nestjs/common';
  import { KafkaService } from './kafka.service';
  
  @Module({
    providers: [KafkaService],
  })
  export class AppModule {}
    </code></pre>
  
    <h2>üöÄ App Controller</h2>
    <p><code>src/app.controller.ts</code></p>
    <pre><code>
  import { Controller, Get } from '@nestjs/common';
  import { KafkaService } from './kafka.service';
  
  @Controller()
  export class AppController {
    constructor(private readonly kafkaService: KafkaService) {}
  
    @Get('send')
    async sendMessage() {
      await this.kafkaService.sendMessage('test-topic', { message: 'Hello Kafka' });
      return 'Message sent';
    }
  }
    </code></pre>
  
    <h2>‚ñ∂Ô∏è Run the App</h2>
    <pre><code>npm run start</code></pre>
    <p>Then visit <code>http://localhost:3000/send</code> to test Kafka message sending.</p>
  
    <h2>üîí Tips</h2>
    <ul>
      <li>Make sure your Kafka broker supports SSL + SASL.</li>
      <li>Replace <code>&lt;BROKER_URL&gt;</code>, <code>&lt;API_KEY&gt;</code>, <code>&lt;API_SECRET&gt;</code> with real credentials.</li>
      <li>Use free cloud Kafka providers for convenience.</li>
    </ul>
  
    <h2>üìö Resources</h2>
    <ul>
      <li><a href="https://docs.nestjs.com/microservices/kafka" target="_blank">NestJS Kafka Docs</a></li>
      <li><a href="https://kafka.js.org/docs" target="_blank">KafkaJS Docs</a></li>
      <li><a href="https://www.confluent.io/cloud/" target="_blank">Confluent Cloud</a></li>
      <li><a href="https://www.cloudkarafka.com/" target="_blank">CloudKarafka</a></li>
    </ul>
  

    </div></li>


    <li data-id="DynamoDBQQ"><span class="faq-question green">
      DynamoDB Questions***
      </span><div class="answer">
<a href="DynamoDB.html">Read More</a>
    </div></li>
    




    <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
      Lambda : Question?
      </span><div class="answer">
      
      <ol>
        <li><strong>What is AWS Lambda?</strong></li>
        <li><strong>What are the key features of AWS Lambda?</strong></li>
        <li><strong>How does AWS Lambda pricing work?</strong></li>
        <li><strong>What triggers can invoke a Lambda function?</strong></li>
        <li><strong>What are the supported languages in AWS Lambda?</strong></li>
        <li><strong>What is the maximum execution time of a Lambda function?</strong></li>
        <li><strong>How do you monitor a Lambda function?</strong></li>
        <li><strong>What is a cold start in AWS Lambda?</strong></li>
        <li><strong>How can you reduce cold start time?</strong></li>
        <li><strong>What is the difference between synchronous and asynchronous invocation?</strong></li>
        <li><strong>How does concurrency work in Lambda?</strong></li>
        <li><strong>What is the default memory limit and how can it be changed?</strong></li>
        <li><strong>How do you handle errors in AWS Lambda?</strong></li>
        <li><strong>Can a Lambda function call another Lambda function?</strong></li>
        <li><strong>How do you version and alias a Lambda function?</strong></li>
        <li><strong>What is Lambda@Edge?</strong></li>
        <li><strong>What is the difference between Lambda and EC2?</strong></li>
        <li><strong>How do you deploy a Lambda function?</strong></li>
        <li><strong>How can environment variables be used in Lambda?</strong></li>
        <li><strong>How does IAM relate to Lambda function permissions?</strong></li>
        <li><strong>What is the Lambda execution role?</strong></li>
        <li><strong>How can you connect Lambda to VPC?</strong></li>
        <li><strong>How do you integrate AWS Lambda with API Gateway?</strong></li>
        <li><strong>What is the use of the Lambda Layers feature?</strong></li>
        <li><strong>What is the difference between Lambda and Step Functions?</strong></li>
      </ol>
      --------------------------------
      </div></li>
    


      <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
        What is AWS Lambda and how does it work?</span>
        <div class="answer">
          <p>
            AWS Lambda is a serverless compute service that runs your code in response to events and automatically manages the underlying compute resources.
          </p>
          <ul>
            <li>You write code (functions).</li>
            <li>Upload it to Lambda.</li>
            <li>Set a trigger (e.g., API Gateway, S3, DynamoDB).</li>
            <li>Lambda scales automatically and runs only when triggered.</li>
            <li>You pay only for the time your code runs (billed per millisecond).</li>
          </ul>
        </li>
      
        <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
          What are Lambda Triggers and Examples?</span>
          <div class="answer">
          <p>A trigger is an AWS service/event that invokes a Lambda function. Examples include:</p>
          <table border="1" cellpadding="5">
            <thead>
              <tr>
                <th>Trigger Source</th>
                <th>Example Use Case</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>API Gateway</td>
                <td>RESTful APIs</td>
              </tr>
              <tr>
                <td>S3</td>
                <td>Process image upload</td>
              </tr>
              <tr>
                <td>DynamoDB Streams</td>
                <td>Audit logs on table change</td>
              </tr>
              <tr>
                <td>CloudWatch Events</td>
                <td>Scheduled tasks (cron jobs)</td>
              </tr>
              <tr>
                <td>SNS/SQS</td>
                <td>Event-driven messaging</td>
              </tr>
            </tbody>
          </table>
        </li>
      
        <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
          What are Cold Starts in AWS Lambda?</span>
          <div class="answer">
          <p>
            A <em>cold start</em> occurs when a Lambda function is invoked after a period of inactivity or when AWS scales up new instances.
          </p>
          <ul>
            <li>Causes delay due to bootstrapping environment</li>
            <li>More noticeable in VPC-connected or large-sized functions</li>
            <li>Can be mitigated using:
              <ul>
                <li>Provisioned Concurrency</li>
                <li>Keeping functions warm via CloudWatch or scheduled triggers</li>
              </ul>
            </li>
          </ul>
        </li>
      
        <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
          What are the Limits of AWS Lambda?</span>
          <div class="answer">
          <table border="1" cellpadding="5">
            <thead>
              <tr>
                <th>Feature</th>
                <th>Default Limit (as of 2024)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Timeout</td>
                <td>Up to 15 minutes (900 seconds)</td>
              </tr>
              <tr>
                <td>Memory</td>
                <td>128 MB to 10,240 MB (10 GB)</td>
              </tr>
              <tr>
                <td>Package Size</td>
                <td>50 MB (direct upload) / 250 MB (S3)</td>
              </tr>
              <tr>
                <td>Environment Variables</td>
                <td>4 KB</td>
              </tr>
              <tr>
                <td>Concurrency</td>
                <td>1,000 per account (soft limit)</td>
              </tr>
              <tr>
                <td>Ephemeral Storage</td>
                <td>512 MB default (up to 10 GB optional)</td>
              </tr>
            </tbody>
          </table>
        </li>
      
        <li data-id="q_call_api_without_useeffect"><span class="faq-question green">
          How does Lambda handle state and scalability?</span>
          <div class="answer">
          <ul>
            <li><strong>State:</strong> Lambda is <em>stateless</em>. Each invocation is isolated. Use external systems like DynamoDB, S3, or Redis to manage state.</li>
            <li><strong>Scalability:</strong> Lambda <em>automatically scales</em> out by running multiple copies in response to incoming events.</li>
            <li>No need to manage servers or instances.</li>
            <li>Can scale from <strong>zero to thousands</strong> of parallel executions.</li>
          </ul>
        </li>


      <li data-id="q_what_is_lambda">
        <span class="faq-question green">Lambda?</span>
        <div class="answer">
          AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers. 
          <br />Lambda handles the rest‚Äîscaling, monitoring, patching, and running your application in response to events.
        
          <br />
          <br />
          <b>Key features of AWS Lambda include:</b>
          <ul>
            <li>No server management</li>
            <li>Automatic scaling</li>
            <li>Sub-second metering (pay only for usage)</li>
            <li>Event-driven invocation (triggers from over 200 AWS services)</li>
            <li>Built-in fault tolerance</li>
            <li>Supports environment variables, versioning, and aliases</li>
            <li>Integration with VPC, Layers, and Container Images</li>
          </ul>
        </div>


        <div class="answer">
          AWS Lambda provides a powerful and flexible serverless compute platform. Its key features include:
          <ul>
            <li><strong>Event-Driven Execution:</strong> Automatically triggered by AWS services (e.g., S3, API Gateway, DynamoDB) or external events.</li>
            <li><strong>No Server Management:</strong> No need to provision or manage infrastructure. AWS handles everything.</li>
            <li><strong>Automatic Scaling:</strong> Lambda scales automatically with the number of incoming events.</li>
            <li><strong>Pay-per-Use Pricing:</strong> Billed per millisecond based on the number of requests and compute time used.</li>
            <li><strong>Supports Multiple Languages:</strong> Includes Node.js, Python, Go, Java, .NET, Ruby, and custom runtimes.</li>
            <li><strong>Short-Lived Functions:</strong> Functions run up to 15 minutes and then terminate automatically.</li>
            <li><strong>Built-in Monitoring:</strong> Integrated with CloudWatch for logs and metrics.</li>
            <li><strong>Environment Variables:</strong> Store configuration and secrets per environment (e.g., dev, prod).</li>
            <li><strong>Versioning & Aliases:</strong> Create immutable versions of code and route traffic with named aliases.</li>
            <li><strong>VPC Support:</strong> Access private resources in a VPC securely.</li>
            <li><strong>Provisioned Concurrency:</strong> Pre-warm instances to avoid cold starts for latency-sensitive workloads.</li>
            <li><strong>Lambda Layers:</strong> Package and share libraries or dependencies across multiple functions.</li>
          </ul>
        </div>
      </li>
      

        <li data-id="q1uuuy">
          <span class="faq-question">Lambda: Keeping functions warm using scheduled CloudWatch Events</span>
          <div class="answer">
            <p>In AWS Lambda, <strong>cold starts</strong> happen when your function is invoked after being idle, causing latency due to container initialization. One common technique to <strong>keep Lambda functions warm</strong> is using <strong>Amazon CloudWatch Events (EventBridge)</strong> to invoke the function on a regular schedule.</p>
      
            <h4>‚úÖ Steps to Keep Lambda Warm with CloudWatch Scheduled Events</h4>
      
            <h5>1. Create a CloudWatch Event Rule</h5>
            <p>This will run every 5 minutes (or less) to trigger the Lambda and keep it warm.</p>
            <p><strong>Example: rate expression:</strong><br><code>rate(5 minutes)</code></p>
            <p><strong>Example: cron expression:</strong><br><code>cron(0/5 * * * ? *)</code></p>
      
            <h5>2. Attach Lambda as the Target</h5>
            <p>Use the AWS Management Console or CLI to set the Lambda function as the target of the scheduled rule.</p>
      
            <h5>3. Lambda Code (Optional: Check <code>source</code> to filter warm-up calls)</h5>
<pre>
  exports.handler = async (event) =&gt; {
    if (event.source === 'aws.events') {
      console.log("Warm-up ping received");
      return "Lambda is warm";
    }
  
    // Normal Lambda logic here
    console.log("Normal execution");
    return "Processed request";
  };
</pre>
      
            <h4>üõ†Ô∏è AWS CLI Example</h4>
            <pre><code>aws events put-rule \
        --name keep-lambda-warm \
        --schedule-expression "rate(5 minutes)"
      
      aws lambda add-permission \
        --function-name myLambdaFunction \
        --statement-id allow-scheduled-invoke \
        --action 'lambda:InvokeFunction' \
        --principal events.amazonaws.com \
        --source-arn arn:aws:events:&lt;region&gt;:&lt;account-id&gt;:rule/keep-lambda-warm
      
      aws events put-targets \
        --rule keep-lambda-warm \
        --targets "Id"="1","Arn"="arn:aws:lambda:&lt;region&gt;:&lt;account-id&gt;:function:myLambdaFunction"</code></pre>
      
            <h4>üî• Best Practices</h4>
            <ul>
              <li>Use a <strong>lightweight payload</strong> to reduce cost.</li>
              <li>For <strong>multiple Lambdas</strong>, consolidate into a single ‚Äúwarming‚Äù function that calls others asynchronously.</li>
              <li>Use <code>Provisioned Concurrency</code> for critical APIs (more reliable but has cost).</li>
            </ul>
          </div>
        </li>
      
      
        
          <li data-id="q2">
            <span class="faq-question green">Step-by-Step: Create a CloudWatch Event Rule to keep an API warm</span>
            <div class="answer">
              <p>This guide shows how to use <strong>Amazon EventBridge (CloudWatch Events)</strong> to ping an API endpoint like:</p>
              <p><code>https://pc0wd3fim2.execute-api.us-east-1.amazonaws.com/</code></p>
        
              <h4>‚úÖ Goal</h4>
              <p>Invoke a Lambda function or API Gateway endpoint every 5 minutes to keep it warm and avoid cold starts.</p>
        
              <h4>üß© Step-by-Step: Using AWS Console to Call an API URL</h4>
        
              <h5>üü¢ 1. Go to <strong>EventBridge</strong></h5>
              <ul>
                <li>Sign in to the AWS Console</li>
                <li>Open <strong>Amazon EventBridge</strong> from the "Management &amp; Governance" section</li>
              </ul>
        
              <h5>üü¢ 2. Create Rule</h5>
              <ul>
                <li>Click <strong>‚ÄúRules‚Äù &gt; ‚ÄúCreate rule‚Äù</strong></li>
                <li>Rule name: <code>keep-api-warm</code></li>
                <li>Description: <code>Keep API Gateway warm</code></li>
                <li><strong>Event Source:</strong> ‚ÄúEventBridge (default bus)‚Äù</li>
                <li><strong>Rule type:</strong> ‚ÄúSchedule‚Äù</li>
              </ul>
        
              <h5>üü¢ 3. Set Schedule</h5>
              <ul>
                <li>Select: <strong>rate expression</strong></li>
                <li>Input: <code>rate(5 minutes)</code></li>
              </ul>
        
              <h5>üü¢ 4. Add Target (API Gateway or Custom URL)</h5>
              <p>Since you are calling an external API endpoint:</p>
              <ul>
                <li>Choose <strong>Target type:</strong> <code>API destination</code></li>
                <li>Click <strong>Create a new API destination</strong></li>
              </ul>
        
              <h5>üîß Set up API Destination</h5>
              <ul>
                <li>Name: <code>KeepWarmDestination</code></li>
                <li>Method: <code>GET</code> or <code>POST</code> (depending on your endpoint)</li>
                <li>Endpoint URL: <code>https://pc0wd3fim2.execute-api.us-east-1.amazonaws.com/</code></li>
                <li>Create a <strong>Connection</strong> (e.g., <code>AnonymousConnection</code>) if no auth is needed</li>
                <li>Choose <strong>No authentication</strong> or <strong>API Key</strong> as required</li>
              </ul>
        
              <p>Then click <strong>Next</strong>, review, and <strong>Create rule</strong>.</p>
        
              <h4>‚úÖ Result</h4>
              <p>EventBridge will call your API endpoint every 5 minutes to prevent cold starts.</p>
        
              <h4>‚ö†Ô∏è Notes</h4>
              <ul>
                <li>Ensure the API doesn‚Äôt require a specific payload (default is empty).</li>
                <li>Monitor usage via CloudWatch Logs.</li>
                <li>You can also create a ‚Äúwarm-up Lambda‚Äù that pings the endpoint if more flexibility is needed.</li>
              </ul>
            </div>
          </li>
        
        

      <li data-id="q_lambda_pricing">
        <span class="faq-question">How does AWS Lambda pricing work?</span>
        <div class="answer">
          AWS Lambda charges are based on:
          <ul>
            <li><strong>Number of requests:</strong> First 1 million requests/month are free. After that, it's $0.20 per million requests.</li>
            <li><strong>Duration:</strong> Billed per millisecond from the time your code begins executing until it returns or otherwise terminates. Depends on the memory allocated.</li>
          </ul>
          Example: If your function runs for 200ms and uses 128MB memory, you only pay for that exact duration and size.
        </div>
      </li>
      
      <li data-id="q_lambda_triggers">
        <span class="faq-question">What triggers can invoke a Lambda function?</span>
        <div class="answer">
          Lambda can be triggered by various AWS services, including:
          <ul>
            <li>API Gateway (HTTP requests)</li>
            <li>S3 (file uploads, deletions)</li>
            <li>DynamoDB Streams</li>
            <li>SNS (notifications)</li>
            <li>SQS (queues)</li>
            <li>CloudWatch Events & Logs</li>
            <li>Cognito, Alexa Skills, EventBridge, etc.</li>
          </ul>
          Lambda can also be triggered manually using the AWS SDK or CLI.
        </div>
      </li>
      
      <li data-id="q_lambda_languages">
        <span class="faq-question">What are the supported languages in AWS Lambda?</span>
        <div class="answer">
          AWS Lambda natively supports:
          <ul>
            <li>Node.js</li>
            <li>Python</li>
            <li>Java</li>
            <li>Go</li>
            <li>C# (.NET Core)</li>
            <li>Ruby</li>
          </ul>
          It also supports custom runtimes and container images, allowing you to use any language.
        </div>
      </li>
      
      <li data-id="q_lambda_timeout">
        <span class="faq-question">What is the maximum execution time of a Lambda function?</span>
        <div class="answer">
          The maximum timeout for a Lambda function is <strong>15 minutes (900 seconds)</strong> per invocation. You can configure the timeout in the Lambda function settings depending on your use case.
        </div>
      </li>
      
      <li data-id="q_lambda_monitoring">
        <span class="faq-question">How do you monitor a Lambda function?</span>
        <div class="answer">
          Lambda integrates with AWS CloudWatch to provide monitoring:
          <ul>
            <li><strong>CloudWatch Logs:</strong> Automatically captures console output and errors.</li>
            <li><strong>CloudWatch Metrics:</strong> Tracks invocation count, duration, error count, throttles, and more.</li>
            <li><strong>CloudWatch Alarms:</strong> Trigger notifications based on metric thresholds.</li>
            <li><strong>X-Ray:</strong> For distributed tracing and performance analysis.</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_call_api_without_useeffect">
        <span class="faq-question">What is a cold start in AWS Lambda?</span>
        <div class="answer">
          A cold start occurs when AWS needs to create a new container to run your Lambda function‚Äîfor example, when there's no existing warm instance available. It includes the time taken to:
          <ul>
            <li>Provision the runtime container</li>
            <li>Download your function code</li>
            <li>Initialize dependencies</li>
          </ul>
          Cold starts introduce extra latency (usually 100ms‚Äì1s). They are more noticeable with VPC-configured or infrequently used functions.
        </div>
      </li>
      
      <li data-id="q_lambda_cold_start_optimization">
        <span class="faq-question">How can you reduce cold start time?</span>
        <div class="answer">
          You can reduce cold start time in AWS Lambda by:
          <ul>
            <li>Using lighter runtimes like Node.js or Go (faster startup)</li>
            <li>Minimizing initialization code and package size</li>
            <li>Keeping functions warm using scheduled CloudWatch Events</li>
            <li>Avoiding VPC connections unless required (or optimizing them)</li>
            <li>Using Provisioned Concurrency (pre-warms containers to eliminate cold starts)</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_lambda_sync_async">
        <span class="faq-question">What is the difference between synchronous and asynchronous invocation?</span>
        <div class="answer">
          <strong>Synchronous Invocation:</strong> Caller waits for the function to process and return a result. Example: API Gateway.<br />
          <strong>Asynchronous Invocation:</strong> Caller sends the request and continues without waiting for a response. Example: S3 or SNS.<br />
          <strong>Differences:</strong>
          <ul>
            <li>Synchronous = real-time; Asynchronous = event-based</li>
            <li>Synchronous errors are returned immediately; asynchronous are logged</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_lambda_concurrency">
        <span class="faq-question">How does concurrency work in Lambda?</span>
        <div class="answer">
          Concurrency is the number of instances that can run in parallel:
          <ul>
            <li><strong>Unreserved concurrency:</strong> Default limit shared across functions (e.g. 1000)</li>
            <li><strong>Reserved concurrency:</strong> Guarantees a specific number of concurrent executions for a function</li>
            <li><strong>Provisioned concurrency:</strong> Keeps containers initialized and ready to respond instantly</li>
          </ul>
          If concurrency limit is hit, excess requests are throttled.
        </div>
      </li>
      
      <li data-id="q_lambda_memory">
        <span class="faq-question">What is the default memory limit and how can it be changed?</span>
        <div class="answer">
          <strong>Default Memory:</strong> 128 MB<br />
          <strong>Range:</strong> 128 MB to 10,240 MB (10 GB), in 1 MB increments.<br />
          You can change it from:
          <ul>
            <li>AWS Console &rarr; Lambda &rarr; Configuration &rarr; Memory</li>
            <li>Or via CLI: <code>aws lambda update-function-configuration</code></li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_lambda_errors">
        <span class="faq-question">How do you handle errors in AWS Lambda?</span>
        <div class="answer">
          You can handle errors in Lambda using:
          <ul>
            <li><strong>Try-catch blocks:</strong> Handle exceptions in your code</li>
            <li><strong>Return meaningful error responses (for synchronous calls)</strong></li>
            <li><strong>Dead Letter Queues (DLQs):</strong> Capture failed async invocations</li>
            <li><strong>CloudWatch Logs:</strong> View stack traces and error details</li>
            <li><strong>Retries:</strong> Lambda automatically retries failed async events (2 times by default)</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_lambda_calls_lambda">
        <span class="faq-question">Can a Lambda function call another Lambda function?</span>
        <div class="answer">
          Yes, a Lambda function can invoke another Lambda using the AWS SDK or AWS CLI. This is useful for microservice architectures or function chaining.<br />
          Example in Node.js:
<pre>
const AWS = require('aws-sdk');
const lambda = new AWS.Lambda();
lambda.invoke({
  FunctionName: 'anotherLambdaFunction',
  Payload: JSON.stringify({ key: 'value' })
}, (err, data) => { ... });
</pre>
          Make sure the calling Lambda has the IAM permission <code>lambda:InvokeFunction</code>.
        </div>
      </li>
      
      <li data-id="q_lambda_version_alias">
        <span class="faq-question">How do you version and alias a Lambda function?</span>
        <div class="answer">
          <strong>Versioning:</strong> Every time you publish a function version, AWS creates an immutable snapshot of the code and configuration.<br />
          <strong>Alias:</strong> Acts as a pointer to a specific version. Useful for traffic shifting (e.g., <code>prod</code>, <code>beta</code> aliases).<br />
          Example:
          <ul>
            <li><code>$LATEST</code> ‚Üí Draft code</li>
            <li><code>1</code>, <code>2</code>, etc. ‚Üí Published versions</li>
            <li><code>alias: prod ‚Üí version: 5</code></li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_call_api_without_useeffect">
        <span class="faq-question">What is Lambda@Edge?</span>
        <div class="answer">
          Lambda@Edge is an extension of AWS Lambda that lets you run functions at AWS edge locations. It's integrated with Amazon CloudFront and is used for:
          <ul>
            <li>Customizing CDN content before it's delivered</li>
            <li>Implementing security/auth at the edge</li>
            <li>Personalizing content based on headers, cookies, etc.</li>
            <li>Modifying requests/responses without origin call</li>
          </ul>
          It improves performance and reduces latency by moving compute closer to the user.
        </div>
      </li>
      
    
      <li data-id="q_lambda_vs_ec2">
        <span class="faq-question">What is the difference between Lambda and EC2?</span>
        <div class="answer">
          <strong>AWS Lambda:</strong> Serverless, event-driven compute service. No server management; pay-per-invocation.<br />
          <strong>EC2:</strong> Virtual server in the cloud. You manage OS, scaling, patching.<br /><br />
          <strong>Key Differences:</strong>
          <ul>
            <li>Lambda is event-based; EC2 is instance-based</li>
            <li>Lambda scales automatically; EC2 needs manual or auto-scaling setup</li>
            <li>Lambda is billed per millisecond; EC2 is billed per second or hour</li>
            <li>Lambda can't be used for long-running tasks (max 15 minutes); EC2 can run indefinitely</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_lambda_deploy">
        <span class="faq-question">How do you deploy a Lambda function?</span>
        <div class="answer">
          You can deploy a Lambda function using:
          <ul>
            <li><strong>AWS Console:</strong> Upload .zip or use inline editor</li>
            <li><strong>AWS CLI:</strong> Use <code>aws lambda create-function</code> or <code>update-function-code</code></li>
            <li><strong>Infrastructure as Code:</strong> Tools like AWS SAM, Serverless Framework, Terraform, or CloudFormation</li>
            <li><strong>CI/CD Pipelines:</strong> Using CodePipeline, GitHub Actions, or Jenkins</li>
          </ul>
        </div>
      </li>
      
      <li data-id="q_lambda_env">
        <span class="faq-question">How can environment variables be used in Lambda?</span>
        <div class="answer">
          Lambda supports environment variables to:
          <ul>
            <li>Store config values (DB URLs, API keys, etc.)</li>
            <li>Separate environment-specific settings (dev, test, prod)</li>
          </ul>
          <strong>Access:</strong> Use <code>process.env.VARIABLE_NAME</code> in your function code.<br />
          <strong>Security:</strong> You can encrypt them using KMS and manage access with IAM policies.
        </div>
      </li>
      
      <li data-id="q_lambda_iam">
        <span class="faq-question">How does IAM relate to Lambda function permissions?</span>
        <div class="answer">
          AWS IAM (Identity and Access Management) controls who can:
          <ul>
            <li>Create, modify, delete Lambda functions</li>
            <li>Assign permissions to Lambda functions</li>
            <li>Invoke functions or access resources Lambda interacts with</li>
          </ul>
          Lambda uses <strong>execution roles</strong> (IAM roles) to interact with other AWS services securely.
        </div>
      </li>
      
      <li data-id="q_lambda_exec_role">
        <span class="faq-question">What is the Lambda execution role?</span>
        <div class="answer">
          The execution role is an IAM role assumed by the Lambda function at runtime. It defines:
          <ul>
            <li>Which AWS services the function can access (e.g., S3, DynamoDB)</li>
            <li>Permission to write logs to CloudWatch</li>
          </ul>
          <strong>Policy Example:</strong>
          <pre><code>{
        "Effect": "Allow",
        "Action": ["s3:GetObject", "logs:CreateLogStream"],
        "Resource": "*"
      }</code></pre>
        </div>
      </li>
      
      <li data-id="q_lambda_vpc">
        <span class="faq-question">How can you connect Lambda to VPC?</span>
        <div class="answer">
          Lambda can access private VPC resources (e.g., RDS, EC2) by assigning:
          <ul>
            <li>VPC ID</li>
            <li>Subnets with NAT Gateway (for internet access)</li>
            <li>Security groups (to control access)</li>
          </ul>
          This allows your Lambda to operate securely within your VPC.
        </div>
      </li>
      
      <li data-id="q_lambda_apigw">
        <span class="faq-question">How do you integrate AWS Lambda with API Gateway?</span>
        <div class="answer">
          You can expose your Lambda function via REST or HTTP APIs using API Gateway:
          <ul>
            <li>Create a REST API in API Gateway</li>
            <li>Define resources and methods (e.g., GET /users)</li>
            <li>Set integration type as Lambda function</li>
            <li>Deploy the API to a stage (e.g., /prod)</li>
          </ul>
          This setup allows clients to invoke Lambda functions over HTTPS.
        </div>
      </li>
      
      <li data-id="q_lambda_layers">
        <span class="faq-question">What is the use of the Lambda Layers feature?</span>
        <div class="answer">
          Lambda Layers are a way to package and reuse shared code or dependencies across multiple functions. Use cases:
          <ul>
            <li>Third-party libraries (e.g., bcrypt, pandas)</li>
            <li>Custom utility modules</li>
            <li>Large binaries or compiled packages</li>
          </ul>
          <strong>Benefits:</strong> Reduces deployment size and duplication across functions.
        </div>
      </li>
      
      <li data-id="q_lambda_vs_stepfunctions">
        <span class="faq-question">What is the difference between Lambda and Step Functions?</span>
        <div class="answer">
          <strong>AWS Lambda:</strong> Executes single tasks triggered by events.<br />
          <strong>AWS Step Functions:</strong> Orchestrates multiple AWS services/functions in workflows with logic.<br />
          <strong>Comparison:</strong>
          <ul>
            <li>Lambda = compute unit; Step Functions = workflow engine</li>
            <li>Step Functions handle retries, timeouts, branching, error catching</li>
            <li>Useful for building complex apps like ETL pipelines, order processing, etc.</li>
          </ul>
        </div>
      </li>
      

<li data-id="q_lambda_vs_stepfunctions">
<span class="faq-question green ">
  üß† What are AWS Step Functions in context of AWS Lambda?
</span>
<div class="answer">
  <p>
    AWS Step Functions is a <strong>visual workflow service</strong> that lets you coordinate multiple AWS services ‚Äî especially <strong>Lambda functions</strong> ‚Äî into <strong>serverless workflows</strong> using <strong>state machines</strong>.
  </p>
  
  <hr>
  
  <h3>üîÑ Use Case</h3>
  <p>You use Step Functions when you need to:</p>
  <ul>
    <li>Orchestrate multiple Lambda functions in sequence or parallel</li>
    <li>Handle retries, timeouts, and error-catching logic easily</li>
    <li>Implement workflows like:
      <ul>
        <li>Order processing</li>
        <li>Approval flows</li>
        <li>ETL pipelines</li>
        <li>ML model training</li>
      </ul>
    </li>
  </ul>
  
  <hr>
  
  <h3>üîß Example: Step Functions + AWS Lambda</h3>
  <h4>üéØ Workflow:</h4>
  <pre>
  User triggers workflow ‚Üí
    Step 1: Validate Order (Lambda)
    Step 2: Check Inventory (Lambda)
    Step 3: Charge Payment (Lambda)
    Step 4: Send Notification (Lambda)
  </pre>
  
  <hr>
  
  <h3>üßæ State Machine Definition (Amazon States Language - JSON)</h3>
  <pre><code>{
    "Comment": "Order Processing Workflow",
    "StartAt": "ValidateOrder",
    "States": {
      "ValidateOrder": {
        "Type": "Task",
        "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:ValidateOrder",
        "Next": "CheckInventory"
      },
      "CheckInventory": {
        "Type": "Task",
        "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:CheckInventory",
        "Next": "ChargePayment"
      },
      "ChargePayment": {
        "Type": "Task",
        "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:ChargePayment",
        "Next": "SendNotification"
      },
      "SendNotification": {
        "Type": "Task",
        "Resource": "arn:aws:lambda:REGION:ACCOUNT_ID:function:SendNotification",
        "End": true
      }
    }
  }
  </code></pre>
  
  <hr>
  
  <h3>‚úÖ Benefits</h3>
  <table border="1" cellpadding="5">
    <thead>
      <tr>
        <th>Feature</th>
        <th>Benefit</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Visual Workflows</td>
        <td>Easy to debug, visualize, and trace steps</td>
      </tr>
      <tr>
        <td>Error Handling</td>
        <td>Built-in retry, catch, and fallback states</td>
      </tr>
      <tr>
        <td>Sequential + Parallel</td>
        <td>Define series and branching flows</td>
      </tr>
      <tr>
        <td>Audit + Logging</td>
        <td>Integrated with CloudWatch Logs</td>
      </tr>
      <tr>
        <td>Pay-per-state</td>
        <td>Charged per state transition, cost-effective</td>
      </tr>
    </tbody>
  </table>
  
  <hr>
  
  <h3>üîê IAM Permissions</h3>
  <p>
    Each Lambda used in Step Functions must:
  </p>
  <ul>
    <li>Allow execution from Step Functions</li>
    <li>Be invoked with appropriate IAM roles</li>
  </ul>
  
  <hr>
  
  <h3>üß™ Bonus: Step Functions + Express Workflows</h3>
  <p>
    If you need faster execution and lower costs for short-duration tasks, use:
  </p>
  <ul>
    <li><strong>Express Workflows</strong> for high-volume, event-driven workloads</li>
    <li><strong>Standard Workflows</strong> for long-running workflows (up to 1 year)</li>
  </ul>
</div>
</li>








<li data-id="q122"><span class="faq-question green ">
  PostGre SQL + Redis : answer
</span><div class="answer">

<ol>
  <li data-id="q1">
    <span class="faq-question">How do Express.js, PostgreSQL, and Redis work together in a backend architecture?</span>
    <div class="answer">
      Express.js acts as the web application framework that handles HTTP requests and responses. PostgreSQL is the primary relational database used for storing persistent, structured data. Redis is used as an in-memory key-value store to cache frequently accessed data and reduce load on PostgreSQL. The flow typically works like this:
      <ul>
        <li>Client sends a request to Express.</li>
        <li>Express first checks Redis for cached data.</li>
        <li>If Redis has the data (cache hit), it is returned immediately.</li>
        <li>If not (cache miss), Express queries PostgreSQL, stores the result in Redis, and sends it to the client.</li>
        <li>When data is modified, the PostgreSQL DB is updated, and Redis is either invalidated or updated accordingly.</li>
      </ul>
    </div>
  </li>

  <li data-id="q2">
    <span class="faq-question green ">What are the common use cases for Redis when using PostgreSQL as the main DB?</span>
    <div class="answer">
      Redis complements PostgreSQL by providing fast, temporary data access for specific use cases:
      <ul>
        <li><strong>Caching:</strong> Store results of frequent or expensive PostgreSQL queries to reduce response time.</li>
        <li><strong>Rate Limiting:</strong> Count requests per user or IP for throttling purposes.</li>
        <li><strong>Session Management:</strong> Store user sessions or auth tokens for quick access.</li>
        <li><strong>Pub/Sub:</strong> Send real-time updates across services or clients.</li>
        <li><strong>Queueing:</strong> Manage background jobs and task queues with lists or streams.</li>
        <li><strong>Leaderboards:</strong> Use sorted sets for ranking data, which is difficult to do efficiently in SQL.</li>
      </ul>
    </div>
  </li>

  <li data-id="q3">
    <span class="faq-question">How do you structure an Express app to connect with PostgreSQL and Redis efficiently?</span>
    <div class="answer">
      A well-structured Express app should modularize database and cache logic for maintainability and performance:
      <ul>
        <li><strong>Connection Modules:</strong> Create separate files like <code>db.js</code> (for PostgreSQL) and <code>redisClient.js</code> (for Redis) to initialize and export connections.</li>
        <li><strong>Service Layer:</strong> Use a service layer to abstract business logic. For example, a userService that first checks Redis before querying PostgreSQL.</li>
        <li><strong>Environment Config:</strong> Use <code>dotenv</code> to load environment-specific DB credentials securely.</li>
        <li><strong>Error Handling:</strong> Implement error handling middleware to catch database or cache errors cleanly.</li>
        <li><strong>Cache TTL:</strong> Set Redis key expirations to avoid stale data.</li>
        <li><strong>Logging & Monitoring:</strong> Use tools like Winston or Morgan for logging, and Redis CLI or monitoring dashboards to track cache health.</li>
      </ul>
    </div>
  </li>



  
    <li data-id="allq">
      <span class="faq-question">When should you cache PostgreSQL queries with Redis?</span>
      <div class="answer">
        <p>
          You should cache PostgreSQL queries in Redis when:
        </p>
        <ul>
          <li>The query results are read-heavy and don't change frequently.</li>
          <li>Data is expensive to compute or involves complex joins or aggregations.</li>
          <li>You want to improve performance and reduce database load.</li>
          <li>You're working with public or semi-public data (e.g., product listings, blog posts).</li>
        </ul>
        <p>Examples include leaderboard data, search suggestions, or homepage feeds.</p>
      </div>
    </li>
  
    <li data-id="allq">
      <span class="faq-question">How do you invalidate a Redis cache when PostgreSQL data is updated?</span>
      <div class="answer">
        <p>
          To invalidate or update Redis cache when PostgreSQL data changes, use one of these strategies:
        </p>
        <ul>
          <li><strong>Write-through caching:</strong> Update both PostgreSQL and Redis simultaneously.</li>
          <li><strong>Cache invalidation:</strong> Delete the Redis key after the database update.</li>
          <li><strong>Time-to-live (TTL):</strong> Set expiration so outdated data is automatically purged.</li>
          <li><strong>Event-based invalidation:</strong> Use PostgreSQL triggers with NOTIFY/LISTEN or Kafka to signal cache clearing.</li>
        </ul>
      </div>
    </li>
  
    <li data-id="allq">
      <span class="faq-question">What are the main data types in PostgreSQL?</span>
      <div class="answer">
        <p>PostgreSQL supports a wide variety of data types including:</p>
        <ul>
          <li><strong>Numeric:</strong> <code>INTEGER</code>, <code>BIGINT</code>, <code>DECIMAL</code>, <code>NUMERIC</code>, <code>REAL</code></li>
          <li><strong>Character:</strong> <code>CHAR</code>, <code>VARCHAR</code>, <code>TEXT</code></li>
          <li><strong>Date/Time:</strong> <code>DATE</code>, <code>TIME</code>, <code>TIMESTAMP</code>, <code>INTERVAL</code></li>
          <li><strong>Boolean:</strong> <code>BOOLEAN</code></li>
          <li><strong>Geometric:</strong> <code>POINT</code>, <code>LINE</code>, <code>CIRCLE</code></li>
          <li><strong>JSON/JSONB:</strong> For structured documents</li>
          <li><strong>Array:</strong> For multi-valued columns</li>
          <li><strong>UUID, ENUM, HSTORE, XML:</strong> Specialized data types</li>
        </ul>
      </div>
    </li>

  



    
  <li data-id="allq">
    <span class="faq-question">What is the difference between VARCHAR, TEXT, and CHAR in PostgreSQL?</span>
    <div class="answer">
      <ul>
        <li><strong>VARCHAR(n):</strong> Variable-length string with a limit of <code>n</code> characters. Truncates if longer (optional constraint).</li>
        <li><strong>TEXT:</strong> Variable-length, unlimited size. No length constraint. Ideal for large strings.</li>
        <li><strong>CHAR(n):</strong> Fixed-length string. Padded with spaces if shorter than <code>n</code>. Useful in rare cases where fixed size is needed.</li>
      </ul>
      <p><strong>Best Practice:</strong> Use <code>TEXT</code> unless you have a specific reason to enforce a length limit.</p>
    </div>
  </li>

  <li data-id="allq">
    <span class="faq-question">How do you write a JOIN query in PostgreSQL?</span>
    <div class="answer">
      <p>Use the <code>JOIN</code> clause to combine rows from two or more tables based on a related column:</p>
      <pre><code>SELECT orders.id, customers.name
FROM orders
JOIN customers ON orders.customer_id = customers.id;</code></pre>
      <p><strong>Types of JOINs:</strong></p>
      <ul>
        <li><code>INNER JOIN</code> ‚Äì Matching records only</li>
        <li><code>LEFT JOIN</code> ‚Äì All from left table + matching from right</li>
        <li><code>RIGHT JOIN</code> ‚Äì All from right table + matching from left</li>
        <li><code>FULL OUTER JOIN</code> ‚Äì All from both sides</li>
      </ul>
    </div>
  </li>

  <li data-id="allq">
    <span class="faq-question">How does indexing work in PostgreSQL? What types of indexes are there?</span>
    <div class="answer">
      <p>
        Indexes in PostgreSQL improve read performance by allowing the database to locate rows faster.
        They are automatically used by the query planner when beneficial.
      </p>
      <p><strong>Types of Indexes:</strong></p>
      <ul>
        <li><strong>B-tree:</strong> Default index type, used for most queries (equality, range).</li>
        <li><strong>Hash:</strong> Optimized for equality only (<code>=</code>).</li>
        <li><strong>GIN (Generalized Inverted Index):</strong> For indexing array, JSONB, full-text search.</li>
        <li><strong>GiST:</strong> Spatial, geometric, full-text, or custom indexing.</li>
        <li><strong>BRIN (Block Range Index):</strong> Best for large tables with sequential data.</li>
        <li><strong>Expression Index:</strong> Indexing the result of an expression.</li>
        <li><strong>Partial Index:</strong> Index only a filtered subset of rows.</li>
      </ul>
    </div>
  </li>

  <li data-id="allq">
    <span class="faq-question">What is a composite index and when should you use it?</span>
    <div class="answer">
      <p>
        A <strong>composite index</strong> is an index on multiple columns. PostgreSQL uses the index from left to right.
      </p>
      <pre><code>CREATE INDEX idx_name ON orders (customer_id, order_date);</code></pre>
      <p><strong>When to use:</strong></p>
      <ul>
        <li>When queries often filter or sort by a combination of columns.</li>
        <li>When the leading column(s) are commonly used in WHERE clauses.</li>
        <li>To improve performance of multi-column JOINs or ORDER BYs.</li>
      </ul>
      <p><strong>Note:</strong> The order of columns matters. The index works best when queries use the leftmost columns first.</p>
    </div>
  </li>






    <li data-id="allq">
      <span class="faq-question">How does UPSERT work in PostgreSQL (ON CONFLICT)?</span>
      <div class="answer">
        <p>
          PostgreSQL supports <strong>UPSERT</strong> using the <code>INSERT ... ON CONFLICT</code> clause. This allows inserting a new row or updating it if a conflict occurs on a unique constraint or primary key.
        </p>
        <pre><code>
  INSERT INTO users (id, name, email)
  VALUES (1, 'John', 'john@example.com')
  ON CONFLICT (id)
  DO UPDATE SET name = EXCLUDED.name, email = EXCLUDED.email;
        </code></pre>
        <p><strong>Key points:</strong></p>
        <ul>
          <li><code>EXCLUDED</code> refers to the row that would have been inserted.</li>
          <li>Use <code>DO NOTHING</code> to skip the update if conflict occurs.</li>
        </ul>
      </div>
    </li>
  
    <li data-id="allq">
      <span class="faq-question">How do you create and use stored procedures in PostgreSQL?</span>
      <div class="answer">
        <p>
          Stored procedures encapsulate SQL logic that can be executed with a single call. PostgreSQL supports both functions and procedures.
        </p>
        <pre><code>
  -- Create a stored procedure
  CREATE OR REPLACE PROCEDURE log_message(msg TEXT)
  LANGUAGE plpgsql
  AS $$
  BEGIN
    INSERT INTO logs(message, created_at) VALUES (msg, NOW());
  END;
  $$;
  
  -- Call the procedure
  CALL log_message('System started');
        </code></pre>
        <p><strong>Note:</strong> Use <code>CALL</code> for procedures and <code>SELECT</code> for functions.</p>
      </div>
    </li>
  
    <li data-id="allq">
      <span class="faq-question">How do transactions work in PostgreSQL and how are they handled in Node.js?</span>
      <div class="answer">
        <p>
          A transaction is a block of SQL operations that are executed as a single unit. In PostgreSQL, you can use:
        </p>
        <pre><code>
  BEGIN;
  UPDATE accounts SET balance = balance - 100 WHERE id = 1;
  UPDATE accounts SET balance = balance + 100 WHERE id = 2;
  COMMIT;
        </code></pre>
        <p>
          If an error occurs, use <code>ROLLBACK</code> to undo the changes.
        </p>
        <p><strong>In Node.js (using pg):</strong></p>
        <pre><code>
  const client = await pool.connect();
  try {
    await client.query('BEGIN');
    await client.query('UPDATE ...');
    await client.query('UPDATE ...');
    await client.query('COMMIT');
  } catch (e) {
    await client.query('ROLLBACK');
    throw e;
  } finally {
    client.release();
  }
        </code></pre>
      </div>
    </li>
  
    <li data-id="allq">
      <span class="faq-question">What are triggers and when would you use them in PostgreSQL?</span>
      <div class="answer">
        <p>
          Triggers are functions that are automatically executed in response to certain events on a table (e.g., <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>).
        </p>
        <p><strong>Use cases:</strong></p>
        <ul>
          <li>Audit logging</li>
          <li>Enforcing business rules</li>
          <li>Auto-updating timestamp columns</li>
          <li>Syncing related tables</li>
        </ul>
        <pre><code>
  -- Create a trigger function
  CREATE OR REPLACE FUNCTION update_modified_column()
  RETURNS TRIGGER AS $$
  BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
  END;
  $$ LANGUAGE plpgsql;
  
  -- Attach it to a table
  CREATE TRIGGER update_modified
  BEFORE UPDATE ON users
  FOR EACH ROW
  EXECUTE FUNCTION update_modified_column();
        </code></pre>
      </div>
    </li>

    
  
 
    
      <li data-id="allq">
        <span class="faq-question">How do you implement pagination using LIMIT and OFFSET in PostgreSQL?</span>
        <div class="answer">
          <p>Pagination is done using the <code>LIMIT</code> and <code>OFFSET</code> clauses in PostgreSQL:</p>
          <pre><code>
    -- Page 1 (first 10 records)
    SELECT * FROM users
    ORDER BY id
    LIMIT 10 OFFSET 0;
    
    -- Page 2 (next 10 records)
    SELECT * FROM users
    ORDER BY id
    LIMIT 10 OFFSET 10;
          </code></pre>
          <p><strong>Best Practices:</strong></p>
          <ul>
            <li>Always use <code>ORDER BY</code> for consistent results.</li>
            <li>OFFSET can be slow for large pages. For better performance, consider <strong>keyset pagination</strong> using a WHERE clause and last seen ID.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="allq">
        <span class="faq-question">What is the difference between row-level and table-level locking?</span>
        <div class="answer">
          <ul>
            <li><strong>Row-level locking:</strong> Locks only the specific rows being modified or selected <code>FOR UPDATE</code>. Allows high concurrency.</li>
            <li><strong>Table-level locking:</strong> Locks the entire table. Prevents all reads/writes depending on the lock mode. Used by commands like <code>LOCK TABLE</code>.</li>
          </ul>
          <p><strong>Example:</strong></p>
          <pre><code>
    -- Row-level lock
    SELECT * FROM users WHERE id = 5 FOR UPDATE;
    
    -- Table-level lock
    LOCK TABLE users IN ACCESS EXCLUSIVE MODE;
          </code></pre>
          <p><strong>Tip:</strong> PostgreSQL handles row-level locking automatically during <code>UPDATE</code>/<code>DELETE</code>.</p>
        </div>
      </li>
    
      <li data-id="allq">
        <span class="faq-question">What is a CTE (Common Table Expression) and how do you use it?</span>
        <div class="answer">
          <p>
            A <strong>CTE (Common Table Expression)</strong> is a temporary result set that you can reference within a <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> query.
          </p>
          <pre><code>
    WITH recent_orders AS (
      SELECT * FROM orders
      WHERE order_date > CURRENT_DATE - INTERVAL '7 days'
    )
    SELECT * FROM recent_orders
    WHERE total_amount > 100;
          </code></pre>
          <p><strong>Why use CTEs?</strong></p>
          <ul>
            <li>Improves readability of complex queries</li>
            <li>Allows recursive queries</li>
            <li>Helps structure modular logic</li>
          </ul>
          <p><strong>Recursive CTE Example:</strong></p>
          <pre><code>
    WITH RECURSIVE nums AS (
      SELECT 1 AS n
      UNION ALL
      SELECT n + 1 FROM nums WHERE n < 5
    )
    SELECT * FROM nums;
          </code></pre>
        </div>
      </li>

      
      
        <li data-id="allq">
          <span class="faq-question">Explain the use of WITH queries in PostgreSQL.</span>
          <div class="answer">
            <p>
              <strong>WITH queries</strong>, also known as <strong>Common Table Expressions (CTEs)</strong>, allow you to define temporary result sets that can be referenced within a main SQL query.
            </p>
            <pre><code>
      WITH top_users AS (
        SELECT id, name, total_purchases
        FROM users
        WHERE total_purchases > 1000
      )
      SELECT * FROM top_users
      ORDER BY total_purchases DESC;
            </code></pre>
            <p><strong>Benefits:</strong></p>
            <ul>
              <li>Improves readability and modularizes complex queries</li>
              <li>Reusable in the same query</li>
              <li>Can be recursive (useful for tree/graph structures)</li>
            </ul>
          </div>
        </li>
      
        <li data-id="allq">
          <span class="faq-question">What is the purpose of PostgreSQL extensions like pg_stat_statements or uuid-ossp?</span>
          <div class="answer">
            <p><strong>PostgreSQL extensions</strong> enhance database functionality. Two useful ones include:</p>
            <ul>
              <li><strong>pg_stat_statements:</strong> Collects and tracks execution statistics for all SQL queries. Helps identify slow or frequent queries.</li>
              <li><strong>uuid-ossp:</strong> Generates UUIDs (Universally Unique Identifiers). Useful for creating unique keys in distributed systems.</li>
            </ul>
            <p><strong>Example:</strong></p>
            <pre><code>
      -- Enable extension
      CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
      CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
      
      -- Generate a UUID
      SELECT uuid_generate_v4();
            </code></pre>
          </div>
        </li>
      
        <li data-id="allq">
          <span class="faq-question">How do you optimize slow queries in PostgreSQL?</span>
          <div class="answer">
            <p><strong>To optimize slow queries in PostgreSQL:</strong></p>
            <ul>
              <li>Use <code>EXPLAIN ANALYZE</code> to analyze query execution plans.</li>
              <li>Ensure proper indexing on frequently filtered/sorted columns.</li>
              <li>Avoid SELECT * ‚Äî fetch only needed columns.</li>
              <li>Use <code>JOIN</code> instead of subqueries where possible.</li>
              <li>Denormalize data when necessary for performance.</li>
              <li>Apply caching for expensive queries using Redis or Materialized Views.</li>
              <li>Use CTEs or subqueries to simplify and reduce redundant operations.</li>
              <li>Check for sequential scans and add indexes if necessary.</li>
            </ul>
            <p><strong>Example:</strong></p>
            <pre><code>
      EXPLAIN ANALYZE
      SELECT * FROM orders WHERE customer_id = 5;
            </code></pre>
            <p>Look at the execution plan to see whether indexes are being used and how long each step takes.</p>
          </div>
        </li>
        
       








</ol>

</div></li>


<li data-id="q122" class="yellow"><span class="faq-question">
Redis Question-Answer
</span>

<div class="answer">
  <ol>
    <li data-id="redddd454554ooi">
      <span class="faq-question">Redis Question?</span>
      <div class="answer">
  <ol>
    <li>What is Redis and what are its primary use cases?</li>
    <li>Is Redis a database, cache, or message broker?</li>
    <li>How is Redis different from other databases like MySQL or MongoDB?</li>
    <li>What are the data structures supported by Redis?</li>
    <li>Is Redis single-threaded or multi-threaded?</li>
    <li>What is the maximum size of a Redis key and value?</li>
    <li>What is the default port Redis runs on?</li>
    <li>What is the difference between Redis and Memcached?</li>
    <li>How does Redis store data in memory?</li>
    <li>Can Redis be used for persistent storage?</li>
  
    <li>What is a Redis string and what operations can be performed on it?</li>
    <li>What is a Redis list? How is it different from a set?</li>
    <li>Explain Redis set and its use cases.</li>
    <li>What are sorted sets in Redis?</li>
    <li>What is a Redis hash and when should you use it?</li>
    <li>Can you perform range queries in Redis? If yes, how?</li>
    <li>How would you store and access a JSON object in Redis?</li>
  
    <li>What is Redis Pub/Sub? Give an example use case.</li>
    <li>What is a Redis stream?</li>
    <li>Explain Redis HyperLogLog.</li>
    <li>What is a Redis bitmap?</li>
    <li>What is Redis GEO data structure used for?</li>
    <li>How can you expire keys in Redis?</li>
    <li>What is the difference between DEL and UNLINK?</li>
  
    <li>How do you ensure Redis performs optimally under high load?</li>
    <li>What are Redis eviction policies?</li>
    <li>Explain Lazy vs Eager expiration in Redis.</li>
    <li>What are Redis memory optimization techniques?</li>
    <li>How to handle large datasets in Redis?</li>
    <li>How do you monitor Redis performance?</li>
  
    <li>What are RDB and AOF in Redis?</li>
    <li>What are the differences between RDB and AOF persistence mechanisms?</li>
    <li>Can Redis use both RDB and AOF at the same time?</li>
    <li>How does Redis handle data recovery after a crash?</li>
    <li>What is the SAVE and BGSAVE command in Redis?</li>
  
    <li>How are transactions handled in Redis?</li>
    <li>What are the commands used to start and execute a transaction in Redis?</li>
    <li>What is the use of WATCH in Redis?</li>
    <li>Can you use Lua scripting in Redis? Why and how?</li>
    <li>Is Redis transaction atomic?</li>
  
    <li>What is Redis Sentinel?</li>
    <li>What is Redis Cluster and how does it work?</li>
    <li>What is the difference between Redis replication and clustering?</li>
    <li>How does Redis handle failover?</li>
    <li>How does Redis shard data in a cluster?</li>
  
    <li>How can you secure a Redis instance?</li>
    <li>How do you configure password authentication in Redis?</li>
    <li>Can Redis be used over SSL/TLS?</li>
    <li>What are some Redis configuration best practices?</li>
    <li>How do you backup and restore Redis data?</li>
    </ol>
    </div></li>


<li data-id="q122redissss"><span class="faq-question green">
  Redis Answer
  </span><div class="answer">

    




</div></li>







</ol>

</div></li>



  <li data-id="allq">
    <span class="faq-question">What is Redis and what are its primary use cases?</span>
    <div class="answer">
      Redis is an open-source, in-memory data structure store used as a database, cache, and message broker.
      It‚Äôs commonly used for:
      <ul>
        <li>Caching frequently accessed data</li>
        <li>Session storage for web applications</li>
        <li>Real-time analytics and counters</li>
        <li>Pub/Sub messaging systems</li>
        <li>Leaderboard and ranking implementations</li>
      </ul>
    </div>
    <div class="answer">
      Redis excels at real-time analytics and counters because it's an in-memory store with extremely fast read/write operations. These are use cases where high-speed data updates are needed constantly, like:
<pre>
  Counting page views
  Tracking video plays
  Live user activity metrics
  Click-through tracking
  API rate limiting
</pre>
    </div>
  </li>


<li data-id="q122redissss"><span class="faq-question">Is Redis a database, cache, or message broker?</span><div class="answer">
  Redis is all three. It can be used as an in-memory NoSQL database, a high-performance cache, and a lightweight message broker via Pub/Sub.

<ol>

  <li data-id="q122redissss"><span class="faq-question">How is Redis different from other databases like MySQL or MongoDB?</span><div class="answer">
    Redis stores all data in memory, enabling ultra-fast access. It supports complex data types like lists and sets, lacks traditional table-based schemas, and is optimized for speed rather than storage size or relational queries.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What are the data structures supported by Redis?</span><div class="answer">
    Strings, Lists, Sets, Sorted Sets (ZSets), Hashes, Bitmaps, HyperLogLogs, Streams, and GEO data.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">Is Redis single-threaded or multi-threaded?</span><div class="answer">
    Redis is single-threaded for most operations to ensure simplicity and predictability, but Redis 6+ supports multi-threaded I/O.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What is the maximum size of a Redis key and value?</span><div class="answer">
    The maximum key size is 512 MB; the value size can also be up to 512 MB for strings.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What is the default port Redis runs on?</span><div class="answer">
    Port 6379.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What is the difference between Redis and Memcached?</span><div class="answer">
    Redis supports more data types, persistence, replication, and scripting. Memcached is simpler and only stores strings in memory.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">How does Redis store data in memory?</span><div class="answer">
    Redis stores all data in RAM using a variety of compact data structures and encodings for high performance.
  </div></li>
  

</ol>


</div></li>

<li data-id="q122redissss"><span class="faq-question">Can Redis be used for persistent storage?</span><div class="answer">
  Yes, Redis supports two persistence mechanisms: RDB (snapshotting) and AOF (Append Only File).

<ol>


  <li data-id="q122redissss"><span class="faq-question">What is a Redis string and what operations can be performed on it?</span><div class="answer">
    A string is the most basic data type and can store any binary data up to 512 MB. Operations: GET, SET, INCR, APPEND, etc.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What is a Redis list? How is it different from a set?</span><div class="answer">
    A list is an ordered collection of strings. A set is an unordered collection of unique strings.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">Explain Redis set and its use cases.</span><div class="answer">
    A set is an unordered collection of unique elements. Use cases include tagging, deduplication, and membership checks.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What are sorted sets in Redis?</span><div class="answer">
    A sorted set is a collection of unique elements ordered by a score. Use cases: leaderboards, ranking systems.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">What is a Redis hash and when should you use it?</span><div class="answer">
    A hash is a mapping between string fields and values, useful for storing objects like user profiles.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">Can you perform range queries in Redis? If yes, how?</span><div class="answer">
    Yes, using Sorted Sets with commands like ZRANGE, ZREVRANGE, and ZRANGEBYSCORE.
  </div></li>
  
  <li data-id="q122redissss"><span class="faq-question">How would you store and access a JSON object in Redis?</span><div class="answer">
    You can store it as a stringified JSON in a string key or use Redis modules like RedisJSON.
  </div></li>
  

</ol>

</div></li>

<li data-id="q122redissss"><span class="faq-question">What is Redis Pub/Sub? Give an example use case.</span><div class="answer">
  Pub/Sub allows messages to be published to channels and received by subscribers. Example: real-time notifications.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is a Redis stream?</span><div class="answer">
  A log-like data structure used for storing time-ordered events, suitable for messaging and event sourcing.
</div></li>

<li data-id="q122redissss"><span class="faq-question">Explain Redis HyperLogLog.</span><div class="answer">
  A probabilistic data structure for approximate cardinality counting (e.g., unique visitors) with minimal memory.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is a Redis bitmap?</span><div class="answer">
  Bitmaps allow you to set and check bits at given offsets in strings; used for tracking binary states compactly.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is Redis GEO data structure used for?</span><div class="answer">
  To store and query geographic locations by longitude and latitude using commands like GEOADD and GEORADIUS.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How can you expire keys in Redis?</span><div class="answer">
  Use EXPIRE, SETEX, or TTL to set and manage time-to-live (TTL) on keys.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is the difference between DEL and UNLINK?</span><div class="answer">
  DEL deletes the key synchronously, while UNLINK deletes asynchronously to avoid blocking the event loop.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How do you ensure Redis performs optimally under high load?</span><div class="answer">
  Use efficient data structures, enable persistence wisely, tune memory limits, and consider clustering or sharding.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What are Redis eviction policies?</span><div class="answer">
  Policies used when memory limit is reached: noeviction, allkeys-lru, volatile-lru, allkeys-random, etc.
</div></li>

<li data-id="q122redissss"><span class="faq-question">Explain Lazy vs Eager expiration in Redis.</span><div class="answer">
  Lazy expiration removes keys only when accessed; eager expiration removes expired keys periodically in the background.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What are Redis memory optimization techniques?</span><div class="answer">
  Use smaller key/value names, appropriate data encodings, Redis modules like RedisJSON, and memory policies.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How to handle large datasets in Redis?</span><div class="answer">
  Use clustering, compress data, offload large blobs to other storage, and keep only hot data in Redis.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How do you monitor Redis performance?</span><div class="answer">
  Use tools like Redis CLI (INFO), RedisInsight, Prometheus + Grafana, and built-in metrics.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What are RDB and AOF in Redis?</span><div class="answer">
  RDB (snapshotting) saves the DB at intervals; AOF logs every write operation. Both are for persistence.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What are the differences between RDB and AOF persistence mechanisms?</span><div class="answer">
  RDB is faster for recovery and saves at intervals; AOF is safer for durability and logs every operation.
</div></li>

<li data-id="q122redissss"><span class="faq-question">Can Redis use both RDB and AOF at the same time?</span><div class="answer">
  Yes, Redis can be configured to use both for improved durability and faster recovery.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How does Redis handle data recovery after a crash?</span><div class="answer">
  Redis reloads data from the AOF file or latest RDB snapshot during startup.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is the SAVE and BGSAVE command in Redis?</span><div class="answer">
  SAVE performs a synchronous snapshot; BGSAVE runs it in the background to avoid blocking.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How are transactions handled in Redis?</span><div class="answer">
  Transactions are supported using MULTI, EXEC, DISCARD, and WATCH, but without rollback.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What are the commands used to start and execute a transaction in Redis?</span><div class="answer">
  MULTI (start), followed by commands, then EXEC (execute) or DISCARD (abort).
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is the use of WATCH in Redis?</span><div class="answer">
  WATCH monitors keys for changes and aborts the transaction if any watched key is modified before EXEC.
</div></li>

<li data-id="q122redissss"><span class="faq-question">Can you use Lua scripting in Redis? Why and how?</span><div class="answer">
  Yes. Lua scripts ensure atomicity and are executed using the EVAL command. Useful for batch operations.
</div></li>

<li data-id="q122redissss"><span class="faq-question">Is Redis transaction atomic?</span><div class="answer">
  Yes. A Redis transaction is atomic, meaning all commands inside MULTI/EXEC are executed sequentially without interference.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is Redis Sentinel?</span><div class="answer">
  Sentinel provides high availability by monitoring Redis instances and performing automatic failover.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is Redis Cluster and how does it work?</span><div class="answer">
  Redis Cluster provides horizontal partitioning (sharding) and high availability without external tools.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What is the difference between Redis replication and clustering?</span><div class="answer">
  Replication copies data to slaves; clustering partitions data across nodes for scalability and fault tolerance.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How does Redis handle failover?</span><div class="answer">
  Redis Sentinel detects failures and promotes a replica to master. Cluster nodes also have failover logic.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How does Redis shard data in a cluster?</span><div class="answer">
  It uses a hash slot algorithm (0‚Äì16383 slots) and distributes keys based on CRC16 hash.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How can you secure a Redis instance?</span><div class="answer">
  Use strong passwords, rename dangerous commands, bind to localhost, enable TLS, and use firewalls.
</div></li>

<li data-id="q122redissss"><span class="faq-question">How do you configure password authentication in Redis?</span><div class="answer">
  Set the <code>requirepass</code> option in <code>redis.conf</code> or with the CONFIG SET command.
</div></li>

<li data-id="q122redissss"><span class="faq-question">Can Redis be used over SSL/TLS?</span><div class="answer">
  Yes. Redis supports TLS natively since version 6.0, or via stunnel/proxy for older versions.
</div></li>

<li data-id="q122redissss"><span class="faq-question">What are some Redis configuration best practices?</span><div class="answer">
  Use maxmemory settings, persistence tuning, password protection, appropriate eviction policy, and monitoring tools.
</div></li>

<li data-id="q122redissss"><span class="faq-question green">How do you backup and restore Redis data?</span><div class="answer">
  Back up by copying the dump.rdb or appendonly.aof files. Restore by placing them in the Redis directory and restarting the server.
</div></li>








<li data-id="q3"><span class="faq-question">---------------------------------------</span><br /><span class="faq-question">---------------------------------------</span></li>    
<li data-id="q3"><span class="faq-question">
a == b ?
</span><div class="answer">
const a = { name: "Ram" };<br />
const b = { name: "Ram" };<br />
console.log(a == b); // false<br />
JSON.stringify(a) === JSON.stringify(b); // true<br />
const _ = require('lodash');<br />
_.isEqual(a, b); // true<br />
</div></li>
    

<li data-id="q3"><span class="faq-question">---------------------------------------</span><br /><span class="faq-question">---------------------------------------</span></li>    
<li data-id="q3"><span class="faq-question">
What are the key features of Node.js?
</span><div class="answer">
Key features include asynchronous and event-driven architecture, single-threaded model, fast execution via V8 engine, non-blocking I/O, npm (Node package manager), and the ability to build scalable network applications.
</div></li>

<li data-id="q4"><span class="faq-question">
Difference between require() and import?
</span><div class="answer">
`require()` is CommonJS syntax used in Node.js; it loads modules synchronously. `import` is ES6 syntax, used with modules, supports static analysis, and is asynchronous. `import` requires `"type": "module"` in `package.json`.
</div></li>


<li data-id="q6"><span class="faq-question">
non-blocking I/O?
</span><div class="answer">
Non-blocking I/O allows Node.js to continue executing other code while waiting for I/O operations (like reading files or querying databases) to complete, improving efficiency and scalability.
</div></li>

<li data-id="q7"><span class="faq-question">
How do you handle asynchronous code in Node.js?
</span><div class="answer">
Asynchronous code can be handled using callbacks, Promises, or `async/await`. These techniques prevent blocking the event loop and ensure smooth execution of concurrent tasks.
</div></li>




<li data-id="q10"><span class="faq-question">
the purpose of package.json?
</span><div class="answer">
`package.json` holds metadata about a Node.js project, including dependencies, scripts, version, main file, and more. It helps manage packages and project configuration.
</div></li>

<li data-id="q11"><span class="faq-question">
Explain the EventEmitter in Node.js.
</span><div class="answer">
`EventEmitter` is a core Node.js module that facilitates communication via events. You can create custom events using `emit()` and subscribe using `on()` or `once()`.
</div></li>







<li data-id="q15"><span class="faq-question">
How do you implement authentication in Node.js (e.g., JWT)?
</span><div class="answer">
Use `jsonwebtoken` to issue and verify JWT tokens. On login, generate a token and send it to the client. For protected routes, use middleware to verify the token.
</div></li>

<li data-id="q16"><span class="faq-question">
What are memory leaks in Node.js and how can you prevent them?
</span><div class="answer">
Memory leaks occur when memory is not released. Common causes include unused references, event listeners, or closures. Use tools like `clinic`, `heapdump`, and `--inspect` to detect and prevent them.
</div></li>

<li data-id="q17"><span class="faq-question">
How do you manage environment variables in Node.js?
</span><div class="answer">
Use `.env` files with the `dotenv` package. Load variables using `require('dotenv').config()` and access them via `process.env.VARIABLE_NAME`.
</div></li>

<li data-id="q18"><span class="faq-question">
the difference between spawn(), exec(), and fork()?
</span><div class="answer">
- `spawn()`: launches a new process, streams output.  
- `exec()`: buffers entire output in memory.  
- `fork()`: spawns a new Node.js process with IPC for communication.
</div></li>




<li data-id="q21"><span class="faq-question">
How does Node.js handle async I/O under the hood (libuv)?
</span><div class="answer">
libuv is a C library that manages thread pool and async I/O. It delegates I/O operations to the OS or internal threads and notifies Node.js when operations complete.
</div></li>



<li data-id="q23"><span class="faq-question">
backpressure in Node.js streams and how to handle it?
</span><div class="answer">
Backpressure occurs when the writable stream can't handle the data speed of a readable stream. Use `stream.pause()`, `drain` events, and `pipe()` for flow control.
</div></li>


<li data-id="q25"><span class="faq-question">
Explain process-level error handling (uncaughtException, unhandledRejection).
</span><div class="answer">
`process.on('uncaughtException')` and `process.on('unhandledRejection')` catch unhandled errors globally. Prefer local error handling; use these for logging and graceful shutdowns.
</div></li>

<li data-id="q26"><span class="faq-question">
How to implement custom events using EventEmitter?
</span><div class="answer">
Create an `EventEmitter` instance, emit events using `.emit('eventName', data)`, and listen using `.on('eventName', callback)`. Useful for decoupling logic.
</div></li>

<li data-id="q27"><span class="faq-question">
What are the differences between microservices and monoliths in a Node.js context?
</span><div class="answer">
Monoliths bundle all logic in one app. Microservices split features into independent services communicating via APIs or messages. Microservices are scalable, but complex to manage.
</div></li>



<li data-id="q29"><span class="faq-question">
Explain the concept of middleware chaining in Express.js.
</span><div class="answer">
Middleware chaining lets multiple functions process a request sequentially. Each middleware calls `next()` to pass control. Useful for validations, authentication, and logging.
</div></li>

<li data-id="q30"><span class="faq-question">
a memory heap and how do you analyze it in Node.js?
</span><div class="answer">
A memory heap is the area where memory is allocated for objects. Analyze it using Chrome DevTools, Node.js `--inspect` flag, or memory profiling tools like `heapdump`.
</div></li>




<li data-id="q_call_api_after_unmount"><span class="faq-question">
How to call an API after a React component unmounts?
</span><div class="answer">
Calling an API <em>after</em> a component unmounts is generally discouraged because the component no longer exists to handle the response.

However, if needed, you can trigger a side effect in the cleanup function of <code>useEffect</code>:

<pre><code>
useEffect(() => {
return () => {
// Cleanup function called on unmount
fetch('/api/endpoint', { method: 'POST' })
.then(res => console.log('API called on unmount'))
.catch(err => console.error(err));
};
}, []);
</code></pre>

Note: The API call may be canceled if the component unmounts abruptly, so it‚Äôs better handled outside React, e.g., in global state or services.
</div></li>


<li data-id="q_call_api_without_useeffect"><span class="faq-question">
How to call an API without using useEffect in React?
</span><div class="answer">
You can call an API without <code>useEffect</code> by triggering the fetch inside event handlers, lifecycle methods (class components), or directly within functions.

Examples:

1. Inside an event handler (e.g., onClick):
<pre><code>
function MyComponent() {
const fetchData = () => {
fetch('/api/data')
.then(res => res.json())
.then(data => console.log(data));
};

return &lt;button onClick={fetchData}&gt;Fetch Data&lt;/button&gt;;
}
</code></pre>

2. In class components, call API in <code>componentDidMount()</code> instead of <code>useEffect</code>.

Direct API calls in render are discouraged to avoid repeated calls on every render.
</div></li>





<ul class="faq">
  <li data-id="q123">
    <span class="faq-question">Shadow copy?</span>
    <div class="answer">
      A <strong>shadow copy</strong> (also known as a **snapshot** or **Volume Shadow Copy**) refers to a backup or snapshot of computer files or volumes, even when they are in use. It is primarily used in Windows operating systems for backup and restore purposes.

      <br><br><strong>Key points:</strong>
      <ul>
        <li>Created using the <code>Volume Shadow Copy Service (VSS)</code>.</li>
        <li>Allows consistent backups of files that are currently in use (e.g., databases).</li>
        <li>Used by features like System Restore, Backup and Restore, and third-party backup software.</li>
        <li>Can be scheduled or triggered manually by system tools or scripts.</li>
      </ul>

      <strong>Use cases:</strong>
      <ul>
        <li>Restoring previous versions of files/folders.</li>
        <li>Backing up live databases or application data without downtime.</li>
      </ul>

      <strong>Command example (Windows CLI):</strong>
      <pre><code>vssadmin list shadows</code></pre>

      <strong>Note:</strong> Shadow copy is a system-level feature and not directly related to JavaScript or Node.js, unless interacting with system-level APIs or performing native operations.
    </div>
  </li>
</ul>


<li data-id="q3">
  <span class="faq-question">What is a TypeScript function? Can you give an example?</span>
  <div class="answer">
    <p>A TypeScript function is similar to a JavaScript function but supports static typing.</p>
    <pre>

      <code>

        function add(a: number, b?: string): string {
          if (b) {
            return `${a} and ${b}`;
          } else {
            return `${a}`;
          }
        }
        
        // Usage examples
        console.log(add(5));        // Output: "5"
        console.log(add(5, "test")); // Output: "5 and test"
        

      </code>

<code>
// Function that adds two numbers and returns a number
function add(a: number, b: number): number {
  return a + b;
}

// Usage
const result = add(5, 10);
console.log(result);  // Output: 15
</code>
    </pre>
  </div>
</li>









<li data-id="q_call_api_without_useeffect"><span class="faq-question222">------------------------------------------<br />-----------------------------
</span><div class="answer"></div></li>







<li data-id="q_call_api_without_useeffect"><span class="faq-question232">------------------------------------------<br />-----------------------------
</span><div class="answer"></div></li>
<li data-id="q_call_api_without_useeffect"><span class="faq-question234234">------------------------------------------<br />-----------------------------
</span><div class="answer"></div></li>



<li data-id="dsfsdfsdq41">
  <span class="faq-question green">How do I use Express with cron jobs, PostgreSQL, and Redis?</span>
  <div class="answer">
    <p>You can schedule background jobs in an Express.js app using <strong>node-cron</strong> to interact with a PostgreSQL database and use Redis for caching.</p>

    
<pre>
  <b>üîß Key Technologies</b>
  1. <b>express</b> ‚Äì for HTTP server
  2. <b>node-cron</b> ‚Äì for scheduling
  3. <b>pg</b> ‚Äì PostgreSQL client
  4. <b>redis</b> ‚Äì in-memory cache

  <b>üìå Summary</b>
  1. Use <b>node-cron</b> for job scheduling
  2. Query and update tasks using <b>pg</b>
  3. Cache or flag task state using <b>redis</b>
  4. Integrate everything inside an <b>Express.js</b> server

  This approach is great for building background task runners, notification schedulers, or lightweight job queues.
</pre>

<pre>
  <b>üì¶ Install Dependencies</b>
  npm install express pg redis node-cron
  npm install -D @types/node @types/express
</pre>
    
<pre>
  <b>üóÇÔ∏è Project Structure</b>
  /src
  ‚îú‚îÄ‚îÄ index.ts       ‚Üê Express app
  ‚îú‚îÄ‚îÄ cronJob.ts     ‚Üê Cron logic
  ‚îî‚îÄ‚îÄ db.ts          ‚Üê PostgreSQL + Redis connection
</pre>

<pre>
  <b>üîå db.ts</b>
  import { Pool } from 'pg';
  import { createClient } from 'redis';

  export const pg = new Pool({
    user: 'postgres',
    host: 'localhost',
    database: 'your_db',
    password: 'your_password',
    port: 5432
  });

  export const redis = createClient();
  redis.connect();
</pre>

<pre>
  <b>‚è∞ cronJob.ts</b>
  import cron from 'node-cron';
  import { pg, redis } from './db';

  export const startCron = () => {
    <b class="green">cron.schedule('* * * * *', async () => {</b>
      console.log('Cron job started');
      try {
        const { rows } = await pg.query("SELECT * FROM tasks WHERE status = 'pending'");
        for (const task of rows) {
          await pg.query("UPDATE tasks SET status = 'done' WHERE id = $1", [task.id]);
          await redis.set(`task:${task.id}`, JSON.stringify(task));
        }
        console.log('Cron job finished');
      } catch (err) {
        console.error('Cron error:', err);
      }
    });
  };
</pre>

<pre>
  <b>üöÄ index.ts</b>
  import express from 'express';
  import { startCron } from './cronJob';

    const app = express();
    app.use(express.json());

    app.get('/', (req, res) => res.send('Server running'));

    startCron();

    app.listen(3000, () => console.log('Server at http://localhost:3000'));
</pre>

<pre>
  <b>üóÑÔ∏è PostgreSQL Table</b>
  CREATE TABLE tasks (
                  id SERIAL PRIMARY KEY,
                  description TEXT,
                  status VARCHAR(20) DEFAULT 'pending'
              );

</pre>


  </div>
</li>




  <li data-id="q300" class="yellow" ><span class="faq-question">
  Mongo DB Question List
  </span><div class="answer">
  <ol>
      <li><strong>What is MongoDB</strong></li>
      <li><strong>What are the key features of MongoDB?</strong></li>
      <li><strong>What is a Document in MongoDB?</strong></li>
      <li><strong>What is a Collection?</strong></li>
      <li><strong>How is MongoDB different from SQL databases?</strong></li>
      <li><strong>What is BSON in MongoDB?</strong></li>
      <li><strong>What is the default port of MongoDB?</strong></li>
      <li><strong>Explain the structure of a MongoDB document.</strong></li>
      <li><strong>How do you create a database in MongoDB?</strong></li>
      <li><strong>How do you insert a document into a collection?</strong></li>
    
      <li><strong>What are indexes in MongoDB?</strong></li>
      <li><strong>What types of indexes does MongoDB support?</strong></li>
      <li><strong>How does MongoDB ensure performance with large datasets?</strong></li>
      <li><strong>What is a replica set?</strong></li>
      <li><strong>What is sharding in MongoDB?</strong></li>
      <li><strong>What is the aggregation framework?</strong></li>
      <li><strong>Difference between find() and findOne()?</strong></li>
      <li><strong>Explain the purpose of $match, $group, and $project in aggregation.</strong></li>
      <li><strong>How do you update multiple documents at once?</strong></li>
      <li><strong>How does MongoDB handle ACID transactions?</strong></li>
    
      <li><strong>Explain the CAP theorem in the context of MongoDB.</strong></li>
      <li><strong>What is the WiredTiger storage engine?</strong></li>
      <li><strong>How do you ensure high availability in MongoDB?</strong></li>
      <li><strong>What is the difference between embedding and referencing in schema design?</strong></li>
      <li><strong>When would you choose embedding over referencing?</strong></li>
      <li><strong>How does MongoDB handle concurrency?</strong></li>
      <li><strong>What are MongoDB transactions, and how do they work?</strong></li>
      <li><strong>What is the use of $lookup in aggregation?</strong></li>
      <li><strong>How do you handle schema validation in MongoDB?</strong></li>
      <li><strong>What is the difference between ObjectId and _id?</strong></li>
    
      <li><strong>How do you secure a MongoDB deployment?</strong></li>
      <li><strong>What is authentication vs authorization in MongoDB?</strong></li>
      <li><strong>What are roles and privileges in MongoDB?</strong></li>
      <li><strong>What is the purpose of mongodump and mongorestore?</strong></li>
      <li><strong>How do you back up and restore a MongoDB database?</strong></li>
      <li><strong>How to check MongoDB logs?</strong></li>
      <li><strong>How to monitor performance in MongoDB?</strong></li>
      <li><strong>What tools do you use with MongoDB for visualization and administration?</strong></li>
      <li><strong>How do you upgrade MongoDB?</strong></li>
      <li><strong>What happens during a replica set election?</strong></li>
    </ol>
    </div></li>
  
  
  
      <li><span class="faq-question">
          What are indexes in MongoDB?
      </span><div class="answer">
        Indexes in MongoDB are special data structures that store a small portion of the collection‚Äôs data in an easy-to-traverse form. They support efficient execution of queries by speeding up the search and sorting process. Without indexes, MongoDB must perform a collection scan, which is slow for large datasets.
      </div></li>
    
      <li><span class="faq-question">
          What types of indexes does MongoDB support?
      </span><div class="answer">
        MongoDB supports several types of indexes:
        <ul>
          <li><strong>Single Field Index:</strong> Indexes on a single field.</li>
          <li><strong>Compound Index:</strong> Indexes on multiple fields.</li>
          <li><strong>Multikey Index:</strong> Indexes arrays and creates index entries for each element.</li>
          <li><strong>Text Index:</strong> Enables text search for string content.</li>
          <li><strong>Hashed Index:</strong> Indexes based on hash values, used for sharding.</li>
          <li><strong>Geospatial Index:</strong> Used for queries on geographical data like coordinates.</li>
          <li><strong>Wildcard Index:</strong> Indexes multiple fields without explicitly specifying all keys.</li>
          <li><strong>Partial Index:</strong> Indexes only documents that meet a specified filter expression.</li>
          <li><strong>Sparse Index:</strong> Indexes only documents that contain the indexed field.</li>
        </ul>
      </div></li>
    
      <li><span class="faq-question">
          How does MongoDB ensure performance with large datasets?
      </span><div class="answer">
        MongoDB maintains performance with large datasets using:
        <ul>
          <li><strong>Indexes:</strong> To speed up search and sort operations.</li>
          <li><strong>Sharding:</strong> To horizontally partition data across multiple servers.</li>
          <li><strong>Efficient Storage Engine:</strong> Uses WiredTiger with compression and memory-mapped files.</li>
          <li><strong>Replication:</strong> Ensures high availability and read scalability.</li>
          <li><strong>Aggregation Framework:</strong> Optimizes data transformation and analysis pipelines.</li>
          <li><strong>Caching:</strong> Frequently accessed data is cached in memory (working set).</li>
        </ul>
        </div>
      </li>
    
      <li><span class="faq-question">
          What is a replica set?
      </span><div class="answer">
        A replica set is a group of MongoDB servers that maintain the same data set, providing redundancy and high availability. It includes:
        <ul>
          <li><strong>Primary:</strong> The node that receives all write operations.</li>
          <li><strong>Secondaries:</strong> Replicate the primary's data and can serve read requests (optionally).</li>
          <li><strong>Arbiter:</strong> Participates in elections but does not hold data.</li>
        </ul>
        If the primary node fails, an election is held to promote one of the secondaries to primary.
        </div>
      </li>
    
      <li><span class="faq-question">
          What is sharding in MongoDB?
      </span><div class="answer">
        Sharding is MongoDB‚Äôs method for horizontal scaling by distributing data across multiple machines (shards). It is used when a dataset grows beyond the capacity of a single server. Key components include:
        <ul>
          <li><strong>Shard:</strong> Each holds a subset of the data.</li>
          <li><strong>Config Server:</strong> Stores metadata and routing information.</li>
          <li><strong>Query Router (mongos):</strong> Directs client requests to the appropriate shard.</li>
        </ul>
        Sharding helps improve read/write throughput and allows MongoDB to handle huge volumes of data efficiently.
        </div>
      </li>
    
  </div></li>
  
  
  
  
  
  
  
          
      <li><span class="faq-question">
      What is the aggregation framework?
      </span><div class="answer">
      The aggregation framework in MongoDB is a powerful feature used to process data and return computed results. It allows you to perform operations like filtering, grouping, sorting, reshaping, and transforming documents. It uses a pipeline approach, where multiple stages are executed in sequence to refine and compute the final result.<br />
      Example usage:
      <pre><code>
      db.orders.aggregate([
      { $match: { status: "completed" } },
      { $group: { _id: "$customerId", total: { $sum: "$amount" } } },
      { $sort: { total: -1 } }
      ]);
      </code></pre>
  
  
      </div>
      </li>
        
          <li><span class="faq-question">
                
                Difference between find() AND findOne()</span><div class="answer">
                <ol>
                  <li><b>find()</b> returns a cursor to all documents that match the query criteria. <br />
                    You can iterate over the results or use <b>toArray()</b> to get all matches.</li>
                  <li><b>findOne()</b> returns the first document that matches the query criteria.</li>
                </ol>
                <strong>Example:</strong><br />
                <b>db.users.find({ age: 25 })</b> ‚Üí returns all matching users<br />
                <b>db.users.findOne({ age: 25 })</b> ‚Üí returns one user
              
                
              </div>
          </li>
          <li data-id="q32335"><span class="faq-question green">
  
            <strong>What is the use of $lookup in aggregation?</strong>
          </span>
          <div class="answer">
          $lookup is an aggregation stage in MongoDB that performs a left outer join to combine documents from two collections. It adds an array field containing matching documents from the ‚Äújoined‚Äù collection.
            
            <strong>Syntax:</strong>
            <pre><code>
        {
          $lookup: {
            from: "orders",
            localField: "userId",
            foreignField: "user_id",
            as: "userOrders"
          }
        }
            </code></pre>
            This will join user documents with their matching orders based on the user ID.
          
  
  </div></li>
          <li><span class="faq-question green">
              Explain the purpose of $match, $group, and $project in aggregation.
          </span><div class="answer">
    
                
                    MongoDB‚Äôs aggregation framework processes documents through a pipeline. The stages $match, $group, and $project are core building blocks of this pipeline:
                
                    <ul class="subul">
                      <li>
                        $match :
                        - Filters documents based on specified criteria, similar to the SQL WHERE clause.<br />
                        - It is usually placed at the beginning of the pipeline to reduce the number of documents early.<br />
                        <strong>Example:</strong>
                        <pre><code>{ $match: { status: "active" } }</code></pre>
                      </li>
                
                      <li>
                        <strong>$group:</strong>
                        - Groups input documents by a specified identifier expression.<br />
                        - Allows use of aggregation expressions like $sum, $avg, $max, $min, etc.<br />
                        <strong>Example:</strong>
                        <pre><code>
                {
                  $group: {
                    _id: "$department",
                    totalSalary: { $sum: "$salary" }
                  }
                }
                        </code></pre>
                      </li>
                
                      <li>
                        <strong>$project:</strong>
                        - Reshapes documents by including, excluding, or computing new fields.<br />
                        - Useful for transforming the output of previous stages.<br />
                        <strong>Example:</strong>
                        <pre><code>
                {
                  $project: {
                    name: 1,
                    department: 1,
                    salary: 1,
                    annualSalary: { $multiply: ["$salary", 12] },
                    _id: 0
                  }
                }
                        </code></pre>
                      </li>
                    </ul>
                
                    <strong>Combined Example:</strong>
                    <pre><code>
                db.employees.aggregate([
                  { $match: { status: "active" } },
                  { $group: { _id: "$department", total: { $sum: "$salary" } } },
                  { $project: { department: "$_id", total: 1, _id: 0 } }
                ]);
                    </code></pre>
                    This aggregation filters active employees, groups them by department, and shows their total salaries.
                  
              </div>
          </li>
        
          <li><span class="faq-question">
              How do you update multiple documents at once? updateMany()
          </span><div class="answer">
                Use the <code>updateMany()</code> method to update all documents that match a condition.
                <pre><code>
            db.products.updateMany(
              { category: "books" },
              { $set: { discount: true } }
            );
                </code></pre>
                This query adds a <code>discount</code> field with value <code>true</code> to all books.
              </div>
          </li>
        
          <li><span class="faq-question">How does MongoDB handle ACID transactions?  session.startTransaction();
          </span><div class="answer">
                MongoDB 4.0+ supports multi-document ACID (Atomicity, Consistency, Isolation, Durability) transactions for replica sets, and 4.2+ for sharded clusters. Transactions in MongoDB ensure that a series of operations either complete entirely or roll back entirely.<br /><br />
                <strong>Atomicity:</strong> All operations in a transaction are atomic.<br />
                <strong>Consistency:</strong> Ensures data remains valid and consistent after the transaction.<br />
                <strong>Isolation:</strong> Transactions operate in isolation until committed.<br />
                <strong>Durability:</strong> Once committed, changes are permanent even after failures.<br /><br />
                <strong>Example:</strong>
                <pre><code>
            const session = db.getMongo().startSession();
            session.startTransaction();
            
            try {
              const users = session.getDatabase("myDB").users;
              users.updateOne({ name: "John" }, { $inc: { balance: -100 } });
              users.updateOne({ name: "Jane" }, { $inc: { balance: 100 } });
              session.commitTransaction();
            } catch (e) {
              session.abortTransaction();
            }
            session.endSession();
                </code></pre>
             </div> </li>
            
            
  
  
  
  
  
          <li data-id="q32"><span class="faq-question">
          
                    <strong>Explain the CAP theorem in the context of MongoDB.</strong>
                  </span><div class="answer">
  
                    The CAP theorem (Consistency, Availability, Partition Tolerance) states that in a distributed system, you can only guarantee two out of the three at any given time:
                    <ul>
                      <li><strong>Consistency (C):</strong> Every read receives the most recent write.</li>
                      <li><strong>Availability (A):</strong> Every request receives a response (not necessarily the latest data).</li>
                      <li><strong>Partition Tolerance (P):</strong> The system continues to function despite network failures or partitioning.</li>
                    </ul>
                    <strong>MongoDB as CP or AP:</strong>
                    <ul>
                      <li>By default, MongoDB is a CP system.</li>
                      <li>In a partitioned network, it will favor consistency by electing a new primary and refusing writes if no primary is available.</li>
                      <li>It provides tunable consistency and availability via readConcern and writeConcern settings.</li>
                    </ul>
  
                  </div></li>
                  <li data-id="q32"><span class="faq-question">
                  
                    <strong>What is the WiredTiger storage engine?</strong></span><div class="answer">
  
                    <strong>WiredTiger</strong> is the default storage engine in MongoDB since version 3.2. It offers:
                    <ul>
                      <li><strong>Document-level concurrency control</strong> using multi-version concurrency control (MVCC).</li>
                      <li><strong>Compression:</strong> Reduces disk usage with snappy or zlib compression.</li>
                      <li><strong>Checkpointing:</strong> Periodically saves data to disk for durability.</li>
                      <li><strong>Efficient memory usage:</strong> Uses a cache that stores frequently accessed data in RAM.</li>
                    </ul>
                    Benefits of WiredTiger include better performance, reduced storage footprint, and improved concurrency over the older MMAPv1 engine.
                  
  </div></li>
  <li data-id="q32"><span class="faq-question">
  
                    <strong>How do you ensure high availability in MongoDB?
  
                    </strong>
                  </span><div class="answer">
  
                    High availability in MongoDB is achieved primarily through:
                    <ul>
                      <li><strong>Replica Sets:</strong> A set of MongoDB servers that maintain the same data.</li>
                      <li><strong>Automatic Failover:</strong> If the primary node fails, a secondary is automatically elected as the new primary.</li>
                      <li><strong>Arbiters:</strong> Help in electing a new primary without holding data.</li>
                      <li><strong>Read Preference:</strong> Allows clients to read from secondaries to improve availability.</li>
                      <li><strong>Write Concern:</strong> Ensures write operations are acknowledged by multiple members.</li>
                      <li><strong>Sharding (with replication):</strong> Provides both horizontal scaling and redundancy.</li>
                    </ul>
                    These features ensure MongoDB can remain accessible and operational during node failures, updates, or scaling operations.
  
                  </div></li>
                  <li data-id="q32"><span class="faq-question">
                  
  
                            <strong>What is the difference between embedding and referencing in schema design?</strong>
                            
                          </span><div class="answer">
  
                            In MongoDB, you can model relationships between documents using two main approaches:
                            <ul>
                              <li><strong>Embedding:</strong> Store related data inside a single document as nested objects or arrays.</li>
                              <li><strong>Referencing:</strong> Store a reference (like an ObjectId) to related documents in separate collections.</li>
                            </ul>
                            <strong>Example of Embedding:</strong>
                            <pre><code>
                        {
                          name: "John",
                          address: {
                            street: "Main St",
                            city: "New York"
                          }
                        }
                            </code></pre>
                        
                            <strong>Example of Referencing:</strong>
                            <pre><code>
                        // User document
                        { _id: 1, name: "John", address_id: 101 }
                        
                        // Address document
                        { _id: 101, street: "Main St", city: "New York" }
                            </code></pre>
  
  
                          </div></li>
                          <li data-id="q32"><span class="faq-question">
                          
                          
                            <strong>When would you choose embedding over referencing?</strong>
                          </span><div class="answer">
  
                            Choose <strong>embedding</strong> when:
                            <ul>
                              <li>The relationship is one-to-one or one-to-few.</li>
                              <li>The embedded data is frequently accessed with the parent document.</li>
                              <li>The data is relatively small and changes infrequently.</li>
                            </ul>
                        
                            Choose <strong>referencing</strong> when:
                            <ul>
                              <li>There is a many-to-many relationship.</li>
                              <li>The embedded data grows large or changes often.</li>
                              <li>You want to avoid duplication and ensure data normalization.</li>
                            </ul>
  
  
                          </div></li>
                          <li data-id="q32"><span class="faq-question">
                          
                          
                            <strong>How does MongoDB handle concurrency?</strong>
                          </span><div class="answer">
  
                            MongoDB handles concurrency using:
                            <ul>
                              <li><strong>Document-level locking:</strong> With WiredTiger, MongoDB allows concurrent operations on different documents.</li>
                              <li><strong>Multi-Version Concurrency Control (MVCC):</strong> Ensures consistent reads while writes are happening.</li>
                              <li><strong>Atomic operations:</strong> Single-document operations are atomic by default.</li>
                              <li><strong>Write concern and journaling:</strong> Ensure data durability and consistency.</li>
                            </ul>
                            This model allows MongoDB to support high levels of concurrent read/write operations safely and efficiently.
    
  
  </div></li>
  <li data-id="q32"><span class="faq-question">
  
  
                            <strong>What are MongoDB transactions, and how do they work?</strong>
                          </span><div class="answer">
  
                            MongoDB supports multi-document <strong>ACID transactions</strong> starting in version 4.0 (replica sets) and 4.2 (sharded clusters). A transaction is a sequence of operations that execute as a single unit of work ‚Äî either all succeed or none apply.
                        
                            <strong>How they work:</strong>
                            <ul>
                              <li>Start a session and begin a transaction using <code>startTransaction()</code>.</li>
                              <li>Execute multiple operations (e.g., insert, update).</li>
                              <li>Commit the transaction using <code>commitTransaction()</code>.</li>
                              <li>If any error occurs, abort using <code>abortTransaction()</code>.</li>
                            </ul>
                        
                            <strong>Example:</strong>
                            <pre><code>
                        const session = db.getMongo().startSession();
                        session.startTransaction();
                        try {
                          const dbSession = session.getDatabase("shop");
                          dbSession.orders.insertOne({ user: "Alice", item: "Book" });
                          dbSession.users.updateOne({ name: "Alice" }, { $inc: { points: 10 } });
                          session.commitTransaction();
                        } catch (e) {
                          session.abortTransaction();
                        }
                        session.endSession();
                            </code></pre>
                        
                            Transactions ensure full consistency even in complex write operations involving multiple documents or collections.
  
  
  </div></li>
  <li data-id="q311"><span class="faq-question">
  
  Helllo
  
  </span><div class="answer">
  
  </div></li>
  
  
  
      
  <li data-id="q32"><span class="faq-question">
  
  
            <strong>How do you handle schema validation in MongoDB?</strong>
          </span><div class="answer">
            MongoDB supports schema validation at the collection level using JSON Schema. You define rules for document structure, data types, required fields, etc., when creating a collection or by modifying it.
        
            <strong>Example:</strong>
            <pre><code>
        db.createCollection("users", {
          validator: {
            $jsonSchema: {
              bsonType: "object",
              required: ["name", "email"],
              properties: {
                name: { bsonType: "string" },
                email: { bsonType: "string", pattern: "^.+@.+$" },
                age: { bsonType: "int", minimum: 18 }
              }
            }
          }
        });
            </code></pre>
            This ensures only valid documents matching the schema are inserted or updated.
  
  
          </div></li>
          <li data-id="q32"><span class="faq-question green">
          
          
            <strong>What is the difference between ObjectId and _id?</strong>
          </span><div class="answer">
            <ol class="subul">
              <li>_id is a reserved field in MongoDB that uniquely identifies a document within a collection.</li>
              <li>ObjectId is the default type used for the _id field unless you explicitly set it to something else.</li>
            </ol>
            <br />
            <strong>ObjectId:</strong> A 12-byte value composed of:
            <ul>
              <li>4-byte timestamp</li>
              <li>5-byte random value</li>
              <li>3-byte incrementing counter</li>
            </ul>
            Example:
            <pre><code>{ _id: ObjectId("507f191e810c19729de860ea") }</code></pre>
  
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
          
            <strong>How do you secure a MongoDB deployment?</strong>
          </span><div class="answer">
            Security in MongoDB can be achieved through a combination of configurations:
            <ul>
              <li><strong>Enable Authentication:</strong> Require users to log in.</li>
              <li><strong>Use Role-Based Access Control (RBAC):</strong> Assign minimal privileges.</li>
              <li><strong>Enable TLS/SSL:</strong> Encrypt data in transit.</li>
              <li><strong>Use Firewalls:</strong> Allow access only from trusted IPs.</li>
              <li><strong>Disable External Bind:</strong> Avoid binding MongoDB to 0.0.0.0 in production.</li>
              <li><strong>Keep Software Updated:</strong> Regularly patch security vulnerabilities.</li>
              <li><strong>Use Encrypted Storage:</strong> Encrypt data at rest with storage engines like WiredTiger.</li>
            </ul>
  
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
          
            <strong>What is authentication vs authorization in MongoDB?</strong>
          </span><div class="answer">
            <ul>
              <li><strong>Authentication:</strong> The process of verifying the identity of a user (e.g., using a username and password).</li>
              <li><strong>Authorization:</strong> The process of verifying what actions a user is allowed to perform after they have authenticated.</li>
            </ul>
            In MongoDB:
            <ul>
              <li>Authentication is enabled via configuration (`--auth` or `security.authorization`).</li>
              <li>Authorization is managed using roles and privileges assigned to users.</li>
            </ul>
  
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
          
            <strong>What are roles and privileges in MongoDB?</strong>
          </span><div class="answer">
            MongoDB uses Role-Based Access Control (RBAC) to manage user access. Each role is associated with specific privileges that define what operations the user can perform.
            <ul>
              <li><strong>Built-in roles:</strong> e.g., <code>read</code>, <code>readWrite</code>, <code>dbAdmin</code>, <code>clusterAdmin</code></li>
              <li><strong>Privileges:</strong> Define actions (e.g., find, insert, drop) and resources (e.g., collections or databases).</li>
            </ul>
            You can also create custom roles using <code>db.createRole()</code>.
  
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
          
            <strong>What is the purpose of mongodump and mongorestore?</strong>
          </span><div class="answer">
            <ul>
              <li><code>mongodump</code> is a utility to back up MongoDB data by creating a binary export of the database.</li>
              <li><code>mongorestore</code> is used to restore the data from a <code>mongodump</code> backup.</li>
            </ul>
            <strong>Example:</strong>
            <pre><code>
        # Create a backup
        mongodump --db=myDatabase --out=/backup/path
        
        # Restore from backup
        mongorestore --db=myDatabase /backup/path/myDatabase
            </code></pre>
            These tools are useful for migrations, backup strategies, and disaster recovery.
  </div>        </li>
  
        
  
  
  
  
  
  <li data-id="q32"><span class="faq-question">
  
  
            <strong>How do you back up and restore a MongoDB database?</strong>
          </span><div class="answer">
            <strong>Backup:</strong> You can use <code>mongodump</code> to create a backup of your database in BSON format.
            <pre><code>
        # Back up an entire database
        mongodump --db=myDatabase --out=/path/to/backup
            </code></pre>
            <strong>Restore:</strong> Use <code>mongorestore</code> to import data from a backup.
            <pre><code>
        # Restore the database from backup
        mongorestore --db=myDatabase /path/to/backup/myDatabase
            </code></pre>
            For sharded clusters or replica sets, it's recommended to use filesystem snapshots or Ops Manager for consistency.
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          <strong>How to check MongoDB logs?</strong>
      </span><div class="answer">
            MongoDB logs contain startup information, query performance, errors, and replication events. To check logs:
            <ul>
              <li>Default log file location on Linux: <code>/var/log/mongodb/mongod.log</code></li>
              <li>Use <code>tail -f</code> to monitor logs in real-time:</li>
            </ul>
            <pre><code>tail -f /var/log/mongodb/mongod.log</code></pre>
            You can configure the log path using the <code>--logpath</code> flag or in the MongoDB config file.
  
            
  </div></li>
  <li data-id="q32"><span class="faq-question green">
  
            <strong>How to monitor performance in MongoDB?</strong>
          </span><div class="answer">
            MongoDB provides multiple tools and commands to monitor performance:
            <ol class="subul">
              <li><strong>db.serverStatus()</strong> ‚Äì returns server metrics.</li>
              <li><strong>db.currentOp()</strong> ‚Äì shows current operations.</li>
              <li><strong>mongostat</strong> ‚Äì real-time server statistics.</li>
              <li><strong>mongotop</strong> ‚Äì collection-level read/write activity.</li>
              <li><strong>Atlas Monitoring:</strong> If using MongoDB Atlas, dashboards are available for metrics, slow queries, etc.</li>
              <li><strong>Ops Manager:</strong> Enterprise-grade monitoring and automation tool for on-prem MongoDB.</li>
            </ol>
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
            <strong>What tools do you use with MongoDB for visualization and administration?</strong>
          </span><div class="answer">
            Popular tools include:
            <ul>
              <li><strong>MongoDB Compass:</strong> Official GUI for exploring and querying MongoDB collections.</li>
              <li><strong>MongoDB Atlas:</strong> Cloud dashboard with admin, metrics, and security tools.</li>
              <li><strong>Studio 3T:</strong> Powerful third-party GUI with advanced features for devs and DBAs.</li>
              <li><strong>Robo 3T:</strong> Lightweight GUI for MongoDB.</li>
              <li><strong>VS Code Extensions:</strong> Extensions like MongoDB for VS Code support browsing and querying MongoDB inside the IDE.</li>
            </ul>
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
            <strong>How do you upgrade MongoDB?</strong>
          </span><div class="answer">
            To upgrade MongoDB safely:
            <ol>
              <li>Review <a href="https://www.mongodb.com/docs/manual/release-notes/" target="_blank">MongoDB release notes</a> for breaking changes.</li>
              <li>Back up your databases using <code>mongodump</code> or snapshots.</li>
              <li>Test the upgrade in a staging environment first.</li>
              <li>Shut down MongoDB instance and replace binaries with the new version.</li>
              <li>Start the MongoDB server and monitor logs.</li>
              <li>For replica sets and sharded clusters, upgrade members one by one to avoid downtime.</li>
            </ol>
            Always follow the <a href="https://www.mongodb.com/docs/manual/tutorial/upgrade-revision/" target="_blank">official upgrade guide</a> for your version.
  
          </div></li>
          <li data-id="q32"><span class="faq-question">
          
            <strong>What happens during a replica set election?</strong>
          </span><div class="answer">
            When the primary node in a replica set becomes unavailable:
            <ul>
              <li>The remaining secondary nodes detect the failure via heartbeats.</li>
              <li>An election is triggered to choose a new primary.</li>
              <li>Eligible secondaries vote based on criteria like priority and replication lag.</li>
              <li>The node that receives a majority of votes becomes the new primary.</li>
              <li>Clients automatically reconnect to the new primary for write operations.</li>
            </ul>
            Elections typically take a few seconds, during which write operations are paused.
  
  
  </div></li>


  <li data-id="q32" class="yellow"><span class="faq-question">
    ------------------------------------------------------------------
    </span></li>
    <li data-id="q32" class="yellow"><span class="faq-question">
    --------------------------------------------------------------
    </span></li>
    <li data-id="q32" class="yellow"><span class="faq-question">
    -------------------------------------------------
    </span></li>

  <li data-id="q32" class="yellow">
    <span class="faq-question">DevOpps</span>
    <div class="answer">
    

      <ol>
        <li>What is DevOps?</li>
        <li>What are the key components of DevOps?</li>
        <li>What is CI/CD in DevOps?</li>
        <li>What is version control? Name some VCS tools.</li>
        <li>What is Git, and how does it differ from SVN?</li>
        <li>Explain Git branching and merging strategies.</li>
        <li>What are Git tags and how are they used?</li>
        <li>What is the difference between Git rebase and merge?</li>
        <li>What is a Git stash?</li>
        <li>What is the purpose of `.gitignore`?</li>
        <li>What is Jenkins? How does it work?</li>
        <li>What are Jenkins pipelines?</li>
        <li>What is a Jenkinsfile?</li>
        <li>What is the difference between a freestyle job and a pipeline job in Jenkins?</li>
        <li>How do you trigger Jenkins builds automatically?</li>
        <li>What are artifacts in a CI/CD pipeline?</li>
        <li>What is the difference between continuous integration and continuous deployment?</li>
        <li>What is Docker?</li>
        <li>How does Docker differ from a virtual machine?</li>
        <li>What is a Docker image and a Docker container?</li>
        <li>What is the purpose of a Dockerfile?</li>
        <li>What is Docker Compose?</li>
        <li>What is the difference between ENTRYPOINT and CMD in Dockerfile?</li>
        <li>How do you persist data in Docker containers?</li>
        <li>What is Docker Swarm?</li>
        <li>What is Kubernetes?</li>
        <li>What are Pods in Kubernetes?</li>
        <li>What are ReplicaSets?</li>
        <li>What is a Deployment in Kubernetes?</li>
        <li>What are Services in Kubernetes?</li>
        <li>What is Helm?</li>
        <li>What is a Kubernetes Namespace?</li>
        <li>How do you perform rolling updates in Kubernetes?</li>
        <li>What are ConfigMaps and Secrets in Kubernetes?</li>
        <li>What is the difference between a StatefulSet and a Deployment?</li>
        <li>What is the purpose of `kubectl`?</li>
        <li>What is Infrastructure as Code (IaC)?</li>
        <li>What is Terraform?</li>
        <li>What are Terraform providers and modules?</li>
        <li>What is the difference between Terraform and CloudFormation?</li>
        <li>What is Ansible?</li>
        <li>What are playbooks in Ansible?</li>
        <li>What is the difference between Ansible and Puppet/Chef?</li>
        <li>What is YAML and why is it used in DevOps?</li>
        <li>What is configuration management?</li>
        <li>What is monitoring in DevOps?</li>
        <li>Name some popular monitoring tools.</li>
        <li>What is Prometheus?</li>
        <li>What is Grafana?</li>
        <li>What is ELK Stack?</li>
        <li>What is log aggregation?</li>
        <li>What is Blue-Green Deployment?</li>
        <li>What is Canary Deployment?</li>
        <li>What are feature flags?</li>
        <li>What is the ‚Äúshift-left‚Äù approach in DevOps?</li>
        <li>What is a service mesh?</li>
        <li>What is Istio?</li>
        <li>What is load balancing?</li>
        <li>What is autoscaling?</li>
        <li>What is horizontal vs vertical scaling?</li>
        <li>What is a reverse proxy?</li>
        <li>What is NGINX used for?</li>
        <li>What is an API Gateway?</li>
        <li>What is a webhook?</li>
        <li>What is a rolling deployment?</li>
        <li>What is immutable infrastructure?</li>
        <li>What are ephemeral environments?</li>
        <li>What is chaos engineering?</li>
        <li>What is incident response in DevOps?</li>
        <li>What is MTTR, MTBF, and MTTD?</li>
        <li>What is site reliability engineering (SRE)?</li>
        <li>What is observability?</li>
        <li>What are the three pillars of observability?</li>
        <li>What is APM?</li>
        <li>What is container orchestration?</li>
        <li>What is Vault by HashiCorp?</li>
        <li>What are secrets management tools?</li>
        <li>What is the principle of least privilege?</li>
        <li>What is OAuth2 and how does it relate to DevOps?</li>
        <li>What is SSL/TLS and why is it important?</li>
        <li>How do you secure CI/CD pipelines?</li>
        <li>What is SonarQube?</li>
        <li>What is static code analysis?</li>
        <li>What is dynamic code analysis?</li>
        <li>What is a build artifact repository?</li>
        <li>What is Nexus or Artifactory?</li>
        <li>What is a package manager?</li>
        <li>What is semantic versioning?</li>
        <li>How do you manage secrets in CI/CD pipelines?</li>
        <li>What is a sandbox environment?</li>
        <li>What is the purpose of staging environments?</li>
        <li>What is blue/green testing?</li>
        <li>How do you handle rollbacks in production?</li>
        <li>What is trunk-based development?</li>
        <li>What is GitOps?</li>
        <li>What is DevSecOps?</li>
        <li>How do you monitor application performance in production?</li>
        <li>What are the challenges of microservices in DevOps?</li>
        <li>What is a centralized logging system?</li>
        <li>What is the twelve-factor app methodology?</li>
        <li>What is cloud-native architecture?</li>
        <li>What is the difference between public, private, and hybrid cloud?</li>
        <li>How do you ensure high availability in cloud deployments?</li>
        <li>What is fault tolerance?</li>
        <li>What is disaster recovery in DevOps?</li>
      </ol>
      
    </div>

  </li>



    <li data-id="q79">
      <span class="faq-question">What is DevOps?</span>
      <div class="answer">
        DevOps is a set of practices that combines software development (Dev) and IT operations (Ops). It aims to shorten the software development lifecycle and deliver high-quality software continuously using automation, collaboration, and monitoring.
      </div>
    </li>
  
    <li data-id="q80">
      <span class="faq-question">What are the key components of DevOps?</span>
      <div class="answer">
        The key components of DevOps include:
        <ul>
          <li>Continuous Integration (CI)</li>
          <li>Continuous Delivery/Deployment (CD)</li>
          <li>Infrastructure as Code (IaC)</li>
          <li>Monitoring and Logging</li>
          <li>Collaboration and Communication</li>
          <li>Automation</li>
        </ul>
      </div>
    </li>
  
    <li data-id="q81">
      <span class="faq-question">What is CI/CD in DevOps?</span>
      <div class="answer">
        CI/CD stands for Continuous Integration and Continuous Delivery/Deployment. CI involves automatically integrating code changes into a shared repository several times a day. CD automates the deployment of these changes to production, ensuring faster and more reliable software releases.
      </div>
    </li>
  
    <li data-id="q82">
      <span class="faq-question">What is version control? Name some VCS tools.</span>
      <div class="answer">
        Version control is a system that records changes to files over time so that you can recall specific versions later. Popular version control tools include Git, SVN (Subversion), Mercurial, and CVS.
      </div>
    </li>
  
    <li data-id="q83">
      <span class="faq-question">What is Git, and how does it differ from SVN?</span>
      <div class="answer">
        Git is a distributed version control system where every developer has a full copy of the codebase, while SVN is a centralized version control system. Git supports branching and merging more efficiently and allows offline work.
      </div>
    </li>
  
    <li data-id="q84">
      <span class="faq-question">Explain Git branching and merging strategies.</span>
      <div class="answer">
        Git branching allows developers to create separate branches for features, fixes, or experiments. Merging integrates these branches into the main codebase. Common strategies include:
        <ul>
          <li>Git Flow</li>
          <li>Feature Branching</li>
          <li>Release Branching</li>
          <li>Trunk-Based Development</li>
        </ul>
      </div>
    </li>
  
    <li data-id="q85">
      <span class="faq-question">What are Git tags and how are they used?</span>
      <div class="answer">
        Git tags are used to mark specific points in history as important, often used for releases (e.g., v1.0.0). Tags can be lightweight or annotated with metadata.
      </div>
    </li>
  
    <li data-id="q86">
      <span class="faq-question">What is the difference between Git rebase and merge?</span>
      <div class="answer">
        <strong>Git merge</strong> preserves the history and creates a new merge commit, while <strong>Git rebase</strong> re-applies commits on top of another base tip, creating a linear history. Rebase is cleaner but can rewrite history.
      </div>
    </li>
  
    <li data-id="q87">
      <span class="faq-question">What is a Git stash?</span>
      <div class="answer">
        Git stash temporarily shelves (or stashes) changes in your working directory so you can work on something else, then come back and re-apply them later.
      </div>
    </li>
  
    <li data-id="q88">
      <span class="faq-question">What is the purpose of <b>.gitignore</b>?</span>
      <div class="answer">
        The <code>.gitignore</code> file specifies intentionally untracked files to ignore, such as log files, build artifacts, and environment-specific files. It helps keep the repository clean and focused.
      </div>
    </li>

      <li data-id="q89">
        <span class="faq-question">What is Jenkins? How does it work?</span>
        <div class="answer">
          Jenkins is an open-source automation server used to automate parts of the software development process, such as building, testing, and deploying code. It works by running jobs or pipelines configured to execute specific tasks on code repositories when triggered manually or automatically.
        </div>
      </li>
    
      <li data-id="q90">
        <span class="faq-question">What are Jenkins pipelines?</span>
        <div class="answer">
          Jenkins pipelines are a suite of plugins that support integration and implementation of continuous delivery pipelines. A pipeline defines the entire lifecycle of a job from code commit to deployment using a domain-specific language (DSL).
        </div>
      </li>
    
      <li data-id="q91">
        <span class="faq-question">What is a Jenkinsfile?</span>
        <div class="answer">
          A Jenkinsfile is a text file that contains the definition of a Jenkins pipeline. It is stored in the source control repository and provides a way to define pipeline steps using either declarative or scripted syntax.
        </div>
      </li>
    
      <li data-id="q92">
        <span class="faq-question">What is the difference between a freestyle job and a pipeline job in Jenkins?</span>
        <div class="answer">
          A freestyle job is a simple, configurable job with limited automation and flexibility. A pipeline job, defined using a Jenkinsfile, allows for complex automation, versioning in source control, and better scalability through stages and parallelism.
        </div>
      </li>
    
      <li data-id="q93">
        <span class="faq-question">How do you trigger Jenkins builds automatically?</span>
        <div class="answer">
          Jenkins builds can be triggered automatically using:
          <ul>
            <li>Webhooks from version control systems like GitHub or GitLab</li>
            <li>Poll SCM (periodic checks for changes)</li>
            <li>Cron schedules</li>
            <li>Upstream/downstream project triggers</li>
            <li>Jenkins REST API calls</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q94">
        <span class="faq-question">What are artifacts in a CI/CD pipeline?</span>
        <div class="answer">
          Artifacts are the output files generated during a build process, such as binaries, JAR files, Docker images, or reports. They are stored and often passed to later stages like testing or deployment.
        </div>
      </li>
    
      <li data-id="q95">
        <span class="faq-question">What is the difference between continuous integration and continuous deployment?</span>
        <div class="answer">
          <strong>Continuous Integration (CI)</strong> involves regularly merging code changes and running automated tests to ensure integration success.  
          <strong>Continuous Deployment (CD)</strong> goes further by automatically deploying every change that passes tests to production without manual intervention.
        </div>
      </li>
    
      <li data-id="q96">
        <span class="faq-question">What is Docker?</span>
        <div class="answer">
          Docker is an open-source platform that enables developers to build, package, and run applications in lightweight, portable containers that include everything needed to run the software, such as code, runtime, libraries, and dependencies.
        </div>
      </li>
    
      <li data-id="q97">
        <span class="faq-question">How does Docker differ from a virtual machine?</span>
        <div class="answer">
          Docker containers share the host OS kernel and are more lightweight and faster to start than virtual machines, which run full guest operating systems on a hypervisor. VMs provide stronger isolation but at the cost of higher overhead.
        </div>
      </li>
    
      <li data-id="q98">
        <span class="faq-question">What is a Docker image and a Docker container?</span>
        <div class="answer">
          A <strong>Docker image</strong> is a read-only template with instructions for creating a container. A <strong>Docker container</strong> is a running instance of an image, with its own file system, networking, and isolated environment.
        </div>
      </li>
  
    


   
        <li data-id="q99">
          <span class="faq-question">What is the purpose of a Dockerfile?</span>
          <div class="answer">
            A Dockerfile is a script containing a series of instructions on how to build a Docker image. It automates the process of creating images by defining the base image, installing dependencies, copying files, setting environment variables, and specifying entry points.
          </div>
        </li>
      
        <li data-id="q100">
          <span class="faq-question">What is Docker Compose?</span>
          <div class="answer">
            Docker Compose is a tool for defining and running multi-container Docker applications using a YAML file. It allows you to configure services, networks, and volumes in one place and start them all with a single command: <code>docker-compose up</code>.
          </div>
        </li>
      
        <li data-id="q101">
          <span class="faq-question">What is the difference between ENTRYPOINT and CMD in Dockerfile?</span>
          <div class="answer">
            <strong>CMD</strong> sets default arguments for the container‚Äôs execution. <strong>ENTRYPOINT</strong> defines the main command to run. If both are used, CMD provides default parameters to ENTRYPOINT. ENTRYPOINT is preferred when you want a fixed executable with configurable arguments.
          </div>
        </li>
      
        <li data-id="q102">
          <span class="faq-question">How do you persist data in Docker containers?</span>
          <div class="answer">
            Data persistence in Docker is achieved using:
            <ul>
              <li><strong>Volumes</strong> ‚Äì Managed by Docker and stored outside the container lifecycle.</li>
              <li><strong>Bind mounts</strong> ‚Äì Link a directory on the host machine to the container.</li>
              <li><strong>tmpfs</strong> ‚Äì Temporary storage in memory (non-persistent).</li>
            </ul>
          </div>
        </li>
      
        <li data-id="q103">
          <span class="faq-question">What is Docker Swarm?</span>
          <div class="answer">
            Docker Swarm is Docker‚Äôs native clustering and orchestration tool. It allows you to manage a cluster of Docker engines (nodes) as a single virtual system, enabling container scaling, service discovery, and load balancing.
          </div>
        </li>
      
        <li data-id="q104">
          <span class="faq-question">What is Kubernetes?</span>
          <div class="answer">
            Kubernetes is an open-source container orchestration platform designed to automate the deployment, scaling, and management of containerized applications across clusters of hosts.
          </div>
        </li>
      
        <li data-id="q105">
          <span class="faq-question">What are Pods in Kubernetes?</span>
          <div class="answer">
            A Pod is the smallest deployable unit in Kubernetes. It can contain one or more containers that share storage, network, and a specification for how to run the containers. Pods are ephemeral and can be replaced by the system.
          </div>
        </li>
      
        <li data-id="q106">
          <span class="faq-question">What are ReplicaSets?</span>
          <div class="answer">
            A ReplicaSet in Kubernetes ensures that a specified number of pod replicas are running at any time. It monitors and maintains the desired number of replicas by starting or terminating pods as needed.
          </div>
        </li>
      
        <li data-id="q107">
          <span class="faq-question">What is a Deployment in Kubernetes?</span>
          <div class="answer">
            A Deployment provides declarative updates for Pods and ReplicaSets. It allows you to manage application updates, rollbacks, and scaling while ensuring zero downtime during deployment processes.
          </div>
        </li>
      
        <li data-id="q108">
          <span class="faq-question">What are Services in Kubernetes?</span>
          <div class="answer">
            A Service in Kubernetes is an abstraction that defines a logical set of Pods and a policy to access them. Services enable communication between components inside the cluster and expose workloads to the outside world.
          </div>
        </li>
      
      

       
          <li data-id="q109">
            <span class="faq-question">What is Helm?</span>
            <div class="answer">
              Helm is a package manager for Kubernetes that simplifies the deployment and management of applications. It uses Helm charts (pre-configured Kubernetes resources) to define, install, and upgrade applications within a Kubernetes cluster.
            </div>
          </li>
        
          <li data-id="q110">
            <span class="faq-question">What is a Kubernetes Namespace?</span>
            <div class="answer">
              A Kubernetes Namespace is a logical partition within a cluster that allows grouping of resources. It helps isolate and manage resources (like Pods, Services, and Deployments) among different teams or environments.
            </div>
          </li>
        
          <li data-id="q111">
            <span class="faq-question">How do you perform rolling updates in Kubernetes?</span>
            <div class="answer">
              Rolling updates in Kubernetes are done using Deployments. Kubernetes gradually replaces Pods with new ones, ensuring zero downtime. This can be configured using <code>kubectl apply</code> and controlled through update strategy settings in the Deployment manifest.
            </div>
          </li>
        
          <li data-id="q112">
            <span class="faq-question">What are ConfigMaps and Secrets in Kubernetes?</span>
            <div class="answer">
              <strong>ConfigMaps</strong> are used to store non-sensitive configuration data in key-value pairs.  
              <strong>Secrets</strong> are used to store sensitive data such as passwords, tokens, and keys. Both can be injected into Pods as environment variables or mounted as files.
            </div>
          </li>
        
          <li data-id="q113">
            <span class="faq-question">What is the difference between a StatefulSet and a Deployment?</span>
            <div class="answer">
              A <strong>Deployment</strong> is used for stateless applications where any Pod can handle any request.  
              A <strong>StatefulSet</strong> is used for stateful applications requiring stable identities, persistent storage, and ordered deployment or scaling (e.g., databases).
            </div>
          </li>
        
          <li data-id="q114">
            <span class="faq-question">What is the purpose of <b>kubectl</b>?</span>
            <div class="answer">
              <code>kubectl</code> is the command-line tool used to interact with Kubernetes clusters. It allows users to deploy applications, inspect and manage cluster resources, and view logs and events.
            </div>
          </li>
        
          <li data-id="q115">
            <span class="faq-question">What is Infrastructure as Code (IaC)?</span>
            <div class="answer">
              Infrastructure as Code (IaC) is the practice of managing and provisioning infrastructure through machine-readable configuration files, rather than manual processes. It enables automation, version control, and consistency across environments.
            </div>
          </li>
        
          <li data-id="q116">
            <span class="faq-question">What is Terraform?</span>
            <div class="answer">
              Terraform is an open-source Infrastructure as Code (IaC) tool developed by HashiCorp. It allows users to define and provision cloud infrastructure using a declarative configuration language called HCL (HashiCorp Configuration Language).
            </div>
          </li>
        
          <li data-id="q117">
            <span class="faq-question">What are Terraform providers and modules?</span>
            <div class="answer">
              <strong>Providers</strong> are plugins in Terraform that interact with APIs of cloud providers (like AWS, Azure, GCP) or other platforms.  
              <strong>Modules</strong> are reusable packages of Terraform configurations that can be shared and used to manage complex infrastructure by breaking it into smaller, reusable components.
            </div>
          </li>
        
          <li data-id="q118">
            <span class="faq-question">What is the difference between Terraform and CloudFormation?</span>
            <div class="answer">
              <strong>Terraform</strong> is a multi-cloud, open-source IaC tool that supports a wide variety of providers and uses a declarative language (HCL).  
              <strong>CloudFormation</strong> is AWS-specific and uses JSON/YAML templates to define and manage AWS resources. Terraform is more flexible for multi-cloud scenarios, while CloudFormation is tightly integrated with AWS.
            </div>
          </li>
      
        
      
            <li data-id="q119">
              <span class="faq-question">What is Ansible?</span>
              <div class="answer">
                Ansible is an open-source IT automation tool used for configuration management, application deployment, orchestration, and task automation. It uses simple, human-readable YAML files and operates over SSH without requiring agent installation.
              </div>
            </li>
          
            <li data-id="q120">
              <span class="faq-question">What are playbooks in Ansible?</span>
              <div class="answer">
                Playbooks are YAML files in Ansible that define a set of tasks to be executed on remote servers. They specify what actions should be performed, such as installing packages, copying files, or restarting services, in a structured and reusable format.
              </div>
            </li>
          
            <li data-id="q121">
              <span class="faq-question">What is the difference between Ansible and Puppet/Chef?</span>
              <div class="answer">
                <ul>
                  <li><strong>Ansible</strong> is agentless and uses YAML, with a push-based approach via SSH.</li>
                  <li><strong>Puppet</strong> and <strong>Chef</strong> use agents on managed nodes and follow a pull-based model.</li>
                  <li>Puppet uses its own DSL (Domain-Specific Language), while Chef uses Ruby.</li>
                  <li>Ansible is considered simpler and easier to learn, especially for smaller teams.</li>
                </ul>
              </div>
            </li>
          
            <li data-id="q122">
              <span class="faq-question">What is YAML and why is it used in DevOps?</span>
              <div class="answer">
                YAML (YAML Ain‚Äôt Markup Language) is a human-readable data serialization format. In DevOps, it‚Äôs used to define configuration files for tools like Ansible, Kubernetes, GitHub Actions, and Docker Compose because of its readability and simplicity.
              </div>
            </li>
          
            <li data-id="q123">
              <span class="faq-question">What is configuration management?</span>
              <div class="answer">
                Configuration management is the process of maintaining consistency of a system‚Äôs performance and functional attributes. In DevOps, it involves managing infrastructure configurations and environments using tools like Ansible, Puppet, Chef, and Terraform.
              </div>
            </li>
          
            <li data-id="q124">
              <span class="faq-question">What is monitoring in DevOps?</span>
              <div class="answer">
                Monitoring in DevOps refers to the practice of observing system performance, availability, and resource usage to ensure reliability and detect failures or bottlenecks. It enables proactive maintenance and better decision-making.
              </div>
            </li>
          
            <li data-id="q125">
              <span class="faq-question">Name some popular monitoring tools.</span>
              <div class="answer">
                Some widely used monitoring tools include:
                <ul>
                  <li>Prometheus</li>
                  <li>Grafana</li>
                  <li>ELK Stack (Elasticsearch, Logstash, Kibana)</li>
                  <li>Datadog</li>
                  <li>New Relic</li>
                  <li>Nagios</li>
                  <li>Zabbix</li>
                </ul>
              </div>
            </li>
          
            <li data-id="q126">
              <span class="faq-question">What is Prometheus?</span>
              <div class="answer">
                Prometheus is an open-source monitoring and alerting toolkit designed for reliability and scalability. It collects metrics from configured targets at specified intervals and stores them in a time-series database, with support for powerful querying and alerting.
              </div>
            </li>
          
            <li data-id="q127">
              <span class="faq-question">What is Grafana?</span>
              <div class="answer">
                Grafana is an open-source analytics and visualization tool that integrates with data sources like Prometheus, InfluxDB, and Elasticsearch. It is widely used for creating interactive dashboards to monitor metrics and system performance.
              </div>
            </li>
          
            <li data-id="q128">
              <span class="faq-question">What is ELK Stack?</span>
              <div class="answer">
                The ELK Stack is a combination of three open-source tools: <strong>Elasticsearch</strong> (search and analytics engine), <strong>Logstash</strong> (log pipeline and transformation), and <strong>Kibana</strong> (visualization and dashboarding). It is used for centralized logging, monitoring, and analysis.
              </div>
            </li>
         
          
           
              <li data-id="q129">
                <span class="faq-question">What is log aggregation?</span>
                <div class="answer">
                  Log aggregation is the process of collecting and centralizing logs from multiple sources (servers, applications, services) into a single system for analysis, monitoring, and troubleshooting. Tools like ELK Stack, Fluentd, and Graylog are commonly used for this purpose.
                </div>
              </li>
            
              <li data-id="q130">
                <span class="faq-question">What is Blue-Green Deployment?</span>
                <div class="answer">
                  Blue-Green Deployment is a deployment strategy that reduces downtime and risk. Two environments are maintained: one (blue) is live, while the other (green) has the new version. Traffic is switched to green after testing, and blue is kept as a backup.
                </div>
              </li>
            
              <li data-id="q131">
                <span class="faq-question">What is Canary Deployment?</span>
                <div class="answer">
                  Canary Deployment is a technique where a new application version is gradually rolled out to a small subset of users before full deployment. This allows testing in a production environment with minimal risk and easier rollback in case of issues.
                </div>
              </li>
            
              <li data-id="q132">
                <span class="faq-question">What are feature flags?</span>
                <div class="answer">
                  Feature flags (or toggles) are mechanisms to enable or disable specific features in an application without deploying new code. They allow safer releases, A/B testing, and gradual rollouts by controlling features at runtime.
                </div>
              </li>
            
              <li data-id="q133">
                <span class="faq-question">What is the ‚Äúshift-left‚Äù approach in DevOps?</span>
                <div class="answer">
                  The ‚Äúshift-left‚Äù approach involves performing testing, security, and quality checks earlier in the software development lifecycle. This helps detect issues sooner, reduces cost and effort, and improves product quality and delivery speed.
                </div>
              </li>
            
              <li data-id="q134">
                <span class="faq-question">What is a service mesh?</span>
                <div class="answer">
                  A service mesh is a dedicated infrastructure layer for managing service-to-service communication in microservices architectures. It provides features like traffic management, observability, security, and policy enforcement without changing application code.
                </div>
              </li>
            
              <li data-id="q135">
                <span class="faq-question">What is Istio?</span>
                <div class="answer">
                  Istio is an open-source service mesh that provides tools for traffic management, security, observability, and policy control in a Kubernetes-based microservices architecture. It uses Envoy as a sidecar proxy to intercept and manage traffic between services.
                </div>
              </li>
            
              <li data-id="q136">
                <span class="faq-question">What is load balancing?</span>
                <div class="answer">
                  Load balancing is the process of distributing network or application traffic across multiple servers to ensure reliability and performance. It prevents overloading a single server and improves responsiveness and availability.
                </div>
              </li>
            
              <li data-id="q137">
                <span class="faq-question">What is autoscaling?</span>
                <div class="answer">
                  Autoscaling automatically adjusts the number of computing resources (like servers or pods) based on real-time demand. It ensures optimal performance and cost-efficiency by scaling up under high load and down when demand decreases.
                </div>
              </li>
            
              <li data-id="q138">
                <span class="faq-question">What is horizontal vs vertical scaling?</span>
                <div class="answer">
                  <ul>
                    <li><strong>Horizontal Scaling</strong> (scale-out): Adding more machines or instances to handle increased load.</li>
                    <li><strong>Vertical Scaling</strong> (scale-up): Increasing the capacity (CPU, RAM) of existing machines.</li>
                  </ul>
                  Horizontal scaling is more flexible and fault-tolerant, while vertical scaling is limited by hardware capacity.
                </div>
              </li>
        
            
             
                <li data-id="q139">
                  <span class="faq-question">What is a reverse proxy?</span>
                  <div class="answer">
                    A reverse proxy is a server that sits in front of one or more backend servers and forwards client requests to them. It provides benefits like load balancing, caching, SSL termination, and enhanced security.
                  </div>
                </li>
              
                <li data-id="q140">
                  <span class="faq-question">What is NGINX used for?</span>
                  <div class="answer">
                    NGINX is a high-performance web server that can also function as a reverse proxy, load balancer, and HTTP cache. It is widely used to serve static content, manage traffic, and improve the scalability and security of web applications.
                  </div>
                </li>
              
                <li data-id="q141">
                  <span class="faq-question">What is an API Gateway?</span>
                  <div class="answer">
                    An API Gateway is a server that acts as an entry point for client requests to microservices. It handles tasks such as request routing, authentication, rate limiting, and response transformation, simplifying the client-side logic.
                  </div>
                </li>
              
                <li data-id="q142">
                  <span class="faq-question">What is a webhook?</span>
                  <div class="answer">
                    A webhook is a way for one application to send real-time data to another application via an HTTP POST request. It is commonly used for event-driven communication, such as triggering actions when a code push occurs or an order is placed.
                  </div>
                </li>
              
                <li data-id="q143">
                  <span class="faq-question">What is a rolling deployment?</span>
                  <div class="answer">
                    A rolling deployment is a software release strategy where new versions of an application are gradually rolled out to a few servers at a time. This allows for zero downtime and easy rollback in case of failure.
                  </div>
                </li>
              
                <li data-id="q144">
                  <span class="faq-question">What is immutable infrastructure?</span>
                  <div class="answer">
                    Immutable infrastructure refers to servers or components that are never modified after deployment. Instead of updating existing systems, new versions are created and replaced. This ensures consistency, reduces errors, and simplifies rollback.
                  </div>
                </li>
              
                <li data-id="q145">
                  <span class="faq-question">What are ephemeral environments?</span>
                  <div class="answer">
                    Ephemeral environments are temporary, on-demand environments (like staging or testing) that are created automatically and destroyed after use. They support rapid development and testing without polluting permanent environments.
                  </div>
                </li>
              
                <li data-id="q146">
                  <span class="faq-question">What is chaos engineering?</span>
                  <div class="answer">
                    Chaos engineering is the practice of intentionally injecting failures into a system to test its resilience and identify weaknesses. It helps teams build more robust systems by understanding how they behave under stress or partial outages.
                  </div>
                </li>
              
                <li data-id="q147">
                  <span class="faq-question">What is incident response in DevOps?</span>
                  <div class="answer">
                    Incident response in DevOps involves detecting, investigating, and resolving unplanned disruptions to services. It includes monitoring, alerting, communication, root cause analysis, and postmortems to improve system reliability.
                  </div>
                </li>
              
                <li data-id="q148">
                  <span class="faq-question">What is MTTR, MTBF, and MTTD?</span>
                  <div class="answer">
                    <ul>
                      <li><strong>MTTR (Mean Time to Recovery)</strong>: The average time taken to restore a system after a failure.</li>
                      <li><strong>MTBF (Mean Time Between Failures)</strong>: The average time between system failures.</li>
                      <li><strong>MTTD (Mean Time to Detect)</strong>: The average time taken to detect an issue or failure in the system.</li>
                    </ul>
                  </div>
                </li>
         
  
 
                  <li data-id="q149">
                    <span class="faq-question">What is site reliability engineering (SRE)?</span>
                    <div class="answer">
                      Site Reliability Engineering (SRE) is a discipline that applies software engineering principles to IT operations. Its goal is to create scalable and highly reliable software systems. SRE teams are responsible for availability, latency, performance, efficiency, and incident response.
                    </div>
                  </li>
                
                  <li data-id="q150">
                    <span class="faq-question">What is observability?</span>
                    <div class="answer">
                      Observability is the ability to measure the internal state of a system by examining its outputs such as logs, metrics, and traces. It helps teams detect and diagnose issues in complex systems effectively.
                    </div>
                  </li>
                
                  <li data-id="q151">
                    <span class="faq-question">What are the three pillars of observability?</span>
                    <div class="answer">
                      The three pillars of observability are:
                      <ul>
                        <li><strong>Logs</strong>: Text records of events that happen in a system.</li>
                        <li><strong>Metrics</strong>: Numeric measurements over time that indicate system health and performance.</li>
                        <li><strong>Traces</strong>: Records of a request's journey through various services in a distributed system.</li>
                      </ul>
                    </div>
                  </li>
                
                  <li data-id="q152">
                    <span class="faq-question">What is APM?</span>
                    <div class="answer">
                      APM (Application Performance Monitoring) refers to tools and practices used to monitor and manage the performance, availability, and user experience of software applications. Examples include New Relic, Datadog, and AppDynamics.
                    </div>
                  </li>
                
                  <li data-id="q153">
                    <span class="faq-question">What is container orchestration?</span>
                    <div class="answer">
                      Container orchestration is the automated management of containerized applications, including deployment, scaling, networking, and lifecycle management. Kubernetes is the most widely used container orchestration platform.
                    </div>
                  </li>
                
                  <li data-id="q154">
                    <span class="faq-question">What is Vault by HashiCorp?</span>
                    <div class="answer">
                      Vault by HashiCorp is a tool for securely storing and accessing secrets, such as API keys, passwords, certificates, and tokens. It provides dynamic secrets, encryption as a service, and access control.
                    </div>
                  </li>
                
                  <li data-id="q155">
                    <span class="faq-question">What are secrets management tools?</span>
                    <div class="answer">
                      Secrets management tools securely store, manage, and control access to sensitive information. Common tools include:
                      <ul>
                        <li>HashiCorp Vault</li>
                        <li>AWS Secrets Manager</li>
                        <li>Azure Key Vault</li>
                        <li>Google Secret Manager</li>
                        <li>SOPS (Secrets OPerationS)</li>
                      </ul>
                    </div>
                  </li>
                
                  <li data-id="q156">
                    <span class="faq-question">What is the principle of least privilege?</span>
                    <div class="answer">
                      The principle of least privilege is a security concept that ensures users and systems are granted the minimum level of access‚Äîor permissions‚Äînecessary to perform their tasks. It helps reduce the attack surface and limit the impact of breaches.
                    </div>
                  </li>
                
                  <li data-id="q157">
                    <span class="faq-question">What is OAuth2 and how does it relate to DevOps?</span>
                    <div class="answer">
                      OAuth2 is an authorization framework that allows third-party applications to access user resources without exposing credentials. In DevOps, it is commonly used for secure API access, SSO (Single Sign-On), and securing CI/CD tools and pipelines.
                    </div>
                  </li>
                
                  <li data-id="q158">
                    <span class="faq-question">What is SSL/TLS and why is it important?</span>
                    <div class="answer">
                      SSL (Secure Sockets Layer) and TLS (Transport Layer Security) are cryptographic protocols used to secure communications over networks. They ensure data confidentiality, integrity, and authenticity, making them essential for secure web and API communication.
                    </div>
                  </li>
                     

           
                    <li data-id="q159">
                      <span class="faq-question">How do you secure CI/CD pipelines?</span>
                      <div class="answer">
                        Securing CI/CD pipelines involves practices like:
                        <ul>
                          <li>Using least privilege for access controls</li>
                          <li>Scanning for secrets and vulnerabilities</li>
                          <li>Validating code with static and dynamic analysis</li>
                          <li>Encrypting credentials and using secure storage</li>
                          <li>Auditing logs and activities</li>
                          <li>Running builds in isolated environments</li>
                        </ul>
                      </div>
                    </li>
                  
                    <li data-id="q160">
                      <span class="faq-question">What is SonarQube?</span>
                      <div class="answer">
                        SonarQube is an open-source platform used to perform automatic reviews of code to detect bugs, code smells, vulnerabilities, and duplications. It integrates with CI/CD tools to enforce code quality gates.
                      </div>
                    </li>
                  
                    <li data-id="q161">
                      <span class="faq-question">What is static code analysis?</span>
                      <div class="answer">
                        Static code analysis is the process of analyzing source code without executing it. It helps identify syntax errors, code smells, security vulnerabilities, and maintainability issues early in the development lifecycle.
                      </div>
                    </li>
                  
                    <li data-id="q162">
                      <span class="faq-question">What is dynamic code analysis?</span>
                      <div class="answer">
                        Dynamic code analysis involves executing a program and monitoring its behavior to find issues such as memory leaks, security vulnerabilities, and performance bottlenecks during runtime.
                      </div>
                    </li>
                  
                    <li data-id="q163">
                      <span class="faq-question">What is a build artifact repository?</span>
                      <div class="answer">
                        A build artifact repository stores the output artifacts (e.g., binaries, JARs, Docker images) generated by CI builds. It supports versioning, access control, and promotes reusability across environments.
                      </div>
                    </li>
                  
                    <li data-id="q164">
                      <span class="faq-question">What is Nexus or Artifactory?</span>
                      <div class="answer">
                        Nexus and Artifactory are artifact repository managers. They store, manage, and distribute build artifacts and dependencies, supporting various package formats like Maven, npm, Docker, and more.
                      </div>
                    </li>
                  
                    <li data-id="q165">
                      <span class="faq-question">What is a package manager?</span>
                      <div class="answer">
                        A package manager is a tool that automates the process of installing, upgrading, configuring, and removing software packages. Examples include npm (JavaScript), pip (Python), apt (Debian/Ubuntu), and yum (RedHat/CentOS).
                      </div>
                    </li>
                  
                    <li data-id="q166">
                      <span class="faq-question">What is semantic versioning?</span>
                      <div class="answer">
                        Semantic versioning is a versioning scheme that uses a three-part number format: <code>MAJOR.MINOR.PATCH</code>. It conveys meaning about the nature of changes:
                        <ul>
                          <li>MAJOR ‚Äì incompatible API changes</li>
                          <li>MINOR ‚Äì backward-compatible functionality</li>
                          <li>PATCH ‚Äì backward-compatible bug fixes</li>
                        </ul>
                      </div>
                    </li>
                  
                    <li data-id="q167">
                      <span class="faq-question">How do you manage secrets in CI/CD pipelines?</span>
                      <div class="answer">
                        Secrets in CI/CD pipelines are managed by:
                        <ul>
                          <li>Storing secrets in secure vaults (e.g., HashiCorp Vault, AWS Secrets Manager)</li>
                          <li>Using environment variables with access controls</li>
                          <li>Avoiding hardcoding secrets in source code</li>
                          <li>Encrypting secrets and rotating them regularly</li>
                          <li>Integrating secrets management tools with CI/CD platforms</li>
                        </ul>
                      </div>
                    </li>
                  
                    <li data-id="q168">
                      <span class="faq-question">What is a sandbox environment?</span>
                      <div class="answer">
                        A sandbox environment is an isolated testing environment that mimics production without affecting live data or users. It is used for development, testing, and experimentation to ensure changes are safe before deployment.
                      </div>
                    </li>
           
                  
                    
                      <li data-id="q169">
                        <span class="faq-question">What is the purpose of staging environments?</span>
                        <div class="answer">
                          A staging environment is a replica of the production environment used to test application changes before deployment. It helps identify issues and ensures that new features or fixes work as expected in a production-like setup.
                        </div>
                      </li>
                    
                      <li data-id="q170">
                        <span class="faq-question">What is blue/green testing?</span>
                        <div class="answer">
                          Blue/Green testing is a deployment strategy that involves running two identical environments: one active (Blue) and one idle (Green). New versions are deployed to the idle environment, and traffic is switched once validated, reducing downtime and risk.
                        </div>
                      </li>
                    
                      <li data-id="q171">
                        <span class="faq-question">How do you handle rollbacks in production?</span>
                        <div class="answer">
                          Rollbacks in production can be handled by:
                          <ul>
                            <li>Keeping previous stable versions ready for redeployment</li>
                            <li>Using deployment strategies like Blue/Green or Canary</li>
                            <li>Automating rollbacks with CI/CD tools</li>
                            <li>Maintaining infrastructure-as-code and versioned artifacts</li>
                          </ul>
                        </div>
                      </li>
                    
                      <li data-id="q172">
                        <span class="faq-question">What is trunk-based development?</span>
                        <div class="answer">
                          Trunk-based development is a Git workflow where all developers commit to a single branch (usually main or trunk). Feature flags and short-lived branches are used to avoid merge conflicts and accelerate CI/CD processes.
                        </div>
                      </li>
                    
                      <li data-id="q173">
                        <span class="faq-question">What is GitOps?</span>
                        <div class="answer">
                          GitOps is a DevOps practice that uses Git as the single source of truth for declarative infrastructure and application configurations. Changes are automatically applied through CI/CD tools when updates are pushed to Git repositories.
                        </div>
                      </li>
                    
                      <li data-id="q174">
                        <span class="faq-question">What is DevSecOps?</span>
                        <div class="answer">
                          DevSecOps integrates security practices into the DevOps pipeline. It involves automated security testing, compliance checks, vulnerability scanning, and secret management to ensure secure code and infrastructure from development to production.
                        </div>
                      </li>
                    
                      <li data-id="q175">
                        <span class="faq-question">How do you monitor application performance in production?</span>
                        <div class="answer">
                          Application performance in production is monitored using:
                          <ul>
                            <li>APM tools like New Relic, Datadog, or AppDynamics</li>
                            <li>Log aggregation tools like ELK or Splunk</li>
                            <li>Metric collection tools like Prometheus and Grafana</li>
                            <li>Custom alerts, dashboards, and health checks</li>
                          </ul>
                        </div>
                      </li>
                    
                      <li data-id="q176">
                        <span class="faq-question">What are the challenges of microservices in DevOps?</span>
                        <div class="answer">
                          Challenges of microservices in DevOps include:
                          <ul>
                            <li>Managing inter-service communication and dependencies</li>
                            <li>Deploying and monitoring numerous services independently</li>
                            <li>Ensuring data consistency and distributed tracing</li>
                            <li>Scaling services efficiently and securely</li>
                            <li>Complex CI/CD workflows and environment management</li>
                          </ul>
                        </div>
                      </li>
                    
                      <li data-id="q177">
                        <span class="faq-question">What is a centralized logging system?</span>
                        <div class="answer">
                          A centralized logging system collects and stores logs from multiple services or servers in one location. It simplifies monitoring, debugging, and auditing. Examples include the ELK Stack (Elasticsearch, Logstash, Kibana) and Graylog.
                        </div>
                      </li>
                    
                      <li data-id="q178">
                        <span class="faq-question">What is the twelve-factor app methodology?</span>
                        <div class="answer">
                          The twelve-factor app is a methodology for building modern, scalable, and maintainable SaaS applications. It promotes practices such as:
                          <ul>
                            <li>Codebase tracking in version control</li>
                            <li>Strict separation of config from code</li>
                            <li>Backing services as attached resources</li>
                            <li>Stateless processes</li>
                            <li>Dev/prod parity</li>
                            <li>Logs as event streams</li>
                            <li>Continuous deployment</li>
                          </ul>
                          It‚Äôs designed to enable portability and resilience in cloud environments.
                        </div>
                      </li>
                    
                    



                     
                        <li data-id="q179">
                          <span class="faq-question">What is cloud-native architecture?</span>
                          <div class="answer">
                            Cloud-native architecture is a design approach that leverages cloud computing technologies to build and run scalable, resilient, and manageable applications. It typically includes microservices, containers, CI/CD automation, and dynamic orchestration with tools like Kubernetes.
                          </div>
                        </li>
                      
                        <li data-id="q180">
                          <span class="faq-question">What is the difference between public, private, and hybrid cloud?</span>
                          <div class="answer">
                            <ul>
                              <li><strong>Public Cloud:</strong> Services provided by third-party providers over the internet (e.g., AWS, Azure, GCP). Shared infrastructure.</li>
                              <li><strong>Private Cloud:</strong> Cloud infrastructure used exclusively by a single organization, either on-premises or hosted.</li>
                              <li><strong>Hybrid Cloud:</strong> Combines public and private clouds, allowing data and apps to move between them for flexibility and optimization.</li>
                            </ul>
                          </div>
                        </li>
                      
                        <li data-id="q181">
                          <span class="faq-question">How do you ensure high availability in cloud deployments?</span>
                          <div class="answer">
                            High availability (HA) in cloud deployments can be ensured through:
                            <ul>
                              <li>Deploying across multiple availability zones or regions</li>
                              <li>Using load balancers for traffic distribution</li>
                              <li>Implementing auto-scaling to handle traffic spikes</li>
                              <li>Using managed services with built-in HA features</li>
                              <li>Regular monitoring and failover mechanisms</li>
                            </ul>
                          </div>
                        </li>
                      
                        <li data-id="q182">
                          <span class="faq-question">What is fault tolerance?</span>
                          <div class="answer">
                            Fault tolerance is the ability of a system to continue operating properly in the event of the failure of one or more components. It involves redundancy, failover strategies, and self-healing mechanisms to ensure uptime and reliability.
                          </div>
                        </li>
                      
                        <li data-id="q183">
                          <span class="faq-question">What is disaster recovery in DevOps?</span>
                          <div class="answer">
                            Disaster recovery in DevOps refers to the strategies and processes to restore systems, data, and operations after a catastrophic failure. This includes:
                            <ul>
                              <li>Automated backups and replication</li>
                              <li>Failover systems and redundant infrastructure</li>
                              <li>Recovery Time Objective (RTO) and Recovery Point Objective (RPO) planning</li>
                              <li>Periodic testing of disaster recovery plans</li>
                            </ul>
                          </div>
                        </li>
                 
                      



<li data-id="q32" class="yellow"><span class="faq-question">
------------------------------------------------------------------
</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">
--------------------------------------------------------------
</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">
-------------------------------------------------
</span></li>
                                                                                    

  <li data-id="q32" class="yellow">
    <span class="faq-question">Jest?</span>
    <div class="answer">
<ol>
  <li>What is Jest?</li>
  <li>How do you install Jest in a Node.js project?</li>
  <li>How do you write a simple test case in Jest?</li>
  <li>What is a test suite in Jest?</li>
  <li>What is a test case in Jest?</li>
  <li>How do you run tests using Jest?</li>
  <li>What is the difference between `test` and `it` in Jest?</li>
  <li>How do you mock functions in Jest?</li>
  <li>What is a mock function (spy) in Jest?</li>
  <li>How do you mock modules in Jest?</li>
  <li>How do you reset mocks between tests in Jest?</li>
  <li>What is the difference between `jest.fn()` and `jest.mock()`?</li>
  <li>How do you test asynchronous code in Jest?</li>
  <li>What is the use of `done` callback in Jest tests?</li>
  <li>How do you test promises in Jest?</li>
  <li>How do you test async/await functions with Jest?</li>
  <li>What is snapshot testing in Jest?</li>
  <li>How do you create and update snapshots in Jest?</li>
  <li>What are some best practices for snapshot testing?</li>
  <li>How do you run only a specific test or test suite in Jest?</li>
  <li>What are Jest setup and teardown methods?</li>
  <li>Explain `beforeAll`, `beforeEach`, `afterAll`, and `afterEach` in Jest.</li>
  <li>How do you configure Jest using `jest.config.js`?</li>
  <li>What is the default test environment in Jest?</li>
  <li>How do you change the test environment in Jest?</li>
  <li>What is code coverage and how do you measure it with Jest?</li>
  <li>How do you exclude files or directories from Jest coverage?</li>
  <li>What is the use of `--watch` mode in Jest?</li>
  <li>How do you run Jest tests in parallel?</li>
  <li>How do you use custom matchers in Jest?</li>
  <li>What are the built-in Jest matchers?</li>
  <li>How do you extend Jest matchers?</li>
  <li>How do you test React components with Jest?</li>
  <li>How do you combine Jest with React Testing Library?</li>
  <li>How do you mock API calls in Jest?</li>
  <li>How do you mock HTTP requests with Jest?</li>
  <li>How do you mock timers in Jest?</li>
  <li>What are fake timers and how do you use them in Jest?</li>
  <li>How do you clear or advance timers in Jest?</li>
  <li>How do you mock Date or time in Jest tests?</li>
  <li>How do you handle exceptions or errors in Jest tests?</li>
  <li>How do you test for thrown errors in Jest?</li>
  <li>How do you debug Jest tests?</li>
  <li>How do you run Jest tests with debugging enabled?</li>
  <li>How do you test private functions in Jest?</li>
  <li>Can you test TypeScript code with Jest?</li>
  <li>How do you configure Jest for TypeScript?</li>
  <li>What is the difference between `jest.resetAllMocks()` and `jest.clearAllMocks()`?</li>
  <li>How do you use the `test.each` function in Jest?</li>
  <li>What is the purpose of `expect.assertions()` in Jest?</li>
  <li>How do you test events or callbacks in Jest?</li>
  <li>What is the difference between `toBe` and `toEqual` in Jest?</li>
  <li>How do you test object properties and array contents with Jest?</li>
  <li>How do you mock environment variables in Jest?</li>
  <li>How do you test code that depends on environment variables?</li>
  <li>How do you use Jest with Babel?</li>
  <li>How do you use Jest with Webpack?</li>
  <li>How do you integrate Jest with CI/CD pipelines?</li>
  <li>What is the default timeout for a Jest test, and how do you change it?</li>
  <li>How do you skip or disable tests in Jest?</li>
  <li>How do you run only a single test file in Jest?</li>
  <li>How do you use test coverage thresholds in Jest?</li>
  <li>How do you generate a code coverage report in Jest?</li>
  <li>How do you mock classes or constructors in Jest?</li>
  <li>How do you spy on method calls in Jest?</li>
  <li>What is the difference between spies and mocks in Jest?</li>
  <li>How do you mock nested modules in Jest?</li>
  <li>How do you mock default exports in Jest?</li>
  <li>How do you mock named exports in Jest?</li>
  <li>How do you mock the `fs` module in Jest?</li>
  <li>How do you test command-line scripts using Jest?</li>
  <li>What is the use of `jest.clearAllTimers()`?</li>
  <li>How do you test React hooks with Jest?</li>
  <li>What is the difference between shallow rendering and full rendering in Jest?</li>
  <li>How do you use `enzyme` with Jest?</li>
  <li>How do you test Redux actions and reducers with Jest?</li>
  <li>How do you test async Redux actions with Jest?</li>
  <li>How do you mock Redux store in Jest tests?</li>
  <li>How do you test GraphQL queries with Jest?</li>
  <li>How do you mock GraphQL API calls in Jest?</li>
  <li>How do you test WebSocket connections in Jest?</li>
  <li>How do you test event emitters in Jest?</li>
  <li>How do you mock third-party libraries in Jest?</li>
  <li>How do you reset module registry in Jest?</li>
  <li>What is the purpose of `jest.isolateModules()`?</li>
  <li>How do you mock fetch requests in Jest?</li>
  <li>How do you use `jest.spyOn()`?</li>
  <li>How do you mock timers globally in Jest?</li>
  <li>How do you test conditional logic in Jest?</li>
  <li>How do you test data transformations in Jest?</li>
  <li>How do you mock database calls in Jest?</li>
  <li>How do you test error handling logic in Jest?</li>
  <li>How do you test middleware functions with Jest?</li>
  <li>How do you mock and test Express routes with Jest?</li>
  <li>How do you test performance-critical code with Jest?</li>
  <li>How do you run Jest tests in watch mode?</li>
  <li>How do you use code coverage badges with Jest?</li>
  <li>How do you generate JSON coverage reports with Jest?</li>
  <li>How do you test web workers in Jest?</li>
  <li>How do you mock console methods in Jest?</li>
  <li>How do you test command execution in Jest?</li>
  <li>How do you test file uploads with Jest?</li>
</ol></div></li>  


<li data-id="q32">
  <span class="faq-question">What is Jest?</span>
  <div class="answer">
    Jest is a popular JavaScript testing framework maintained by Meta, designed to work out-of-the-box for testing JavaScript and TypeScript projects. It provides a complete and easy-to-use solution for unit, integration, and snapshot testing with features like zero-config setup, built-in assertions, mocking, and code coverage.
  </div>
</li>

<li data-id="q33">
  <span class="faq-question">How do you install Jest in a Node.js project?</span>
  <div class="answer">
    You can install Jest via npm by running: <code>npm install --save-dev jest</code>. Then, add a test script in <code>package.json</code> like: <code>"test": "jest"</code>. Finally, run tests using <code>npm test</code>.
  </div>
</li>

<li data-id="q34">
  <span class="faq-question">How do you write a simple test case in Jest?</span>
  <div class="answer">
    You write a test case using the <code>test()</code> or <code>it()</code> function. Example:
    <pre><code>test('adds 1 + 2 to equal 3', () => {
  expect(1 + 2).toBe(3);
});</code></pre>
  </div>
</li>

<li data-id="q35">
  <span class="faq-question">What is a test suite in Jest?</span>
  <div class="answer">
    A test suite is a collection of related test cases grouped together using the <code>describe()</code> function. It helps organize tests logically.
  </div>
</li>

<li data-id="q36">
  <span class="faq-question">What is a test case in Jest?</span>
  <div class="answer">
    A test case is an individual unit of testing defined using <code>test()</code> or <code>it()</code>. It contains the actual code that tests a specific behavior or function.
  </div>
</li>

<li data-id="q37">
  <span class="faq-question">How do you run tests using Jest?</span>
  <div class="answer">
    Run the command <code>npx jest</code> or <code>npm test</code> (if configured) in the terminal. Jest will find and execute tests matching its default or configured patterns.
  </div>
</li>

<li data-id="q38">
  <span class="faq-question">What is the difference between <b>test</b> and <b>it</b> in Jest?</span>
  <div class="answer">
    There is no functional difference between <code>test()</code> and <code>it()</code> in Jest. Both define a test case. <code>it()</code> is often preferred for readability in behavior-driven development (BDD) style.
  </div>
</li>

<li data-id="q39">
  <span class="faq-question">How do you mock functions in Jest?</span>
  <div class="answer">
    You can mock functions using <code>jest.fn()</code> to create a mock function or use <code>jest.spyOn(object, 'method')</code> to spy on existing methods.
  </div>
</li>

<li data-id="q40">
  <span class="faq-question">What is a mock function (spy) in Jest?</span>
  <div class="answer">
    A mock function (spy) records information about its calls, such as arguments and return values, allowing you to test if a function was called correctly without executing its real implementation.
  </div>
</li>

<li data-id="q41">
  <span class="faq-question">How do you mock modules in Jest?</span>
  <div class="answer">
    Use <code>jest.mock('moduleName')</code> to mock an entire module. You can provide custom implementations by passing a factory function as the second argument.
  </div>
</li>
<li data-id="q42">
  <span class="faq-question">How do you reset mocks between tests in Jest?</span>
  <div class="answer">
    You can reset mocks between tests using Jest's lifecycle methods such as <code>beforeEach(() => { jest.resetAllMocks(); })</code> or <code>afterEach(() => { jest.clearAllMocks(); })</code> to ensure mocks don‚Äôt retain state between tests.
  </div>
</li>

<li data-id="q43">
  <span class="faq-question">What is the difference between <b>jest.fn()</b> and <b>jest.mock()</b>?</span>
  <div class="answer">
    <code>jest.fn()</code> creates a standalone mock function, while <code>jest.mock()</code> mocks entire modules or specific module exports automatically.
  </div>
</li>

<li data-id="q44">
  <span class="faq-question">How do you test asynchronous code in Jest?</span>
  <div class="answer">
    You can test async code by returning a Promise, using async/await, or using the <code>done</code> callback to signal Jest when the async operation completes.
  </div>
</li>

<li data-id="q45">
  <span class="faq-question">What is the use of <b>done</b> callback in Jest tests?</span>
  <div class="answer">
    The <code>done</code> callback is used in tests to tell Jest that an asynchronous test has finished, which is useful for callback-based async functions.
  </div>
</li>

<li data-id="q46">
  <span class="faq-question">How do you test promises in Jest?</span>
  <div class="answer">
    Return the promise from the test, and use matchers like <code>resolves</code> and <code>rejects</code> to assert outcomes. Example: <code>return expect(promise).resolves.toBe(value);</code>
  </div>
</li>

<li data-id="q47">
  <span class="faq-question">How do you test async/await functions with Jest?</span>
  <div class="answer">
    Declare the test function as <code>async</code> and use <code>await</code> inside it to wait for promises. Example: <code>test('...', async () => { const data = await fetchData(); expect(data).toBe(...); });</code>
  </div>
</li>

<li data-id="q48">
  <span class="faq-question">What is snapshot testing in Jest?</span>
  <div class="answer">
    Snapshot testing captures the rendered output or value of a component/function at a given time and compares it on subsequent runs to detect unintended changes.
  </div>
</li>

<li data-id="q49">
  <span class="faq-question">How do you create and update snapshots in Jest?</span>
  <div class="answer">
    Run tests with <code>jest --updateSnapshot</code> or <code>u</code> in interactive mode to create or update snapshot files.
  </div>
</li>

<li data-id="q50">
  <span class="faq-question">What are some best practices for snapshot testing?</span>
  <div class="answer">
    Keep snapshots small and focused, review snapshot changes carefully before committing, and avoid snapshots for frequently changing or trivial output.
  </div>
</li>

<li data-id="q51">
  <span class="faq-question">How do you run only a specific test or test suite in Jest?</span>
  <div class="answer">
    Use <code>test.only()</code> or <code>describe.only()</code> to run specific tests or suites. Alternatively, run Jest with the <code>-t</code> flag and a test name pattern.
  </div>
</li>
<li data-id="q52">
  <span class="faq-question">What are Jest setup and teardown methods?</span>
  <div class="answer">
    Setup and teardown methods in Jest are lifecycle hooks that run code before and after tests or test suites, helping prepare the environment or clean up resources.
  </div>
</li>

<li data-id="q53">
  <span class="faq-question">Explain <b>beforeAll</b>, <b>beforeEach</b>, <b>afterAll</b>, and <b>afterEach</b> in Jest.</span>
  <div class="answer">
    <ul>
      <li><code>beforeAll()</code>: Runs once before all tests in a suite.</li>
      <li><code>beforeEach()</code>: Runs before each individual test.</li>
      <li><code>afterEach()</code>: Runs after each individual test.</li>
      <li><code>afterAll()</code>: Runs once after all tests in a suite.</li>
    </ul>
  </div>
</li>

<li data-id="q54">
  <span class="faq-question">How do you configure Jest using <b>jest.config.js</b>?</span>
  <div class="answer">
    Create a <code>jest.config.js</code> file in the project root and export an object with Jest configuration options, e.g.:
    <pre><code>module.exports = {
  testEnvironment: 'node',
  verbose: true,
  coverageDirectory: 'coverage',
};</code></pre>
  </div>
</li>

<li data-id="q55">
  <span class="faq-question">What is the default test environment in Jest?</span>
  <div class="answer">
    The default test environment in Jest is <code>jsdom</code>, which simulates a browser-like environment.
  </div>
</li>

<li data-id="q56">
  <span class="faq-question">How do you change the test environment in Jest?</span>
  <div class="answer">
    Set the <code>testEnvironment</code> option in <code>jest.config.js</code>, e.g., <code>testEnvironment: 'node'</code> to use a Node.js environment.
  </div>
</li>

<li data-id="q57">
  <span class="faq-question">What is code coverage and how do you measure it with Jest?</span>
  <div class="answer">
    Code coverage measures how much of your code is exercised by tests. In Jest, use the <code>--coverage</code> flag to generate coverage reports.
  </div>
</li>

<li data-id="q58">
  <span class="faq-question">How do you exclude files or directories from Jest coverage?</span>
  <div class="answer">
    Use the <code>coveragePathIgnorePatterns</code> option in <code>jest.config.js</code> to specify files or folders to exclude from coverage.
  </div>
</li>

<li data-id="q59">
  <span class="faq-question">What is the use of <b>--watch</b> mode in Jest?</span>
  <div class="answer">
    The <code>--watch</code> mode runs Jest in watch mode, re-running tests on file changes for faster development feedback.
  </div>
</li>

<li data-id="q60">
  <span class="faq-question">How do you run Jest tests in parallel?</span>
  <div class="answer">
    Jest runs tests in parallel by default, using worker threads. You can control concurrency with the <code>--maxWorkers</code> option.
  </div>
</li>

<li data-id="q61">
  <span class="faq-question">How do you use custom matchers in Jest?</span>
  <div class="answer">
    Custom matchers can be added by extending Jest‚Äôs expect using <code>expect.extend()</code> with your own matcher functions.
  </div>
</li>
<li data-id="q62">
  <span class="faq-question">What are the built-in Jest matchers?</span>
  <div class="answer">
    Jest provides built-in matchers like <code>toBe()</code>, <code>toEqual()</code>, <code>toContain()</code>, <code>toBeNull()</code>, <code>toBeTruthy()</code>, <code>toHaveBeenCalled()</code>, and many more for asserting values and behaviors.
  </div>
</li>

<li data-id="q63">
  <span class="faq-question">How do you extend Jest matchers?</span>
  <div class="answer">
    Use <code>expect.extend()</code> to add custom matcher functions, which enhance Jest‚Äôs assertion capabilities with your own logic.
  </div>
</li>

<li data-id="q64">
  <span class="faq-question">How do you test React components with Jest?</span>
  <div class="answer">
    Write test files that import React components, render them (usually with tools like React Testing Library or Enzyme), and use Jest assertions to verify UI behavior and output.
  </div>
</li>

<li data-id="q65">
  <span class="faq-question">How do you combine Jest with React Testing Library?</span>
  <div class="answer">
    Use React Testing Library‚Äôs rendering and querying utilities inside Jest test cases to interact with components and assert expected UI states.
  </div>
</li>

<li data-id="q66">
  <span class="faq-question">How do you mock API calls in Jest?</span>
  <div class="answer">
    Mock API calls by mocking the modules making HTTP requests using <code>jest.mock()</code> or by using libraries like <code>msw</code> (Mock Service Worker) for more advanced scenarios.
  </div>
</li>

<li data-id="q67">
  <span class="faq-question">How do you mock HTTP requests with Jest?</span>
  <div class="answer">
    Use Jest‚Äôs manual mocks to replace HTTP libraries (like axios or fetch) or use <code>jest.spyOn()</code> to mock specific methods, returning controlled responses.
  </div>
</li>

<li data-id="q68">
  <span class="faq-question">How do you mock timers in Jest?</span>
  <div class="answer">
    Use Jest‚Äôs fake timer functions with <code>jest.useFakeTimers()</code> to control timer functions like <code>setTimeout</code>, <code>setInterval</code>, and <code>Date.now()</code>.
  </div>
</li>

<li data-id="q69">
  <span class="faq-question">What are fake timers and how do you use them in Jest?</span>
  <div class="answer">
    Fake timers allow you to simulate and control the passage of time in tests. Use <code>jest.useFakeTimers()</code> and then control time with methods like <code>jest.advanceTimersByTime()</code>.
  </div>
</li>

<li data-id="q70">
  <span class="faq-question">How do you clear or advance timers in Jest?</span>
  <div class="answer">
    Use <code>jest.clearAllTimers()</code> to clear timers and <code>jest.advanceTimersByTime(ms)</code> to fast-forward the timer by a specified number of milliseconds.
  </div>
</li>

<li data-id="q71">
  <span class="faq-question">How do you mock Date or time in Jest tests?</span>
  <div class="answer">
    Mock Date by overriding <code>Date.now()</code> or creating a mock Date object inside tests, often combined with fake timers for complete control over time-based code.
  </div>
</li>
<li data-id="q72">
  <span class="faq-question">How do you handle exceptions or errors in Jest tests?</span>
  <div class="answer">
    Use <code>try/catch</code> blocks inside test functions or test for errors using Jest‚Äôs <code>toThrow()</code> matcher to assert that a function throws an error.
  </div>
</li>

<li data-id="q73">
  <span class="faq-question">How do you test for thrown errors in Jest?</span>
  <div class="answer">
    Use <code>expect(() => fn()).toThrow()</code> or <code>await expect(asyncFn()).rejects.toThrow()</code> to test synchronous and asynchronous error throwing respectively.
  </div>
</li>

<li data-id="q74">
  <span class="faq-question">How do you debug Jest tests?</span>
  <div class="answer">
    Use <code>console.log()</code> statements or run Jest in debug mode with Node.js debuggers like Chrome DevTools or VSCode debugger to inspect variables and test flow.
  </div>
</li>

<li data-id="q75">
  <span class="faq-question">How do you run Jest tests with debugging enabled?</span>
  <div class="answer">
    Run Jest with <code>node --inspect-brk ./node_modules/.bin/jest --runInBand</code> and attach a debugger in your IDE or Chrome DevTools for step-by-step debugging.
  </div>
</li>

<li data-id="q76">
  <span class="faq-question">How do you test private functions in Jest?</span>
  <div class="answer">
    Export private functions explicitly for testing or test them indirectly through the public API. Avoid testing internals directly to keep tests maintainable.
  </div>
</li>

<li data-id="q77">
  <span class="faq-question">Can you test TypeScript code with Jest?</span>
  <div class="answer">
    Yes, Jest supports TypeScript via additional setup like <code>ts-jest</code> which compiles TypeScript during tests.
  </div>
</li>

<li data-id="q78">
  <span class="faq-question">How do you configure Jest for TypeScript?</span>
  <div class="answer">
    Install <code>ts-jest</code> and configure Jest by setting <code>preset: "ts-jest"</code> in <code>jest.config.js</code> to enable TypeScript support.
  </div>
</li>

<li data-id="q79">
  <span class="faq-question">What is the difference between <b>jest.resetAllMocks()</b> and <b>jest.clearAllMocks()</b>?</span>
  <div class="answer">
    <code>jest.clearAllMocks()</code> resets mock call history but keeps mock implementations; <code>jest.resetAllMocks()</code> resets both call history and implementations.
  </div>
</li>

<li data-id="q80">
  <span class="faq-question">How do you use the <b>test.each</b> function in Jest?</span>
  <div class="answer">
    <code>test.each(table)(name, fn)</code> runs the same test repeatedly with different data sets from <code>table</code>, useful for parameterized testing.
  </div>
</li>

<li data-id="q81">
  <span class="faq-question">What is the purpose of <b>expect.assertions()</b> in Jest?</span>
  <div class="answer">
    It ensures a certain number of assertions are called during a test, useful especially in async tests to verify all expected checks run.
  </div>
</li>










<li data-id="q32" class="yellow"><span class="faq-question">==========  jest : 50 - 102 ======================</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">================================</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">================================</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">================================</span></li>















  
  
<li data-id="q32" class="yellow"><span class="faq-question">
CI/CD Question List?
</span><div class="answer">

  <ol>
    <li>What is GitHub Actions?</li>
    <li>How does GitHub Actions enable CI/CD?</li>
    <li>What is a workflow in GitHub Actions?</li>
    <li>What is a job in GitHub Actions?</li>
    <li>What are steps in a GitHub Actions workflow?</li>
    <li>What is an action in GitHub Actions?</li>
    <li>What is a runner in GitHub Actions?</li>
    <li>What is the difference between a hosted and self-hosted runner?</li>
    <li>How do you trigger a GitHub Actions workflow?</li>
    <li>What are GitHub Actions workflow events?</li>
    <li>How do you schedule workflows in GitHub Actions?</li>
    <li>What is the syntax of a GitHub Actions workflow file?</li>
    <li>What are reusable workflows in GitHub Actions?</li>
    <li>How do you use secrets in GitHub Actions?</li>
    <li>How do you pass environment variables in GitHub Actions?</li>
    <li>How do you cache dependencies in GitHub Actions?</li>
    <li>How do you use matrix builds in GitHub Actions?</li>
    <li>How do you implement conditional steps in GitHub Actions?</li>
    <li>How do you deploy to AWS from GitHub Actions?</li>
    <li>How do you deploy to Heroku using GitHub Actions?</li>
    <li>How do you deploy to Firebase using GitHub Actions?</li>
    <li>How do you deploy to Kubernetes using GitHub Actions?</li>
    <li>How do you use Docker in GitHub Actions?</li>
    <li>How do you publish Docker images to GitHub Container Registry (GHCR)?</li>
    <li>What is the `uses` keyword in GitHub Actions?</li>
    <li>What is the `run` keyword in GitHub Actions?</li>
    <li>How do you debug GitHub Actions workflows?</li>
    <li>What are the different status checks in GitHub Actions?</li>
    <li>What is the difference between `main.yml` and `ci.yml`?</li>
    <li>How do you use third-party actions in your workflow?</li>
    <li>How do you create a custom GitHub Action?</li>
    <li>What are composite actions in GitHub?</li>
    <li>How do you handle manual approvals in GitHub Actions?</li>
    <li>What are environments in GitHub Actions?</li>
    <li>How do you create deployment gates with GitHub Actions?</li>
    <li>How do you test PRs with GitHub Actions?</li>
    <li>How do you restrict workflows to specific branches?</li>
    <li>How do you use `concurrency` in GitHub Actions?</li>
    <li>What is the `jobs.<job_id>.needs` keyword used for?</li>
    <li>How do you run workflows only on specific file changes?</li>
    <li>How do you upload and download artifacts in GitHub Actions?</li>
    <li>What is the `GITHUB_TOKEN` and how is it used?</li>
    <li>How do you integrate GitHub Actions with Slack?</li>
    <li>How do you implement CI/CD for a Node.js app using GitHub Actions?</li>
    <li>How do you set up CI/CD for a React app using GitHub Actions?</li>
    <li>How do you implement testing with Jest in GitHub Actions?</li>
    <li>How do you version your application using GitHub Actions?</li>
    <li>How do you implement semantic release with GitHub Actions?</li>
    <li>How do you use GitHub Actions for monorepos?</li>
    <li>What are common security best practices for GitHub Actions?</li>
    <li>What are common CI/CD anti-patterns in GitHub Actions?</li>

    <li>What is CI/CD?</li>
    <li>What are the main goals of CI/CD?</li>
    <li>What are the benefits of implementing CI/CD in a project?</li>
    <li>What is the difference between CI and CD?</li>
    <li>What are the key components of a CI/CD pipeline?</li>
    <li>How do you design a CI/CD pipeline?</li>
    <li>What tools are commonly used for CI/CD?</li>
    <li>Explain the role of Jenkins in CI/CD.</li>
    <li>What are some popular alternatives to Jenkins?</li>
    <li>What is a build pipeline?</li>
    <li>What is a deployment pipeline?</li>
    <li>What is continuous integration?</li>
    <li>What is continuous delivery?</li>
    <li>What is continuous deployment?</li>
    <li>What is the difference between continuous delivery and deployment?</li>
    <li>What is a build artifact?</li>
    <li>What is an artifact repository?</li>
    <li>How do you manage secrets in a CI/CD pipeline?</li>
    <li>What is a webhook in the context of CI/CD?</li>
    <li>What is pipeline as code?</li>
    <li>What is YAML and how is it used in CI/CD?</li>
    <li>What is GitOps?</li>
    <li>What are stages in a CI/CD pipeline?</li>
    <li>How do you handle rollback in CI/CD?</li>
    <li>What are canary deployments?</li>
    <li>What are blue-green deployments?</li>
    <li>What is A/B testing in deployment?</li>
    <li>What is the purpose of unit testing in CI/CD?</li>
    <li>What is integration testing?</li>
    <li>What is end-to-end testing?</li>
    <li>What is smoke testing in CI/CD?</li>
    <li>How do you automate testing in a CI/CD pipeline?</li>
    <li>How do you monitor a CI/CD pipeline?</li>
    <li>What is code coverage and how is it tracked?</li>
    <li>How do you enforce code quality in a pipeline?</li>
    <li>What are some security concerns with CI/CD?</li>
    <li>What is DevSecOps?</li>
    <li>What is a self-hosted runner?</li>
    <li>What is a shared runner in GitLab CI?</li>
    <li>How does GitHub Actions compare to Jenkins?</li>
    <li>How do you deploy to AWS using CI/CD?</li>
    <li>How do you deploy to Kubernetes using CI/CD?</li>
    <li>How do you deploy to Azure using CI/CD?</li>
    <li>What is Helm and how is it used in CI/CD?</li>
    <li>What is ArgoCD?</li>
    <li>What is Spinnaker?</li>
    <li>What is CircleCI?</li>
    <li>What is Travis CI?</li>
    <li>What is Bitbucket Pipelines?</li>
    <li>What is CodePipeline (AWS)?</li>
    <li>What is CodeBuild (AWS)?</li>
    <li>How do you secure credentials in GitHub Actions?</li>
    <li>What is the role of environment variables in CI/CD?</li>
    <li>What is caching in CI/CD pipelines?</li>
    <li>What are pipeline triggers?</li>
    <li>How do you run a pipeline manually?</li>
    <li>What is a multi-branch pipeline?</li>
    <li>How do you handle database migrations in CI/CD?</li>
    <li>How do you version artifacts in a pipeline?</li>
    <li>How do you notify teams of pipeline results?</li>
    <li>What is the difference between declarative and scripted pipelines?</li>
    <li>How do you integrate Docker in a CI/CD pipeline?</li>
    <li>How do you publish Docker images from a pipeline?</li>
    <li>How do you use Docker Compose in CI/CD?</li>
    <li>What are runners/agents/executors in CI/CD?</li>
    <li>How can you parallelize builds in CI/CD?</li>
    <li>What are matrix builds?</li>
    <li>What are the best practices for writing CI/CD pipelines?</li>
    <li>What is infrastructure as code (IaC) in CI/CD?</li>
    <li>What is Terraform and how is it used in CI/CD?</li>
    <li>What is Ansible and how is it integrated in pipelines?</li>
    <li>What is the difference between on-prem CI/CD and cloud CI/CD?</li>
    <li>How do you test microservices with CI/CD?</li>
    <li>How do you manage monorepos in CI/CD?</li>
    <li>How does feature flagging help in CD?</li>
    <li>What is progressive delivery?</li>
    <li>What is a job in CI/CD terminology?</li>
    <li>What is a workflow in GitHub Actions?</li>
    <li>What is a pipeline template?</li>
    <li>How do you use artifacts between pipeline stages?</li>
    <li>How do you implement approval gates in CI/CD?</li>
    <li>What is pipeline orchestration?</li>
    <li>What are common CI/CD anti-patterns?</li>
    <li>What is the role of code review in CI/CD?</li>
    <li>What is the difference between push and pull-based deployment?</li>
    <li>What is drift detection in CI/CD?</li>
    <li>How do you test infrastructure changes with CI/CD?</li>
    <li>How can you use static code analysis tools in a pipeline?</li>
    <li>What is SonarQube and how is it used in CI/CD?</li>
    <li>What is the importance of feedback loops in CI/CD?</li>
    <li>How do you track pipeline history?</li>
    <li>How do you configure branch-based deployments?</li>
    <li>How do you handle dependency management in CI/CD?</li>
    <li>How do you test frontend and backend apps together in CI/CD?</li>
    <li>What‚Äôs the role of a package manager in CI/CD?</li>
    <li>How do you run background services for tests in CI/CD?</li>
    <li>How do you debug a failed pipeline?</li>
    <li>How do you make pipelines scalable?</li>
    <li>How do you ensure idempotency in deployments?</li>
    <li>How do you manage pipeline drift?</li>
  </ol>
  
</div></li>

<li data-id="q32">
  <span class="faq-question">What is GitHub Actions?</span>
  <div class="answer">
    GitHub Actions is a CI/CD platform provided by GitHub that allows you to automate software workflows directly in your repository. You can use it to build, test, and deploy your code every time a change is pushed to your repo, or on a schedule.
  </div>
</li>

<li data-id="q33">
  <span class="faq-question">How does GitHub Actions enable CI/CD?</span>
  <div class="answer">
    GitHub Actions enables CI/CD by allowing developers to define workflows using YAML files. These workflows can include steps for building, testing, and deploying applications automatically in response to triggers like code pushes, pull requests, or cron schedules.
  </div>
</li>

<li data-id="q34">
  <span class="faq-question">What is a workflow in GitHub Actions?</span>
  <div class="answer">
    A workflow is a configurable automated process made up of one or more jobs. It is defined in a YAML file stored in the `.github/workflows` directory of your repository and is triggered by specific GitHub events like `push`, `pull_request`, or `schedule`.
  </div>
</li>

<li data-id="q35">
  <span class="faq-question">What is a job in GitHub Actions?</span>
  <div class="answer">
    A job is a set of steps that execute on the same runner in a workflow. Jobs are executed in parallel by default, but you can define dependencies using the `needs` keyword to control their order of execution.
  </div>
</li>

<li data-id="q36">
  <span class="faq-question">What are steps in a GitHub Actions workflow?</span>
  <div class="answer">
    Steps are individual tasks that are executed as part of a job in a GitHub Actions workflow. They can run shell commands or use actions. All steps in a job run sequentially on the same runner.
  </div>
</li>

<li data-id="q37">
  <span class="faq-question">What is an action in GitHub Actions?</span>
  <div class="answer">
    An action is a reusable extension that can be used as a step in a workflow. Actions can be created by you or sourced from the GitHub Marketplace. They encapsulate a specific task, like setting up a language environment or deploying code.
  </div>
</li>

<li data-id="q38">
  <span class="faq-question">What is a runner in GitHub Actions?</span>
  <div class="answer">
    A runner is a server that executes the jobs defined in your GitHub Actions workflows. It listens for available jobs and runs each job‚Äôs steps in sequence using the environment defined by the job.
  </div>
</li>

<li data-id="q39">
  <span class="faq-question">What is the difference between a hosted and self-hosted runner?</span>
  <div class="answer">
    A hosted runner is provided by GitHub and runs in their cloud environment, while a self-hosted runner is a machine you manage. Hosted runners are easy to set up and maintain, but self-hosted runners allow more control over the runtime and environment.
  </div>
</li>


<li data-id="q40">
  <span class="faq-question">How do you trigger a GitHub Actions workflow?</span>
  <div class="answer">
    A GitHub Actions workflow can be triggered by various events such as a `push` to a branch, a `pull_request`, a manual dispatch (`workflow_dispatch`), or a scheduled cron job (`schedule`). These triggers are defined under the `on:` key in the workflow file.
  </div>
</li>

<li data-id="q41">
  <span class="faq-question">What are GitHub Actions workflow events?</span>
  <div class="answer">
    Workflow events are specific GitHub events that trigger workflows. Common events include `push`, `pull_request`, `issues`, `release`, `workflow_dispatch`, and `schedule`. Each event corresponds to actions performed on the repository.
  </div>
</li>

<li data-id="q42">
  <span class="faq-question">How do you schedule workflows in GitHub Actions?</span>
  <div class="answer">
    Workflows can be scheduled using the `schedule` event and a cron expression. This allows you to run workflows automatically at specific intervals or times. For example:<br><code>on: schedule:<br>&nbsp;&nbsp;- cron: '0 0 * * *'</code>
  </div>
</li>

<li data-id="q43">
  <span class="faq-question">What is the syntax of a GitHub Actions workflow file?</span>
  <div class="answer">
    A workflow file is written in YAML and stored under `.github/workflows/`. The basic syntax includes `name`, `on` (event), `jobs`, and `steps`. Each job contains steps, and each step can run a command or use an action.
  </div>
</li>

<li data-id="q44">
  <span class="faq-question">What are reusable workflows in GitHub Actions?</span>
  <div class="answer">
    Reusable workflows are workflows that can be referenced and called from other workflows using the `workflow_call` trigger. They promote modularity and reduce duplication across repositories or workflows.
  </div>
</li>

<li data-id="q45">
  <span class="faq-question">How do you use secrets in GitHub Actions?</span>
  <div class="answer">
    Secrets can be stored securely in your GitHub repository or organization settings under <strong>Settings &gt; Secrets</strong>. You can reference them in workflows using <code>${{ secrets.SECRET_NAME }}</code> and they are automatically masked in logs.
  </div>
</li>

<li data-id="q46">
  <span class="faq-question">How do you pass environment variables in GitHub Actions?</span>
  <div class="answer">
    You can pass environment variables using the `env` key at the workflow, job, or step level. Example:<br>
    <code>env:<br>&nbsp;&nbsp;NODE_ENV: production</code><br>
    These variables can then be accessed in shell commands or scripts within the workflow.
  </div>
</li>

<li data-id="q47">
  <span class="faq-question">How do you cache dependencies in GitHub Actions?</span>
  <div class="answer">
    You can cache dependencies using the `actions/cache` action. This speeds up builds by storing and reusing dependency files. Example for Node.js:<br>
    <code>
      - uses: actions/cache@v3<br>
        with:<br>
        &nbsp;&nbsp;path: node_modules<br>
        &nbsp;&nbsp;key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
    </code>
  </div>
</li>

<li data-id="q48">
  <span class="faq-question">How do you use matrix builds in GitHub Actions?</span>
  <div class="answer">
    Matrix builds allow you to run a job across multiple combinations of variables. This is useful for testing across multiple Node.js versions or OS types. Example:<br>
    <code>
      strategy:<br>
      &nbsp;&nbsp;matrix:<br>
      &nbsp;&nbsp;&nbsp;&nbsp;node-version: [14, 16, 18]
    </code>
  </div>
</li>

<li data-id="q49">
  <span class="faq-question">How do you implement conditional steps in GitHub Actions?</span>
  <div class="answer">
    You can implement conditional steps using the `if` keyword. It allows you to run a step only if a certain condition is met. Example:<br>
    <code>
      - name: Run only on main<br>
        if: github.ref == 'refs/heads/main'<br>
        run: echo "This runs only on main branch"
    </code>
  </div>
</li>

<li data-id="q50">
  <span class="faq-question">How do you deploy to AWS from GitHub Actions?</span>
  <div class="answer">
    To deploy to AWS, you typically use the `aws-actions/configure-aws-credentials` action followed by CLI or custom actions for deployment. Example:<br>
    <code>
      - uses: aws-actions/configure-aws-credentials@v3<br>
        with:<br>
        &nbsp;&nbsp;aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}<br>
        &nbsp;&nbsp;aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}<br>
        &nbsp;&nbsp;aws-region: us-east-1
    </code>
  </div>
</li>

<li data-id="q51">
  <span class="faq-question">How do you deploy to Heroku using GitHub Actions?</span>
  <div class="answer">
    You can deploy to Heroku by using the `akhileshns/heroku-deploy` action. It requires a Heroku API key, app name, and email. Example:<br>
    <code>
      - uses: akhileshns/heroku-deploy@v3.12.12<br>
        with:<br>
        &nbsp;&nbsp;heroku_api_key: ${{ secrets.HEROKU_API_KEY }}<br>
        &nbsp;&nbsp;heroku_app_name: "your-app-name"<br>
        &nbsp;&nbsp;heroku_email: "you@example.com"
    </code>
  </div>
</li>

<li data-id="q52">
  <span class="faq-question">How do you deploy to Firebase using GitHub Actions?</span>
  <div class="answer">
    To deploy to Firebase, you can use the `FirebaseExtended/action-hosting-deploy` action. It requires a Firebase token and project ID. Example:<br>
    <code>
      - uses: FirebaseExtended/action-hosting-deploy@v0<br>
        with:<br>
        &nbsp;&nbsp;repoToken: "${{ secrets.GITHUB_TOKEN }}"<br>
        &nbsp;&nbsp;firebaseServiceAccount: "${{ secrets.FIREBASE_SERVICE_ACCOUNT }}"<br>
        &nbsp;&nbsp;channelId: live<br>
        &nbsp;&nbsp;projectId: your-project-id
    </code>
  </div>
</li>

<li data-id="q53">
  <span class="faq-question">How do you deploy to Kubernetes using GitHub Actions?</span>
  <div class="answer">
    You can deploy to Kubernetes using the `kubectl` CLI in GitHub Actions. Set up your kubeconfig and run deployment commands. Example:<br>
    <code>
      - name: Set up Kubeconfig<br>
        run: echo "${{ secrets.KUBECONFIG }}" &gt; $HOME/.kube/config<br><br>
      - name: Deploy<br>
        run: kubectl apply -f k8s/deployment.yaml
    </code>
  </div>
</li>

<li data-id="q54">
  <span class="faq-question">How do you use Docker in GitHub Actions?</span>
  <div class="answer">
    You can use Docker in GitHub Actions to build, test, and push images. Example:<br>
    <code>
      - name: Build Docker image<br>
        run: docker build -t my-app .<br><br>
      - name: Run container<br>
        run: docker run my-app
    </code>
  </div>
</li>

<li data-id="q55">
  <span class="faq-question">How do you publish Docker images to GitHub Container Registry (GHCR)?</span>
  <div class="answer">
    Use `docker login` and `docker push` in GitHub Actions. Example:<br>
    <code>
      - name: Log in to GitHub Container Registry<br>
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin<br><br>
      - name: Push image<br>
        run: docker push ghcr.io/${{ github.repository }}/my-image:latest
    </code>
  </div>
</li>

<li data-id="q56">
  <span class="faq-question">What is the <b>uses</b> keyword in GitHub Actions?</span>
  <div class="answer">
    The <code>uses</code> keyword specifies an action to run in a step. It can refer to an action from the GitHub Marketplace, a public repo, or a local path. Example:<br>
    <code>
      - uses: actions/checkout@v3
    </code>
  </div>
</li>
<li data-id="q57">
  <span class="faq-question">What is the <b>run</b> keyword in GitHub Actions?</span>
  <div class="answer">
    The <code>run</code> keyword is used to execute shell commands in a step within a job. You can use it to build, test, or run any script directly in the runner‚Äôs shell. Example:<br>
    <code>
      - name: Install dependencies<br>
        run: npm install
    </code>
  </div>
</li>

<li data-id="q58">
  <span class="faq-question">How do you debug GitHub Actions workflows?</span>
  <div class="answer">
    You can debug workflows by using `run: echo` statements, enabling step output logging, and enabling `ACTIONS_STEP_DEBUG=true` as a secret. Additionally, GitHub provides logs for every step to help identify issues.
  </div>
</li>

<li data-id="q59">
  <span class="faq-question">What are the different status checks in GitHub Actions?</span>
  <div class="answer">
    Status checks include success, failure, cancelled, and skipped. These indicate whether a job or workflow ran successfully, failed, was manually cancelled, or didn‚Äôt meet conditions to run.
  </div>
</li>

<li data-id="q60">
  <span class="faq-question">What is the difference between <b>main.yml</b> and <b>ci.yml</b>?</span>
  <div class="answer">
    There is no functional difference based on file name alone. Both are workflow YAML files. Naming is for organization: <code>main.yml</code> might run general tasks, while <code>ci.yml</code> may be focused on continuous integration like building and testing.
  </div>
</li>

<li data-id="q61">
  <span class="faq-question">How do you use third-party actions in your workflow?</span>
  <div class="answer">
    You can use third-party actions by referencing them in the <code>uses</code> keyword. Most actions are available on the GitHub Marketplace. Example:<br>
    <code>
      - uses: actions/setup-node@v3<br>
        with:<br>
        &nbsp;&nbsp;node-version: '18'
    </code>
  </div>
</li>
<li data-id="q62">
  <span class="faq-question">How do you create a custom GitHub Action?</span>
  <div class="answer">
    You can create a custom action using JavaScript, Docker, or as a composite action. Place the action code in a repository and define it in an <code>action.yml</code> file with inputs, outputs, and runs section. Example:<br>
    <code>
      name: "My Custom Action"<br>
      runs:<br>
      &nbsp;&nbsp;using: "node12"<br>
      &nbsp;&nbsp;main: "index.js"
    </code>
  </div>
</li>

<li data-id="q63">
  <span class="faq-question">What are composite actions in GitHub?</span>
  <div class="answer">
    Composite actions let you combine multiple steps from different actions into one reusable action. They're written in YAML and use the <code>runs.using: composite</code> field. Useful for encapsulating repeatable logic.
  </div>
</li>

<li data-id="q64">
  <span class="faq-question">How do you handle manual approvals in GitHub Actions?</span>
  <div class="answer">
    Use environments with required reviewers for manual approvals. When a job references an environment, GitHub will pause the workflow until it's manually approved. Example:<br>
    <code>
      environment: production
    </code>
  </div>
</li>

<li data-id="q65">
  <span class="faq-question">What are environments in GitHub Actions?</span>
  <div class="answer">
    Environments define specific deployment targets like staging or production. You can configure secrets, protection rules, and required reviewers for each environment. Jobs can reference an environment using the <code>environment</code> key.
  </div>
</li>

<li data-id="q66">
  <span class="faq-question">How do you create deployment gates with GitHub Actions?</span>
  <div class="answer">
    Deployment gates are created using environments with required reviewers and wait timers. This allows enforcing approvals or time-based delays before continuing with the deployment job.
  </div>
</li>

<li data-id="q67">
  <span class="faq-question">How do you test PRs with GitHub Actions?</span>
  <div class="answer">
    You can trigger workflows on pull request events using <code>on: pull_request</code>. This runs your tests or other jobs automatically whenever a PR is created or updated.
  </div>
</li>

<li data-id="q68">
  <span class="faq-question">How do you restrict workflows to specific branches?</span>
  <div class="answer">
    Use the <code>branches</code> filter under the <code>on</code> key. Example:<br>
    <code>
      on:<br>
      &nbsp;&nbsp;push:<br>
      &nbsp;&nbsp;&nbsp;&nbsp;branches: [ main, develop ]
    </code>
  </div>
</li>

<li data-id="q69">
  <span class="faq-question">How do you use <b>concurrency</b> in GitHub Actions?</span>
  <div class="answer">
    The <code>concurrency</code> keyword ensures that only one workflow or job with the same concurrency group runs at a time, canceling any previous runs in the group. Useful to avoid race conditions. Example:<br>
    <code>
      concurrency:<br>
      &nbsp;&nbsp;group: ${{ github.ref }}<br>
      &nbsp;&nbsp;cancel-in-progress: true
    </code>
  </div>
</li>

<li data-id="q70">
  <span class="faq-question">What is the <b>jobs..needs</b> keyword used for?</span>
  <div class="answer">
    The <code>needs</code> keyword defines job dependencies, making a job wait for others to complete before running. It helps create sequential or conditional workflows. Example:<br>
    <code>
      jobs:<br>
      &nbsp;&nbsp;build:<br>
      &nbsp;&nbsp;&nbsp;&nbsp;runs-on: ubuntu-latest<br>
      &nbsp;&nbsp;test:<br>
      &nbsp;&nbsp;&nbsp;&nbsp;needs: build<br>
      &nbsp;&nbsp;&nbsp;&nbsp;runs-on: ubuntu-latest
    </code>
  </div>
</li>

<li data-id="q71">
  <span class="faq-question">How do you run workflows only on specific file changes?</span>
  <div class="answer">
    Use the <code>paths</code> or <code>paths-ignore</code> filters under the <code>on</code> key to trigger workflows only when certain files or directories change. Example:<br>
    <code>
      on:<br>
      &nbsp;&nbsp;push:<br>
      &nbsp;&nbsp;&nbsp;&nbsp;paths: [ 'src/**', 'package.json' ]
    </code>
  </div>
</li>
<li data-id="q72">
  <span class="faq-question">How do you upload and download artifacts in GitHub Actions?</span>
  <div class="answer">
    Use the <code>actions/upload-artifact</code> action to upload artifacts and <code>actions/download-artifact</code> to download them in later jobs. Example:<br>
    <code>
      - uses: actions/upload-artifact@v3<br>
        with:<br>
        &nbsp;&nbsp;name: my-artifact<br>
        &nbsp;&nbsp;path: path/to/files<br><br>
      - uses: actions/download-artifact@v3<br>
        with:<br>
        &nbsp;&nbsp;name: my-artifact
    </code>
  </div>
</li>

<li data-id="q73">
  <span class="faq-question">What is the <b>GITHUB_TOKEN</b> and how is it used?</span>
  <div class="answer">
    <code>GITHUB_TOKEN</code> is an automatically generated secret used to authenticate workflows and interact with the GitHub API. It‚Äôs used for actions like pushing commits, creating issues, or accessing the repo securely.
  </div>
</li>

<li data-id="q74">
  <span class="faq-question">How do you integrate GitHub Actions with Slack?</span>
  <div class="answer">
    Use a Slack webhook and GitHub Action like <code>8398a7/action-slack</code> to send notifications. Configure the webhook URL as a secret and add a step to post messages on workflow success or failure.
  </div>
</li>

<li data-id="q75">
  <span class="faq-question">How do you implement CI/CD for a Node.js app using GitHub Actions?</span>
  <div class="answer">
    Typical CI/CD includes steps to install dependencies, run tests, build, and deploy. Example steps:<br>
    <code>
      - run: npm install<br>
      - run: npm test<br>
      - run: npm run build<br>
      - run: npm run deploy
    </code>
  </div>
</li>

<li data-id="q76">
  <span class="faq-question">How do you set up CI/CD for a React app using GitHub Actions?</span>
  <div class="answer">
    Similar to Node.js, but includes building React production assets. Typical workflow:<br>
    <code>
      - run: npm install<br>
      - run: npm test<br>
      - run: npm run build<br>
      - run: deploy to hosting service (e.g., Firebase, Netlify)
    </code>
  </div>
</li>

<li data-id="q77">
  <span class="faq-question">How do you implement testing with Jest in GitHub Actions?</span>
  <div class="answer">
    Add a step to install dependencies and run Jest tests in your workflow:<br>
    <code>
      - uses: actions/checkout@v3<br>
      - name: Install dependencies<br>
        run: npm install<br>
      - name: Run Jest tests<br>
        run: npm test
    </code>
  </div>
</li>

<li data-id="q78">
  <span class="faq-question">How do you version your application using GitHub Actions?</span>
  <div class="answer">
    Use Git tags and automate versioning by incrementing versions and creating tags using actions like <code>actions/create-release</code> or semantic versioning tools integrated into the workflow.
  </div>
</li>

<li data-id="q79">
  <span class="faq-question">How do you implement semantic release with GitHub Actions?</span>
  <div class="answer">
    Use the <code>semantic-release</code> package in a workflow step to automatically determine version bumps, generate changelogs, and publish releases based on commit messages.
  </div>
</li>

<li data-id="q80">
  <span class="faq-question">How do you use GitHub Actions for monorepos?</span>
  <div class="answer">
    Use path filters and matrix strategies to run workflows only on affected packages. Tools like <code>nx</code> or <code>lerna</code> help manage builds and tests for monorepos efficiently.
  </div>
</li>

<li data-id="q81">
  <span class="faq-question">What are common security best practices for GitHub Actions?</span>
  <div class="answer">
    Use least privilege tokens, secrets management, restrict workflow triggers, avoid running untrusted code, enable branch protection, and keep actions updated.
  </div>
</li>
<li data-id="q82">
  <span class="faq-question">What are common CI/CD anti-patterns in GitHub Actions?</span>
  <div class="answer">
    Examples include long-running workflows, redundant jobs, poor secret management, ignoring failed tests, overcomplicated pipelines, and running everything on every commit without filtering.
  </div>
</li>

<li data-id="q83">
  <span class="faq-question">What is CI/CD?</span>
  <div class="answer">
    CI/CD stands for Continuous Integration and Continuous Delivery/Deployment. It‚Äôs a practice of automatically integrating code changes, testing them, and delivering/deploying software frequently and reliably.
  </div>
</li>

<li data-id="q84">
  <span class="faq-question">What are the main goals of CI/CD?</span>
  <div class="answer">
    To improve code quality, reduce integration issues, automate testing, accelerate delivery, and enable fast, reliable releases.
  </div>
</li>

<li data-id="q85">
  <span class="faq-question">What are the benefits of implementing CI/CD in a project?</span>
  <div class="answer">
    Faster feedback cycles, higher software quality, reduced manual errors, increased deployment frequency, and improved collaboration among teams.
  </div>
</li>

<li data-id="q86">
  <span class="faq-question">What is the difference between CI and CD?</span>
  <div class="answer">
    CI (Continuous Integration) focuses on automatically building and testing code changes. CD (Continuous Delivery/Deployment) automates releasing code to production or staging environments.
  </div>
</li>
<li data-id="q87">
  <span class="faq-question">What are the key components of a CI/CD pipeline?</span>
  <div class="answer">
    Key components include source code repository, build automation, automated testing, artifact storage, deployment automation, and monitoring.
  </div>
</li>

<li data-id="q88">
  <span class="faq-question">How do you design a CI/CD pipeline?</span>
  <div class="answer">
    Design involves defining stages (build, test, deploy), selecting tools, automating workflows, setting triggers, ensuring security, and monitoring pipeline health.
  </div>
</li>

<li data-id="q89">
  <span class="faq-question">What tools are commonly used for CI/CD?</span>
  <div class="answer">
    Common tools include GitHub Actions, Jenkins, GitLab CI, CircleCI, Travis CI, Azure DevOps, and Bitbucket Pipelines.
  </div>
</li>

<li data-id="q90">
  <span class="faq-question">Explain the role of Jenkins in CI/CD.</span>
  <div class="answer">
    Jenkins is an open-source automation server that orchestrates the CI/CD pipeline by automating builds, tests, and deployments using plugins and custom scripts.
  </div>
</li>

<li data-id="q91">
  <span class="faq-question">What are some popular alternatives to Jenkins?</span>
  <div class="answer">
    Alternatives include GitHub Actions, GitLab CI, CircleCI, Travis CI, Azure DevOps, and Bamboo.
  </div>
</li>
<li data-id="q92">
  <span class="faq-question">What is a build pipeline?</span>
  <div class="answer">
    A build pipeline automates the process of compiling source code, running tests, and producing build artifacts ready for deployment.
  </div>
</li>

<li data-id="q93">
  <span class="faq-question">What is a deployment pipeline?</span>
  <div class="answer">
    A deployment pipeline automates the steps to deploy build artifacts to various environments, such as staging or production, including approvals and testing.
  </div>
</li>

<li data-id="q94">
  <span class="faq-question">What is continuous integration?</span>
  <div class="answer">
    Continuous Integration (CI) is the practice of automatically merging and testing code changes frequently to detect errors early.
  </div>
</li>

<li data-id="q95">
  <span class="faq-question">What is continuous delivery?</span>
  <div class="answer">
    Continuous Delivery (CD) is the practice of automatically preparing code changes for release to production, with manual approval before deployment.
  </div>
</li>

<li data-id="q96">
  <span class="faq-question">What is continuous deployment?</span>
  <div class="answer">
    Continuous Deployment automates the release of every successful change directly to production without manual intervention.
  </div>
</li>
<li data-id="q97">
  <span class="faq-question">What is the difference between continuous delivery and deployment?</span>
  <div class="answer">
    Continuous Delivery prepares and validates code for release, requiring manual approval to deploy, while Continuous Deployment automatically releases every change to production without manual steps.
  </div>
</li>

<li data-id="q98">
  <span class="faq-question">What is a build artifact?</span>
  <div class="answer">
    A build artifact is the output of the build process, such as binaries, executables, or packaged files ready for deployment.
  </div>
</li>

<li data-id="q99">
  <span class="faq-question">What is an artifact repository?</span>
  <div class="answer">
    An artifact repository stores build artifacts securely, allowing teams to manage versions and retrieve them for deployments.
  </div>
</li>

<li data-id="q100">
  <span class="faq-question">How do you manage secrets in a CI/CD pipeline?</span>
  <div class="answer">
    Secrets are managed using secure storage solutions like GitHub Secrets, Vault, or environment variables, ensuring sensitive data isn‚Äôt exposed in logs or code.
  </div>
</li>

<li data-id="q101">
  <span class="faq-question">What is a webhook in the context of CI/CD?</span>
  <div class="answer">
    A webhook is an HTTP callback triggered by events (like code pushes) that notifies CI/CD systems to start pipelines automatically.
  </div>
</li>
<li data-id="q102">
  <span class="faq-question">What is pipeline as code?</span>
  <div class="answer">
    Pipeline as code means defining your CI/CD pipeline configuration as code files (often YAML) stored in your repository, enabling versioning and easier maintenance.
  </div>
</li>

<li data-id="q103">
  <span class="faq-question">What is YAML and how is it used in CI/CD?</span>
  <div class="answer">
    YAML (YAML Ain't Markup Language) is a human-readable data serialization format used to define pipeline configurations in CI/CD tools like GitHub Actions, GitLab CI, and Jenkins.
  </div>
</li>

<li data-id="q104">
  <span class="faq-question">What is GitOps?</span>
  <div class="answer">
    GitOps is a practice where Git repositories serve as the single source of truth for declarative infrastructure and application deployment, enabling automated CI/CD workflows.
  </div>
</li>

<li data-id="q105">
  <span class="faq-question">What are stages in a CI/CD pipeline?</span>
  <div class="answer">
    Stages are logical phases in a CI/CD pipeline such as build, test, deploy, and release, which organize and sequence the workflow steps.
  </div>
</li>

<li data-id="q106">
  <span class="faq-question">How do you handle rollback in CI/CD?</span>
  <div class="answer">
    Rollback is handled by deploying a previous stable build or version, automated through pipeline scripts or manually triggered when issues arise.
  </div>
</li>
<li data-id="q107">
  <span class="faq-question">What are canary deployments?</span>
  <div class="answer">
    Canary deployments gradually release new software versions to a small subset of users to monitor for issues before a full rollout.
  </div>
</li>

<li data-id="q108">
  <span class="faq-question">What are blue-green deployments?</span>
  <div class="answer">
    Blue-green deployments use two identical production environments (blue and green) to reduce downtime by switching traffic from the old to the new version instantly.
  </div>
</li>

<li data-id="q109">
  <span class="faq-question">What is A/B testing in deployment?</span>
  <div class="answer">
    A/B testing involves releasing two different versions of software to different user groups to compare performance or user experience before choosing the best.
  </div>
</li>

<li data-id="q110">
  <span class="faq-question">What is the purpose of unit testing in CI/CD?</span>
  <div class="answer">
    Unit testing verifies individual components or functions to catch bugs early and ensure code correctness during CI/CD processes.
  </div>
</li>

<li data-id="q111">
  <span class="faq-question">What is integration testing?</span>
  <div class="answer">
    Integration testing checks how different modules or services work together, validating interactions and data flow in the system.
  </div>
</li>
<li data-id="q112">
  <span class="faq-question">What is end-to-end testing?</span>
  <div class="answer">
    End-to-end testing validates the entire application flow from start to finish to ensure all integrated components work as expected.
  </div>
</li>

<li data-id="q113">
  <span class="faq-question">What is smoke testing in CI/CD?</span>
  <div class="answer">
    Smoke testing is a quick set of tests run to verify the basic functionality of a build before deeper testing is done.
  </div>
</li>

<li data-id="q114">
  <span class="faq-question">How do you automate testing in a CI/CD pipeline?</span>
  <div class="answer">
    Automate testing by integrating test scripts into pipeline stages, triggering tests on code commits, and blocking deployments on failures.
  </div>
</li>

<li data-id="q115">
  <span class="faq-question">How do you monitor a CI/CD pipeline?</span>
  <div class="answer">
    Monitoring is done using dashboards, alerts, logs, and metrics to track pipeline health, success rates, and failures in real-time.
  </div>
</li>

<li data-id="q116">
  <span class="faq-question">What is code coverage and how is it tracked?</span>
  <div class="answer">
    Code coverage measures the percentage of code exercised by tests and is tracked using tools like Jest, Istanbul, or Coveralls integrated into CI pipelines.
  </div>
</li>

<li data-id="q117">
  <span class="faq-question">How do you enforce code quality in a pipeline?</span>
  <div class="answer">
    Enforce code quality by integrating static code analysis, linting, unit tests, code reviews, and quality gates in the pipeline.
  </div>
</li>

<li data-id="q118">
  <span class="faq-question">What are some security concerns with CI/CD?</span>
  <div class="answer">
    Security concerns include secret leakage, insecure dependencies, insufficient access controls, and unverified code deployments.
  </div>
</li>

<li data-id="q119">
  <span class="faq-question">What is DevSecOps?</span>
  <div class="answer">
    DevSecOps integrates security practices into the DevOps process to automate security testing and ensure secure software delivery.
  </div>
</li>

<li data-id="q120">
  <span class="faq-question">What is a self-hosted runner?</span>
  <div class="answer">
    A self-hosted runner is a machine you manage that runs CI/CD jobs instead of using the cloud-hosted runners provided by services like GitHub.
  </div>
</li>

<li data-id="q121">
  <span class="faq-question">What is a shared runner in GitLab CI?</span>
  <div class="answer">
    A shared runner is a GitLab-managed runner that can be used by multiple projects, simplifying setup but sharing resources among users.
  </div>
</li>

<li data-id="q122">
  <span class="faq-question">How does GitHub Actions compare to Jenkins?</span>
  <div class="answer">
    GitHub Actions is cloud-native and tightly integrated with GitHub, offering simpler setup and scalable workflows, while Jenkins is highly customizable and self-hosted, with extensive plugin support.
  </div>
</li>

<li data-id="q123">
  <span class="faq-question">How do you deploy to AWS using CI/CD?</span>
  <div class="answer">
    Deploy to AWS by integrating AWS CLI or SDKs in pipelines, using services like CodeDeploy, ECS, Lambda, or CloudFormation for automated deployment.
  </div>
</li>

<li data-id="q124">
  <span class="faq-question">How do you deploy to Kubernetes using CI/CD?</span>
  <div class="answer">
    Deploy to Kubernetes by building container images, pushing them to registries, and applying manifests or Helm charts through automated pipeline steps.
  </div>
</li>

<li data-id="q125">
  <span class="faq-question">How do you deploy to Azure using CI/CD?</span>
  <div class="answer">
    Deploy to Azure using Azure DevOps pipelines or GitHub Actions with Azure CLI, ARM templates, or Terraform to provision and deploy resources.
  </div>
</li>

<li data-id="q126">
  <span class="faq-question">What is Helm and how is it used in CI/CD?</span>
  <div class="answer">
    Helm is a package manager for Kubernetes that simplifies deployment by managing charts; it‚Äôs used in CI/CD to automate Kubernetes app installations and updates.
  </div>
</li>
<li data-id="q127">
  <span class="faq-question">What is ArgoCD?</span>
  <div class="answer">
    ArgoCD is a declarative, GitOps continuous delivery tool for Kubernetes that automates the deployment of applications using Git repositories as the source of truth.
  </div>
</li>

<li data-id="q128">
  <span class="faq-question">What is Spinnaker?</span>
  <div class="answer">
    Spinnaker is an open-source, multi-cloud continuous delivery platform that helps release software changes with high velocity and confidence.
  </div>
</li>

<li data-id="q129">
  <span class="faq-question">What is CircleCI?</span>
  <div class="answer">
    CircleCI is a cloud-based CI/CD platform that automates software builds, tests, and deployments with flexible configuration and integration options.
  </div>
</li>

<li data-id="q130">
  <span class="faq-question">What is Travis CI?</span>
  <div class="answer">
    Travis CI is a hosted continuous integration service used to build and test software projects hosted on GitHub, supporting many languages and platforms.
  </div>
</li>

<li data-id="q131">
  <span class="faq-question">What is Bitbucket Pipelines?</span>
  <div class="answer">
    Bitbucket Pipelines is a CI/CD service integrated into Bitbucket that automates build, test, and deployment workflows using YAML configuration.
  </div>
</li>

<li data-id="q132">
  <span class="faq-question">What is CodePipeline (AWS)?</span>
  <div class="answer">
    AWS CodePipeline is a fully managed continuous delivery service that automates the build, test, and deploy phases of your release process.
  </div>
</li>

<li data-id="q133">
  <span class="faq-question">What is CodeBuild (AWS)?</span>
  <div class="answer">
    AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages ready for deployment.
  </div>
</li>

<li data-id="q134">
  <span class="faq-question">How do you secure credentials in GitHub Actions?</span>
  <div class="answer">
    Secure credentials by storing them in GitHub Secrets, using environment variables, and limiting access permissions to prevent exposure.
  </div>
</li>

<li data-id="q135">
  <span class="faq-question">What is the role of environment variables in CI/CD?</span>
  <div class="answer">
    Environment variables provide dynamic configuration to pipelines, allowing different settings for build, test, and deployment stages without hardcoding.
  </div>
</li>

<li data-id="q136">
  <span class="faq-question">What is caching in CI/CD pipelines?</span>
  <div class="answer">
    Caching stores dependencies or build outputs between pipeline runs to speed up build times and reduce redundant work.
  </div>
</li>
<li data-id="q137">
  <span class="faq-question">What are pipeline triggers?</span>
  <div class="answer">
    Pipeline triggers are events or conditions like code commits, pull requests, or schedules that automatically start a CI/CD pipeline.
  </div>
</li>

<li data-id="q138">
  <span class="faq-question">How do you run a pipeline manually?</span>
  <div class="answer">
    Pipelines can be run manually through CI/CD tool dashboards, CLI commands, or API calls to trigger the workflow on demand.
  </div>
</li>

<li data-id="q139">
  <span class="faq-question">What is a multi-branch pipeline?</span>
  <div class="answer">
    A multi-branch pipeline automatically creates and manages pipelines for each branch in a repository, enabling branch-specific builds and tests.
  </div>
</li>

<li data-id="q140">
  <span class="faq-question">How do you handle database migrations in CI/CD?</span>
  <div class="answer">
    Database migrations are automated in pipelines using migration tools/scripts that run during deployment to update schema safely.
  </div>
</li>

<li data-id="q141">
  <span class="faq-question">How do you version artifacts in a pipeline?</span>
  <div class="answer">
    Artifacts are versioned using semantic versioning, commit hashes, or timestamps to uniquely identify builds for traceability.
  </div>
</li>
<li data-id="q142">
  <span class="faq-question">How do you notify teams of pipeline results?</span>
  <div class="answer">
    Teams are notified via integrations with email, Slack, Microsoft Teams, or other messaging tools, often configured as post-build steps or webhooks.
  </div>
</li>

<li data-id="q143">
  <span class="faq-question">What is the difference between declarative and scripted pipelines?</span>
  <div class="answer">
    Declarative pipelines use a predefined syntax for easier readability and structure, while scripted pipelines offer more flexibility through Groovy scripting.
  </div>
</li>

<li data-id="q144">
  <span class="faq-question">How do you integrate Docker in a CI/CD pipeline?</span>
  <div class="answer">
    Docker is integrated by building container images during the pipeline, running tests inside containers, and pushing images to registries.
  </div>
</li>

<li data-id="q145">
  <span class="faq-question">How do you publish Docker images from a pipeline?</span>
  <div class="answer">
    Docker images are published by authenticating to a container registry and using Docker CLI commands like `docker push` within pipeline steps.
  </div>
</li>

<li data-id="q146">
  <span class="faq-question">How do you use Docker Compose in CI/CD?</span>
  <div class="answer">
    Docker Compose is used to define and run multi-container applications during testing or deployment stages within pipelines.
  </div>
</li>
<li data-id="q147">
  <span class="faq-question">What are runners/agents/executors in CI/CD?</span>
  <div class="answer">
    Runners, agents, or executors are machines or services that run the jobs defined in a CI/CD pipeline.
  </div>
</li>

<li data-id="q148">
  <span class="faq-question">How can you parallelize builds in CI/CD?</span>
  <div class="answer">
    Parallelization is done by splitting jobs or tests into multiple agents or runners that run simultaneously to reduce overall pipeline time.
  </div>
</li>

<li data-id="q149">
  <span class="faq-question">What are matrix builds?</span>
  <div class="answer">
    Matrix builds run the same job with multiple variations of parameters like OS, language versions, or environment variables in parallel.
  </div>
</li>
<li data-id="q150">
  <span class="faq-question">What are the best practices for writing CI/CD pipelines?</span>
  <div class="answer">
    Best practices include keeping pipelines simple and modular, using pipeline as code, automating tests, securing secrets, and enabling fast feedback loops.
  </div>
</li>

<li data-id="q151">
  <span class="faq-question">What is infrastructure as code (IaC) in CI/CD?</span>
  <div class="answer">
    IaC is managing and provisioning infrastructure through machine-readable configuration files, enabling automation and versioning in CI/CD pipelines.
  </div>
</li>
<li data-id="q152">
  <span class="faq-question">What is Terraform and how is it used in CI/CD?</span>
  <div class="answer">
    Terraform is an infrastructure as code tool that provisions and manages cloud resources declaratively, often integrated in CI/CD pipelines for automated infrastructure deployment and updates.
  </div>
</li>

<li data-id="q153">
  <span class="faq-question">What is Ansible and how is it integrated in pipelines?</span>
  <div class="answer">
    Ansible is an automation tool for configuration management and application deployment, integrated into pipelines to automate environment setup and deployments.
  </div>
</li>

<li data-id="q154">
  <span class="faq-question">What is the difference between on-prem CI/CD and cloud CI/CD?</span>
  <div class="answer">
    On-prem CI/CD is hosted on local infrastructure offering full control but requiring maintenance, while cloud CI/CD is hosted by providers offering scalability, easier setup, and managed services.
  </div>
</li>

<li data-id="q155">
  <span class="faq-question">How do you test microservices with CI/CD?</span>
  <div class="answer">
    Testing microservices involves unit, integration, and contract tests, often orchestrated in pipelines using containerization and service virtualization for isolated testing.
  </div>
</li>

<li data-id="q156">
  <span class="faq-question">How do you manage monorepos in CI/CD?</span>
  <div class="answer">
    Monorepos are managed with selective builds and tests using tools that detect changed projects, optimizing pipeline efficiency and reducing unnecessary runs.
  </div>
</li>

<li data-id="q157">
  <span class="faq-question">How does feature flagging help in CD?</span>
  <div class="answer">
    Feature flagging allows teams to enable or disable features dynamically without deploying new code, enabling safer and controlled continuous delivery.
  </div>
</li>

<li data-id="q158">
  <span class="faq-question">What is progressive delivery?</span>
  <div class="answer">
    Progressive delivery is an approach that gradually rolls out changes to subsets of users, reducing risk and enabling fast feedback during deployments.
  </div>
</li>

<li data-id="q159">
  <span class="faq-question">What is a job in CI/CD terminology?</span>
  <div class="answer">
    A job is a set of steps executed sequentially in a pipeline, usually representing a stage like build, test, or deploy.
  </div>
</li>

<li data-id="q160">
  <span class="faq-question">What is a workflow in GitHub Actions?</span>
  <div class="answer">
    A workflow is an automated process defined in a YAML file that contains one or more jobs triggered by specific events.
  </div>
</li>

<li data-id="q161">
  <span class="faq-question">What is a pipeline template?</span>
  <div class="answer">
    A pipeline template is a reusable configuration blueprint that defines common pipeline stages or jobs, promoting consistency and reuse.
  </div>
</li>


<li data-id="q162">
  <span class="faq-question">How do you use artifacts between pipeline stages?</span>
  <div class="answer">
    Artifacts are saved after one stage and downloaded in subsequent stages to share build outputs, test results, or deployment packages.
  </div>
</li>

<li data-id="q163">
  <span class="faq-question">How do you implement approval gates in CI/CD?</span>
  <div class="answer">
    Approval gates require manual intervention or automated policies before proceeding to the next pipeline stage, ensuring checks and compliance.
  </div>
</li>

<li data-id="q164">
  <span class="faq-question">What is pipeline orchestration?</span>
  <div class="answer">
    Pipeline orchestration manages the execution order, dependencies, and resource allocation of multiple jobs or pipelines.
  </div>
</li>

<li data-id="q165">
  <span class="faq-question">What are common CI/CD anti-patterns?</span>
  <div class="answer">
    Anti-patterns include long-running pipelines, manual approvals delaying automation, hardcoded secrets, and ignoring failure handling.
  </div>
</li>

<li data-id="q166">
  <span class="faq-question">What is the role of code review in CI/CD?</span>
  <div class="answer">
    Code review ensures code quality, catches bugs early, and enforces standards before changes are integrated and deployed.
  </div>
</li>
<li data-id="q167">
  <span class="faq-question">What is the difference between push and pull-based deployment?</span>
  <div class="answer">
    Push-based deployment initiates deployments from a central system pushing changes to targets, while pull-based deployment lets targets pull changes themselves, often improving security and scalability.
  </div>
</li>

<li data-id="q168">
  <span class="faq-question">What is drift detection in CI/CD?</span>
  <div class="answer">
    Drift detection identifies differences between the desired infrastructure state and the actual deployed state, helping maintain consistency.
  </div>
</li>

<li data-id="q169">
  <span class="faq-question">How do you test infrastructure changes with CI/CD?</span>
  <div class="answer">
    Infrastructure changes are tested using automated validation tools, infrastructure tests, and deploying to staging environments before production.
  </div>
</li>

<li data-id="q170">
  <span class="faq-question">How can you use static code analysis tools in a pipeline?</span>
  <div class="answer">
    Static code analysis tools are integrated as pipeline steps to analyze code quality, security, and style before merging changes.
  </div>
</li>

<li data-id="q171">
  <span class="faq-question">What is SonarQube and how is it used in CI/CD?</span>
  <div class="answer">
    SonarQube is a platform for continuous inspection of code quality that integrates with CI/CD pipelines to provide automated code reviews and track technical debt.
  </div>
</li>

<li data-id="q172">
  <span class="faq-question">What is the importance of feedback loops in CI/CD?</span>
  <div class="answer">
    Fast feedback loops help teams detect and fix issues quickly, improving software quality and reducing time to market.
  </div>
</li>

<li data-id="q173">
  <span class="faq-question">How do you track pipeline history?</span>
  <div class="answer">
    Pipeline history is tracked via CI/CD tools that log execution details, statuses, logs, and artifacts for auditing and troubleshooting.
  </div>
</li>

<li data-id="q174">
  <span class="faq-question">How do you configure branch-based deployments?</span>
  <div class="answer">
    Branch-based deployments are configured by specifying branch filters in pipeline triggers, allowing different environments or behaviors per branch.
  </div>
</li>

<li data-id="q175">
  <span class="faq-question">How do you handle dependency management in CI/CD?</span>
  <div class="answer">
    Dependency management is handled by using package managers, caching dependencies, and locking versions to ensure reproducible builds.
  </div>
</li>

<li data-id="q176">
  <span class="faq-question">How do you test frontend and backend apps together in CI/CD?</span>
  <div class="answer">
    Integration tests and end-to-end tests run in pipelines using staging environments or mock services to validate frontend-backend interactions.
  </div>
</li>

<li data-id="q177">
  <span class="faq-question">What‚Äôs the role of a package manager in CI/CD?</span>
  <div class="answer">
    A package manager handles dependency installation and versioning, ensuring consistent and reproducible builds across pipeline runs.
  </div>
</li>

<li data-id="q178">
  <span class="faq-question">How do you run background services for tests in CI/CD?</span>
  <div class="answer">
    Background services are run using containers, service mocks, or dedicated test environments initialized before test execution in the pipeline.
  </div>
</li>

<li data-id="q179">
  <span class="faq-question">How do you debug a failed pipeline?</span>
  <div class="answer">
    Debugging involves examining logs, re-running failed steps with verbose output, and isolating failing tests or configuration errors.
  </div>
</li>

<li data-id="q180">
  <span class="faq-question">How do you make pipelines scalable?</span>
  <div class="answer">
    Scalability is achieved through parallel execution, distributed runners, caching, and modular pipeline design.
  </div>
</li>

<li data-id="q181">
  <span class="faq-question">How do you ensure idempotency in deployments?</span>
  <div class="answer">
    Idempotency ensures deployments can be repeated without side effects by using declarative configurations and avoiding mutable state changes.
  </div>
</li>

<li data-id="q182">
  <span class="faq-question">How do you manage pipeline drift?</span>
  <div class="answer">
    Pipeline drift is managed by regularly auditing pipeline configurations, automating updates, and enforcing version control on pipeline code.
  </div>
</li>

  

<li data-id="q182" class="yellow">
  <span class="faq-question">AWS API Gateway</span>
<div class="answer">
  <ol>
    <li>What is AWS API Gateway?</li>
    <li>What are the main features of API Gateway?</li>
    <li>What types of APIs can you create with API Gateway?</li>
    <li>What is the difference between REST API and HTTP API in API Gateway?</li>
    <li>When should you use WebSocket API in API Gateway?</li>
    <li>How does API Gateway integrate with AWS Lambda?</li>
    <li>What is a proxy integration in API Gateway?</li>
    <li>What is a non-proxy integration?</li>
    <li>What is a VPC link in API Gateway?</li>
    <li>How do you enable CORS in API Gateway?</li>
    <li>What are stages in API Gateway?</li>
    <li>How can you deploy an API in API Gateway?</li>
    <li>What is a usage plan in API Gateway?</li>
    <li>What are API keys and how are they used?</li>
    <li>How can you throttle requests in API Gateway?</li>
    <li>How does caching work in API Gateway?</li>
    <li>What is the role of IAM in securing APIs?</li>
    <li>How can you secure API Gateway using Lambda authorizers?</li>
    <li>What is a custom domain name in API Gateway?</li>
    <li>How do you configure custom domain mappings?</li>
    <li>What is the difference between a REST API and an HTTP API in terms of performance?</li>
    <li>What are integration request and integration response?</li>
    <li>How does API Gateway handle binary data?</li>
    <li>How do you monitor APIs with CloudWatch?</li>
    <li>How can you enable logging in API Gateway?</li>
    <li>What is mutual TLS (mTLS) in API Gateway?</li>
    <li>What is a request validator?</li>
    <li>How does API Gateway handle request transformations?</li>
    <li>How does response mapping work?</li>
    <li>What is method request and method response?</li>
    <li>What limits exist in AWS API Gateway?</li>
    <li>How do you handle versioning of APIs?</li>
    <li>What is the difference between regional, edge-optimized, and private APIs?</li>
    <li>Can API Gateway work with private VPC endpoints?</li>
    <li>How do you use API Gateway with AWS WAF?</li>
    <li>How can you test your API Gateway endpoints?</li>
    <li>What is a mock integration?</li>
    <li>What is the role of Swagger/OpenAPI in API Gateway?</li>
    <li>Can you import/export API definitions?</li>
    <li>What are authorizer types supported by API Gateway?</li>
    <li>How does token-based authentication work with JWT in API Gateway?</li>
    <li>How can you migrate from REST API to HTTP API?</li>
    <li>What is throttling vs quota in usage plans?</li>
    <li>How can you prevent abuse of public APIs?</li>
    <li>What are some best practices for designing scalable APIs with API Gateway?</li>
    <li>How does API Gateway support multi-region deployments?</li>
    <li>What is the lifecycle of an API Gateway request?</li>
    <li>Can you integrate API Gateway with Step Functions?</li>
    <li>How do you roll back a failed deployment in API Gateway?</li>
    <li>What is the role of stage variables?</li>
  </ol>
</div>
</li>


  <li data-id="q182">
    <span class="faq-question">What is AWS API Gateway?</span>
    <div class="answer">
      AWS API Gateway is a fully managed service that allows developers to create, publish, maintain, monitor, and secure RESTful, HTTP, and WebSocket APIs at any scale. It acts as a front door for applications to access data, business logic, or functionality from backend services like AWS Lambda, EC2, or any web application.
    </div>
  </li>

  <li data-id="q183">
    <span class="faq-question">What are the main features of API Gateway?</span>
    <div class="answer">
      Key features include:
      <ul>
        <li>Support for REST, HTTP, and WebSocket APIs</li>
        <li>Authorization using IAM, Lambda Authorizers, and Cognito</li>
        <li>Throttling and rate limiting</li>
        <li>Request/response transformation</li>
        <li>Custom domain support</li>
        <li>Caching and usage plans</li>
        <li>Built-in monitoring with CloudWatch</li>
      </ul>
    </div>
  </li>

  <li data-id="q184">
    <span class="faq-question">What types of APIs can you create with API Gateway?</span>
    <div class="answer">
      API Gateway supports three types of APIs:
      <ul>
        <li><strong>REST API:</strong> Full-featured, best for complex authorization and transformation needs.</li>
        <li><strong>HTTP API:</strong> Lightweight, faster, and cheaper; ideal for most use cases.</li>
        <li><strong>WebSocket API:</strong> Used for real-time communication like chat apps or live notifications.</li>
      </ul>
    </div>
  </li>

  <li data-id="q185">
    <span class="faq-question">What is the difference between REST API and HTTP API in API Gateway?</span>
    <div class="answer">
      <table border="1" cellpadding="6">
        <thead>
          <tr><th>Feature</th><th>REST API</th><th>HTTP API</th></tr>
        </thead>
        <tbody>
          <tr><td>Performance</td><td>Higher latency</td><td>Lower latency</td></tr>
          <tr><td>Price</td><td>More expensive</td><td>Cheaper</td></tr>
          <tr><td>Authorization</td><td>IAM, Cognito, Lambda</td><td>IAM, JWT (Cognito or OpenID)</td></tr>
          <tr><td>Transformation</td><td>Request/response mapping supported</td><td>No built-in transformations</td></tr>
          <tr><td>Use Case</td><td>Advanced features needed</td><td>Simple, fast APIs</td></tr>
        </tbody>
      </table>
    </div>
  </li>

  <li data-id="q186">
    <span class="faq-question">When should you use WebSocket API in API Gateway?</span>
    <div class="answer">
      Use WebSocket API when your application requires real-time, two-way communication between the client and server. Examples include:
      <ul>
        <li>Chat applications</li>
        <li>Live notifications</li>
        <li>Gaming servers</li>
        <li>Live collaboration tools</li>
      </ul>
    </div>
  </li>

  <li data-id="q187">
    <span class="faq-question">How does API Gateway integrate with AWS Lambda?</span>
    <div class="answer">
      API Gateway acts as a trigger for AWS Lambda. When a client makes an HTTP request to an API Gateway endpoint:
      <ol>
        <li>API Gateway receives the request.</li>
        <li>It validates, authorizes, and transforms the request if configured.</li>
        <li>The request is forwarded to the configured Lambda function.</li>
        <li>The Lambda function processes the logic and returns a response.</li>
        <li>API Gateway formats the response and sends it back to the client.</li>
      </ol>
    </div>
  </li>
  <li data-id="q188">
    <span class="faq-question">What is a proxy integration in API Gateway?</span>
    <div class="answer">
      A proxy integration allows API Gateway to pass the entire request to the backend service (like AWS Lambda or HTTP endpoint) without modifying it. The backend is responsible for interpreting the request and returning a response in a format API Gateway can pass back to the client. This is common in Lambda proxy integration where API Gateway forwards request data as-is to the Lambda function.
    </div>
  </li>

  <li data-id="q189">
    <span class="faq-question">What is a non-proxy integration?</span>
    <div class="answer">
      A non-proxy integration enables you to configure how the request is mapped to the backend and how the response is transformed back to the client. You can define mapping templates, headers, status codes, and query parameters manually. This approach is useful when you want more control over the interaction between API Gateway and your backend.
    </div>
  </li>

  <li data-id="q190">
    <span class="faq-question">What is a VPC link in API Gateway?</span>
    <div class="answer">
      A VPC Link in API Gateway allows your API to connect privately to AWS services hosted in your Amazon VPC, such as private ALBs, NLBs, or EC2 instances. It establishes a secure connection without exposing services to the public internet.
    </div>
  </li>

  <li data-id="q191">
    <span class="faq-question">How do you enable CORS in API Gateway?</span>
    <div class="answer">
      To enable CORS (Cross-Origin Resource Sharing):
      <ol>
        <li>Go to your API Gateway method (e.g., GET, POST).</li>
        <li>Add a method response with the header <code>Access-Control-Allow-Origin</code>.</li>
        <li>Set the integration response to include the CORS headers.</li>
        <li>Optionally, create an <code>OPTIONS</code> method to handle preflight requests.</li>
        <li>Deploy the API for changes to take effect.</li>
      </ol>
    </div>
  </li>

  <li data-id="q192">
    <span class="faq-question">What are stages in API Gateway?</span>
    <div class="answer">
      Stages in API Gateway represent different environments (like <code>dev</code>, <code>test</code>, <code>prod</code>) for a deployed API. Each stage can have its own configuration, logging settings, throttling limits, and variables. This helps you manage versions and environments effectively.
    </div>
  </li>

  <li data-id="q193">
    <span class="faq-question">How can you deploy an API in API Gateway?</span>
    <div class="answer">
      To deploy an API in API Gateway:
      <ol>
        <li>Create or update your API definition.</li>
        <li>Choose or create a stage (e.g., <code>dev</code>).</li>
        <li>Click ‚ÄúDeploy API‚Äù from the API Gateway console or use the AWS CLI.</li>
        <li>Once deployed, API Gateway assigns an endpoint URL for the selected stage.</li>
      </ol>
    </div>
  </li>
    <li data-id="q194">
      <span class="faq-question">What is a usage plan in API Gateway?</span>
      <div class="answer">
        A usage plan in API Gateway defines who can access one or more deployed API stages and how much and how fast they can access them. It allows you to throttle and quota usage per customer via API keys, enabling fine-grained control over API consumption.
      </div>
    </li>
  
    <li data-id="q195">
      <span class="faq-question">What are API keys and how are they used?</span>
      <div class="answer">
        API keys are alphanumeric strings that identify the calling project or application. In API Gateway, API keys are used in combination with usage plans to:
        <ul>
          <li>Authenticate client requests</li>
          <li>Track usage and apply throttling/quotas</li>
          <li>Differentiate between different consumers</li>
        </ul>
        Clients pass the API key in the <code>x-api-key</code> header when making requests.
      </div>
    </li>
  
    <li data-id="q196">
      <span class="faq-question">How can you throttle requests in API Gateway?</span>
      <div class="answer">
        API Gateway provides throttling at two levels:
        <ul>
          <li><strong>Account-level throttling</strong>: Default settings that apply to all APIs within an account.</li>
          <li><strong>Usage plan-level throttling</strong>: Custom rate (requests per second) and burst limits (maximum concurrent requests) applied to specific API keys.</li>
        </ul>
        Throttling helps protect backend services from being overwhelmed by high traffic.
      </div>
    </li>
  
    <li data-id="q197">
      <span class="faq-question">How does caching work in API Gateway?</span>
      <div class="answer">
        API Gateway supports response caching at the stage level. When enabled:
        <ul>
          <li>Responses are cached for a specified time (TTL - Time to Live).</li>
          <li>Cached responses are returned for repeated requests with the same parameters.</li>
          <li>Caching reduces backend load and improves performance.</li>
        </ul>
        You can enable caching per method and configure cache keys (e.g., headers, query strings).
      </div>
    </li>
  
    <li data-id="q198">
      <span class="faq-question">What is the role of IAM in securing APIs?</span>
      <div class="answer">
        AWS Identity and Access Management (IAM) helps secure APIs by:
        <ul>
          <li>Controlling which IAM users, groups, or roles can call specific API Gateway methods.</li>
          <li>Allowing signed requests using AWS Signature Version 4.</li>
          <li>Integrating with policies to define granular access control based on context (e.g., source IP, user agent).</li>
        </ul>
        IAM-based auth is ideal for internal APIs or APIs accessed by other AWS services.
      </div>
    </li>
  
    <li data-id="q199">
      <span class="faq-question">How can you secure API Gateway using Lambda authorizers?</span>
      <div class="answer">
        Lambda authorizers (also called custom authorizers) are Lambda functions used to control access to your APIs. When a request is made:
        <ol>
          <li>API Gateway invokes the Lambda authorizer before calling the backend.</li>
          <li>The function evaluates a token (e.g., JWT, OAuth2) and returns an IAM policy.</li>
          <li>API Gateway allows or denies the request based on the returned policy.</li>
        </ol>
        This allows you to implement custom authentication and authorization logic.
      </div>
    </li>
  

      <li data-id="q200">
        <span class="faq-question">What is a custom domain name in API Gateway?</span>
        <div class="answer">
          A custom domain name in API Gateway allows you to provide a user-friendly URL (e.g., <code>https://api.yourdomain.com</code>) instead of using the default AWS endpoint. You can map custom domains to different stages or routes of your APIs for branding and better user experience.
        </div>
      </li>
    
      <li data-id="q201">
        <span class="faq-question">How do you configure custom domain mappings?</span>
        <div class="answer">
          To configure custom domain mappings:
          <ol>
            <li>Purchase and configure your domain using Route 53 or another DNS provider.</li>
            <li>Create a custom domain in API Gateway and associate it with an ACM certificate.</li>
            <li>Set up base path mappings to map the domain to specific API stages or routes.</li>
            <li>Create a CNAME or A record in your DNS to point to the API Gateway domain.</li>
          </ol>
        </div>
      </li>
    
      <li data-id="q202">
        <span class="faq-question">What is the difference between a REST API and an HTTP API in terms of performance?</span>
        <div class="answer">
          <ul>
            <li><strong>HTTP API</strong> has better performance with lower latency and is more cost-effective.</li>
            <li><strong>REST API</strong> supports more advanced features like request/response mapping, API keys, usage plans, and fine-grained authorization.</li>
          </ul>
          Use HTTP API for lightweight services and REST API when you need advanced capabilities.
        </div>
      </li>
    
      <li data-id="q203">
        <span class="faq-question">What are integration request and integration response?</span>
        <div class="answer">
          <ul>
            <li><strong>Integration Request:</strong> Transforms the client request before sending it to the backend. You can map headers, query strings, and body data.</li>
            <li><strong>Integration Response:</strong> Transforms the backend response before returning it to the client. You can set headers, status codes, and body templates.</li>
          </ul>
          These mappings are available in non-proxy integrations.
        </div>
      </li>
    
      <li data-id="q204">
        <span class="faq-question">How does API Gateway handle binary data?</span>
        <div class="answer">
          API Gateway can handle binary data by:
          <ul>
            <li>Adding supported <code>binaryMediaTypes</code> (like <code>image/png</code>) in the settings.</li>
            <li>Base64-encoding the binary content in the response from Lambda or integration.</li>
            <li>Decoding the base64-encoded data on the client side.</li>
          </ul>
          This ensures safe transmission of binary data over HTTP.
        </div>
      </li>
    
      <li data-id="q205">
        <span class="faq-question">How do you monitor APIs with CloudWatch?</span>
        <div class="answer">
          API Gateway integrates with Amazon CloudWatch to provide:
          <ul>
            <li><strong>Execution logs</strong> for debugging and tracing requests</li>
            <li><strong>Metrics</strong> like 4XX/5XX errors, latency, and request count</li>
            <li><strong>Alarms</strong> to notify you of abnormal behavior</li>
          </ul>
          You can enable logging at the stage level and customize log groups and formats.
        </div>
      </li>

      <li data-id="q206">
        <span class="faq-question">How can you enable logging in API Gateway?</span>
        <div class="answer">
          To enable logging in API Gateway:
          <ol>
            <li>Go to your API stage settings in the console.</li>
            <li>Enable CloudWatch Logs under the ‚ÄúLogs/Tracing‚Äù section.</li>
            <li>Choose a log level (INFO, ERROR, etc.).</li>
            <li>Grant the API Gateway execution role permission to write to CloudWatch.</li>
            <li>Deploy your stage for changes to take effect.</li>
          </ol>
          Logs will now be visible in the specified CloudWatch Log Group.
        </div>
      </li>
    
      <li data-id="q207">
        <span class="faq-question">What is mutual TLS (mTLS) in API Gateway?</span>
        <div class="answer">
          Mutual TLS (mTLS) is a security enhancement where both the client and server authenticate each other using X.509 certificates. In API Gateway:
          <ul>
            <li>Clients must present a trusted certificate when calling the API.</li>
            <li>API Gateway verifies the client certificate against a configured truststore.</li>
            <li>It provides an additional layer of security beyond token-based or IAM authentication.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q208">
        <span class="faq-question">What is a request validator?</span>
        <div class="answer">
          A request validator in API Gateway validates incoming requests based on configured criteria:
          <ul>
            <li>Required query string parameters</li>
            <li>Required headers</li>
            <li>Request body (JSON schema)</li>
          </ul>
          You can choose to validate only parameters, only the body, or both, reducing load on backends by filtering bad requests early.
        </div>
      </li>
    
      <li data-id="q209">
        <span class="faq-question">How does API Gateway handle request transformations?</span>
        <div class="answer">
          API Gateway can transform incoming requests using mapping templates (Velocity Template Language - VTL) before forwarding them to the backend. This allows:
          <ul>
            <li>Extracting and reshaping headers, query strings, and body</li>
            <li>Inserting static values or conditionals</li>
            <li>Combining inputs into new formats (e.g., JSON ‚Üí XML)</li>
          </ul>
          This is available in non-proxy REST integrations.
        </div>
      </li>
    
      <li data-id="q210">
        <span class="faq-question">How does response mapping work?</span>
        <div class="answer">
          Response mapping in API Gateway allows transforming backend responses into desired formats before sending them to the client. This includes:
          <ul>
            <li>Changing HTTP status codes based on backend output</li>
            <li>Mapping or modifying headers</li>
            <li>Restructuring the response body using mapping templates</li>
          </ul>
          Useful when the backend format doesn't match client expectations.
        </div>
      </li>
    
      <li data-id="q211">
        <span class="faq-question">What is method request and method response?</span>
        <div class="answer">
          <ul>
            <li><strong>Method Request:</strong> Defines how API Gateway receives a request from the client, including query parameters, headers, and authorization settings.</li>
            <li><strong>Method Response:</strong> Specifies the structure of the response returned to the client, including status codes, headers, and models.</li>
          </ul>
          These configurations are used in conjunction with integration settings to process and validate API traffic.
        </div>
      </li>

      <li data-id="q212">
        <span class="faq-question">What limits exist in AWS API Gateway?</span>
        <div class="answer">
          AWS API Gateway has several soft and hard limits:
          <ul>
            <li>Max 10,000 requests per second (soft limit, can be increased).</li>
            <li>Payload size: 10 MB for request/response in REST APIs, 6 MB in HTTP APIs.</li>
            <li>Max 30 seconds timeout for integrations like Lambda.</li>
            <li>Rate limiting and burst throttling per account or usage plan.</li>
            <li>Concurrent requests per region and account.</li>
          </ul>
          These limits can be increased by submitting a request to AWS Support.
        </div>
      </li>
    
      <li data-id="q213">
        <span class="faq-question">How do you handle versioning of APIs?</span>
        <div class="answer">
          API versioning in API Gateway can be managed by:
          <ul>
            <li>Creating different stages (e.g., <code>/v1</code>, <code>/v2</code>)</li>
            <li>Using base path mappings with custom domains (<code>api.example.com/v1</code>)</li>
            <li>Deploying separate APIs for different versions</li>
            <li>Including version info in headers (less common)</li>
          </ul>
          Choose a strategy based on your application's compatibility needs and client adoption.
        </div>
      </li>
    
      <li data-id="q214">
        <span class="faq-question">What is the difference between regional, edge-optimized, and private APIs?</span>
        <div class="answer">
          <ul>
            <li><strong>Regional APIs:</strong> Accessible only in a specific AWS region. Ideal for internal or regional applications.</li>
            <li><strong>Edge-Optimized APIs:</strong> Deployed globally using CloudFront. Best for public APIs accessed from various locations.</li>
            <li><strong>Private APIs:</strong> Accessible only within your VPC using interface VPC endpoints. Used for secure internal services.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q215">
        <span class="faq-question">Can API Gateway work with private VPC endpoints?</span>
        <div class="answer">
          Yes, API Gateway can integrate with resources inside a VPC using:
          <ul>
            <li><strong>VPC Link</strong> for REST APIs to connect to Network Load Balancers (NLB) in the VPC.</li>
            <li><strong>Private integrations</strong> with PrivateLink for HTTP APIs and private REST APIs.</li>
          </ul>
          This allows secure and scalable access to backend services not exposed to the public internet.
        </div>
      </li>
    
      <li data-id="q216">
        <span class="faq-question">How do you use API Gateway with AWS WAF?</span>
        <div class="answer">
          AWS WAF (Web Application Firewall) can be associated with:
          <ul>
            <li>Edge-optimized APIs (via associated CloudFront distributions)</li>
            <li>Regional APIs directly</li>
          </ul>
          WAF protects your APIs from common threats (SQL injection, XSS, IP blocking, rate limiting) by defining rules that inspect incoming requests.
        </div>
      </li>
    
      <li data-id="q217">
        <span class="faq-question">How can you test your API Gateway endpoints?</span>
        <div class="answer">
          You can test API Gateway endpoints by:
          <ul>
            <li>Using the ‚ÄúTest‚Äù feature in the API Gateway console</li>
            <li>Sending HTTP requests using <code>curl</code>, Postman, or similar tools</li>
            <li>Calling the endpoint from Lambda test events (if Lambda is the backend)</li>
            <li>Using automated test scripts and CI/CD pipelines</li>
          </ul>
          Logging and CloudWatch metrics can help diagnose and validate test results.
        </div>
      </li>

      <li data-id="q218">
        <span class="faq-question">What is a mock integration?</span>
        <div class="answer">
          A mock integration in API Gateway allows you to return a response to the client without sending a request to a backend. It's useful for:
          <ul>
            <li>Testing API setup without deploying backend services</li>
            <li>Creating stub responses for frontend development</li>
            <li>Simulating error or success responses</li>
          </ul>
          You define response templates and status codes within API Gateway itself.
        </div>
      </li>
    
      <li data-id="q219">
        <span class="faq-question">What is the role of Swagger/OpenAPI in API Gateway?</span>
        <div class="answer">
          Swagger/OpenAPI specifications allow you to define your API contract using a standard format. In API Gateway, they are used to:
          <ul>
            <li>Import APIs via the console or CLI</li>
            <li>Document existing APIs</li>
            <li>Generate SDKs and test tools</li>
          </ul>
          OpenAPI v2 and v3 are supported, and can be integrated with CI/CD pipelines.
        </div>
      </li>
    
      <li data-id="q220">
        <span class="faq-question">Can you import/export API definitions?</span>
        <div class="answer">
          Yes, API Gateway supports both import and export of API definitions:
          <ul>
            <li><strong>Import:</strong> Upload OpenAPI definitions to create or update an API.</li>
            <li><strong>Export:</strong> Download the API structure in Swagger/OpenAPI format for documentation or sharing.</li>
            <li>Supported via console, AWS CLI, SDKs, and Infrastructure as Code tools like SAM and CloudFormation.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q221">
        <span class="faq-question">What are authorizer types supported by API Gateway?</span>
        <div class="answer">
          API Gateway supports the following authorizer types:
          <ul>
            <li><strong>Lambda Authorizers (Custom):</strong> Use a Lambda function to validate tokens or headers.</li>
            <li><strong>IAM Authorization:</strong> Controls access using AWS IAM roles and policies.</li>
            <li><strong>Cognito User Pools:</strong> Provides authentication and user management with JWT-based access tokens.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q222">
        <span class="faq-question">How does token-based authentication work with JWT in API Gateway?</span>
        <div class="answer">
          Token-based authentication using JWT works by:
          <ul>
            <li>Client sends a JWT in the Authorization header.</li>
            <li>API Gateway validates the token using Cognito or a custom Lambda authorizer.</li>
            <li>If the token is valid, the request is forwarded to the backend; otherwise, a 401 Unauthorized response is returned.</li>
            <li>JWTs typically contain claims (e.g., user ID, role) used for access control.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q223">
        <span class="faq-question">How can you migrate from REST API to HTTP API?</span>
        <div class="answer">
          To migrate from REST API to HTTP API in API Gateway:
          <ol>
            <li>Export your existing REST API definition as OpenAPI.</li>
            <li>Create a new HTTP API and import the OpenAPI definition.</li>
            <li>Update your integrations, as some REST features (e.g., request/response mapping) may differ.</li>
            <li>Test and deploy the new HTTP API.</li>
            <li>Update DNS/custom domains and clients if needed.</li>
          </ol>
          Note: HTTP APIs offer lower latency and cost, but not all REST features are supported.
        </div>
      </li>

      <li data-id="q224">
        <span class="faq-question">What is throttling vs quota in usage plans?</span>
        <div class="answer">
          <ul>
            <li><strong>Throttling:</strong> Limits the rate of requests (requests per second) to prevent spikes. Includes:
              <ul>
                <li><strong>Rate limit</strong> (e.g., 100 requests/second)</li>
                <li><strong>Burst limit</strong> (e.g., temporary spikes up to 200)</li>
              </ul>
            </li>
            <li><strong>Quota:</strong> Defines the total number of allowed requests over a time period (e.g., 10,000 requests per month). It's a hard cap.</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q225">
        <span class="faq-question">How can you prevent abuse of public APIs?</span>
        <div class="answer">
          <ul>
            <li>Use <strong>API keys</strong> with usage plans (throttling and quotas)</li>
            <li>Enable <strong>authentication and authorization</strong> (Cognito, IAM, Lambda Authorizers)</li>
            <li>Use <strong>AWS WAF</strong> to block malicious traffic (IP block lists, rate limits)</li>
            <li>Enable <strong>CloudWatch logging</strong> to monitor and analyze traffic patterns</li>
            <li>Apply <strong>CORS policies</strong> properly to control who can access your API</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q226">
        <span class="faq-question">What are some best practices for designing scalable APIs with API Gateway?</span>
        <div class="answer">
          <ul>
            <li>Use <strong>HTTP APIs</strong> for lightweight, low-latency workloads</li>
            <li>Leverage <strong>Lambda and Step Functions</strong> for serverless backends</li>
            <li>Apply <strong>usage plans and throttling</strong> to manage load</li>
            <li>Use <strong>VPC Links</strong> for secure private integrations</li>
            <li>Enable <strong>caching</strong> where possible</li>
            <li>Use <strong>CloudFormation</strong> or <strong>CDK</strong> for infrastructure automation</li>
            <li>Design with <strong>idempotent endpoints</strong> for safe retries</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q227">
        <span class="faq-question">How does API Gateway support multi-region deployments?</span>
        <div class="answer">
          You can deploy the same API in multiple regions to improve latency and availability:
          <ul>
            <li>Deploy identical stacks in different regions using <strong>Infrastructure as Code</strong></li>
            <li>Use <strong>Route 53 latency-based routing</strong> to route requests to the nearest region</li>
            <li>Ensure <strong>data synchronization</strong> across regions if needed</li>
            <li>Handle region failover scenarios using health checks and monitoring</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q228">
        <span class="faq-question">What is the lifecycle of an API Gateway request?</span>
        <div class="answer">
          The lifecycle of a request in API Gateway includes:
          <ol>
            <li>Client sends request to API Gateway endpoint</li>
            <li>Stage and resource route match is resolved</li>
            <li>Request passes through <strong>authorizers</strong> (IAM/Cognito/Lambda)</li>
            <li>Request validation and transformation occurs</li>
            <li>Request sent to backend (Lambda, HTTP, VPC link, etc.)</li>
            <li>Integration response is mapped</li>
            <li>Method response is generated and returned to the client</li>
            <li>Logs and metrics are captured in CloudWatch</li>
          </ol>
        </div>
      </li>
    
      <li data-id="q229">
        <span class="faq-question">Can you integrate API Gateway with Step Functions?</span>
        <div class="answer">
          Yes, API Gateway can invoke AWS Step Functions directly via:
          <ul>
            <li><strong>AWS Service integration:</strong> Use the <code>StartExecution</code> action</li>
            <li><strong>HTTP integration:</strong> If the Step Function has an HTTP endpoint (via Lambda or API Gateway)</li>
          </ul>
          This is useful for orchestrating workflows (e.g., approvals, data processing) behind API calls.
        </div>
      </li>
    
      <li data-id="q230">
        <span class="faq-question">How do you roll back a failed deployment in API Gateway?</span>
        <div class="answer">
          You can roll back by:
          <ul>
            <li>Re-deploying a previous stage deployment</li>
            <li>Using <strong>stage variables</strong> to switch versions dynamically</li>
            <li>Automating deployments using <strong>CI/CD tools</strong> that maintain versions</li>
            <li>Exporting previous OpenAPI definitions for restore</li>
          </ul>
        </div>
      </li>
    
      <li data-id="q231">
        <span class="faq-question">What is the role of stage variables?</span>
        <div class="answer">
          Stage variables are key-value pairs that you define at the stage level in API Gateway. They are used to:
          <ul>
            <li>Reference different backend endpoints (e.g., dev vs prod)</li>
            <li>Pass dynamic configuration to Lambda or HTTP integrations</li>
            <li>Control deployment behavior without changing the code</li>
            <li>Work with Lambda aliases for versioning</li>
          </ul>
        </div>
      </li>
                


  








  
      <li data-id="q231" class="yellow"><span class="faq-question">AWS S3 Bucket</span></li>



      <li data-id="q231">
  <span class="faq-question">What is Amazon S3?</span>
  <div class="answer">
        Amazon S3 (Simple Storage Service) is an object storage service that offers industry-leading scalability, availability, security, and performance.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an S3 bucket?</span>
  <div class="answer">
        An S3 bucket is a container for storing objects (files, data) in Amazon S3.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are the naming rules for S3 buckets?</span>
  <div class="answer">
        Names must be globally unique, contain only lowercase letters, numbers, hyphens, and periods, and be between 3 and 63 characters.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an S3 object?</span>
  <div class="answer">
        An object is a file and its metadata stored in a bucket.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are the storage classes in Amazon S3?</span>
  <div class="answer">
        - S3 Standard<br>
        - S3 Intelligent-Tiering<br>
        - S3 Standard-IA<br>
        - S3 One Zone-IA<br>
        - S3 Glacier<br>
        - S3 Glacier Deep Archive
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How is data secured in S3?</span>
  <div class="answer">
        Using encryption at rest (SSE-S3, SSE-KMS, SSE-C) and encryption in transit (SSL/TLS).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is versioning in S3?</span>
  <div class="answer">
        Versioning allows you to preserve, retrieve, and restore every version of every object stored in a bucket.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you enable versioning?</span>
  <div class="answer">
        Using the AWS Management Console, CLI, or SDK with `put-bucket-versioning` command.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an S3 Lifecycle Rule?</span>
  <div class="answer">
        A lifecycle rule automates transitions and deletions of objects based on age or status.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are pre-signed URLs?</span>
  <div class="answer">
        Temporary links that grant time-limited access to S3 objects without needing to change bucket permissions.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an S3 policy?</span>
  <div class="answer">
        A JSON-based access policy attached to a bucket to control access permissions.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between bucket policy and IAM policy?</span>
  <div class="answer">
        Bucket policy applies to the bucket and its objects; IAM policy applies to specific users or roles.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you host a static website on S3?</span>
  <div class="answer">
        Enable static website hosting in bucket properties and upload an `index.html` and optionally an `error.html`.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a signed cookie in S3?</span>
  <div class="answer">
        A signed cookie allows access to restricted S3 content through CloudFront using cookies instead of URLs.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the default consistency model in S3?</span>
  <div class="answer">
        S3 offers strong read-after-write consistency for all objects.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you delete all versions of an object?</span>
  <div class="answer">
        Use the AWS CLI with `--version-id` or configure a lifecycle rule for expired delete markers.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you move data between storage classes?</span>
  <div class="answer">
        Automatically via lifecycle rules or manually by copying the object with the new class.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Multipart Upload?</span>
  <div class="answer">
        It allows you to upload large objects as parts, improving upload efficiency and reliability.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you list all objects in a bucket?</span>
  <div class="answer">
        Use the CLI command: `aws s3 ls s3://your-bucket-name --recursive`
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the maximum object size in S3?</span>
  <div class="answer">
        5 TB (using multipart upload). Single PUT uploads are limited to 5 GB.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you make a bucket public?</span>
  <div class="answer">
        Update the bucket policy and disable the "Block Public Access" settings.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you restrict access to specific IP addresses?</span>
  <div class="answer">
        Add an IP-based condition in the bucket policy using `aws:SourceIp`.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is S3 Transfer Acceleration?</span>
  <div class="answer">
        Speeds up uploads using Amazon CloudFront‚Äôs globally distributed edge locations.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you enable S3 event notifications?</span>
  <div class="answer">
        Configure notifications to trigger AWS Lambda, SNS, or SQS on object events (PUT, DELETE).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you set object retention in S3?</span>
  <div class="answer">
        Use Object Lock with governance or compliance retention modes.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between S3 and EBS?</span>
  <div class="answer">
        S3 is object storage for unstructured data; EBS is block storage for EC2 volumes.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can you rename an S3 object?</span>
  <div class="answer">
        No, you must copy it to a new key and delete the original.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you allow cross-account access?</span>
  <div class="answer">
        Use a bucket policy that grants permissions to another AWS account's IAM role or user.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is SSE-KMS?</span>
  <div class="answer">
        Server-Side Encryption using AWS Key Management Service for key management and auditing.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are S3 Access Points?</span>
  <div class="answer">
        Named network endpoints for managing access to shared datasets with fine-grained controls.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a bucket ACL?</span>
  <div class="answer">
        Legacy access control list allowing access to buckets/objects on a per-user basis.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you backup S3 data?</span>
  <div class="answer">
        Use Cross-Region Replication (CRR), AWS Backup, or manual object copying.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is S3 Object Lock?</span>
  <div class="answer">
        Prevents objects from being deleted or overwritten for a defined retention period.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you monitor S3 activity?</span>
  <div class="answer">
        Use CloudTrail, S3 server access logs, and AWS CloudWatch metrics.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the role of a storage class analysis in S3?</span>
  <div class="answer">
        Helps determine when to transition objects to a more cost-effective storage class.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Intelligent-Tiering?</span>
  <div class="answer">
        A storage class that automatically moves objects between frequent and infrequent access tiers.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are delete markers?</span>
  <div class="answer">
        Markers added to objects when versioning is enabled and a delete request is made.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you block public access to all buckets?</span>
  <div class="answer">
        Use the global S3 settings or bucket-level settings to block all public access.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is replication in S3?</span>
  <div class="answer">
        Automatically copies objects to another bucket (within or across regions) for backup or compliance.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are S3 metrics and how are they used?</span>
  <div class="answer">
        CloudWatch metrics like bucket size, number of objects, and request counts help in monitoring and billing.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can you host dynamic websites on S3?</span>
  <div class="answer">
        No. S3 only supports static websites; dynamic behavior must use Lambda, API Gateway, etc.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you secure S3 uploads from a frontend app?</span>
  <div class="answer">
        Use pre-signed URLs or assume-role federation (e.g., Cognito + IAM Role).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What happens when you delete a versioned object?</span>
  <div class="answer">
        A delete marker is added. The object isn‚Äôt removed unless a specific version is deleted.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you automate S3 cleanups?</span>
  <div class="answer">
        Use lifecycle rules to expire or transition objects.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can you mount an S3 bucket like a filesystem?</span>
  <div class="answer">
        Yes, using tools like s3fs-fuse, but it's not recommended for transactional workloads.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the maximum number of buckets allowed per account?</span>
  <div class="answer">
        100 by default, but you can request an increase.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you grant public read access to an object?</span>
  <div class="answer">
        Set the object ACL to `public-read` or use a bucket policy that allows public `s3:GetObject`.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are S3 Object Tags?</span>
  <div class="answer">
        Key-value pairs attached to objects that help with classification, lifecycle, and cost management.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between Glacier and Glacier Deep Archive?</span>
  <div class="answer">
        Glacier is for archive data with minutes-to-hours retrieval; Deep Archive is the lowest-cost option with 12‚Äì48 hours retrieval.
      </div>
  </li>
    
  
  <li data-id="q231" class="yellow"><span class="faq-question">AWS Cloud font</span></li>
  
      <li data-id="q231">
  <span class="faq-question">What is Amazon CloudFront?</span>
  <div class="answer">
        A content delivery network (CDN) that delivers data, videos, applications, and APIs globally with low latency.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are Edge Locations in CloudFront?</span>
  <div class="answer">
        Data centers located around the world where CloudFront caches content closer to users.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an Origin in CloudFront?</span>
  <div class="answer">
        The source of content, such as an S3 bucket, HTTP server, or ALB/EC2 instance, that CloudFront fetches from.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Distribution in CloudFront?</span>
  <div class="answer">
        A configuration that tells CloudFront where the content is stored and how to deliver it.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are the two types of CloudFront distributions?</span>
  <div class="answer">
        - Web Distribution (HTTP/HTTPS)<br>
        - RTMP Distribution (for streaming media - now deprecated)
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How does CloudFront cache content?</span>
  <div class="answer">
        Content is cached at edge locations based on Cache-Control headers, TTL, and other settings.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is TTL (Time to Live) in CloudFront?</span>
  <div class="answer">
        The duration that CloudFront caches content at edge locations before revalidating it.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an Invalidations request in CloudFront?</span>
  <div class="answer">
        A way to remove objects from the cache before they expire.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the default TTL in CloudFront?</span>
  <div class="answer">
        24 hours (can be configured per cache behavior or via headers).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the maximum file size supported by CloudFront?</span>
  <div class="answer">
        30 GB (for HTTP/HTTPS content).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a signed URL?</span>
  <div class="answer">
        A URL with an embedded policy and signature to restrict access to content.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a signed cookie?</span>
  <div class="answer">
        A cookie that allows access to restricted content without exposing URLs.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">When should you use signed cookies over signed URLs?</span>
  <div class="answer">
        When providing access to multiple restricted files, such as whole folders.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can you use HTTPS with CloudFront?</span>
  <div class="answer">
        Yes, CloudFront supports HTTPS for both viewers and origin communication.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an Origin Access Identity (OAI)?</span>
  <div class="answer">
        A CloudFront feature that allows access to private S3 buckets only through CloudFront.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you restrict S3 bucket access only through CloudFront?</span>
  <div class="answer">
        Use Origin Access Identity (OAI) and set a bucket policy to allow access only from CloudFront.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Field-Level Encryption?</span>
  <div class="answer">
        Encrypts sensitive data (like credit card info) before it reaches your origin.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Lambda@Edge?</span>
  <div class="answer">
        A feature to run Lambda functions at CloudFront edge locations for request/response manipulation.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are some use cases of Lambda@Edge?</span>
  <div class="answer">
        A/B testing, header modification, URL rewriting, authentication, and bot filtering.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What protocols does CloudFront support?</span>
  <div class="answer">
        HTTP and HTTPS.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between Viewer Protocol Policy and Origin Protocol Policy?</span>
  <div class="answer">
        Viewer Protocol: HTTP/HTTPS options for clients.<br>
        Origin Protocol: HTTP/HTTPS options for CloudFront to fetch from the origin.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can CloudFront deliver dynamic content?</span>
  <div class="answer">
        Yes, by configuring behaviors to forward all headers, cookies, and query strings.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Geo Restriction in CloudFront?</span>
  <div class="answer">
        Restricts access to content based on the viewer's country.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you monitor CloudFront?</span>
  <div class="answer">
        Use CloudWatch metrics, logs, and alarms.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the purpose of cache behaviors in CloudFront?</span>
  <div class="answer">
        To define how CloudFront handles requests based on URL patterns.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the default behavior in CloudFront?</span>
  <div class="answer">
        The default cache behavior is used when no other path patterns match.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you enable logging in CloudFront?</span>
  <div class="answer">
        Enable standard logging to an S3 bucket or real-time logs to Kinesis.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the cost of invalidation requests?</span>
  <div class="answer">
        The first 1000 paths per month are free. Charges apply thereafter.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the purpose of forwarding headers to origin?</span>
  <div class="answer">
        To help the origin serve personalized or dynamic content based on headers.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can CloudFront serve private content?</span>
  <div class="answer">
        Yes, using signed URLs or signed cookies.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Origin Failover in CloudFront?</span>
  <div class="answer">
        Enables CloudFront to route traffic to a secondary origin if the primary one fails.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the purpose of custom error pages?</span>
  <div class="answer">
        To show user-friendly error messages instead of default CloudFront responses.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between CloudFront and S3 Static Website Hosting?</span>
  <div class="answer">
        S3 delivers from a single region. CloudFront caches content globally for better performance.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you configure a custom domain with CloudFront?</span>
  <div class="answer">
        Use an alternate domain name (CNAME) and attach an SSL certificate (via ACM).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Real-Time Logging in CloudFront?</span>
  <div class="answer">
        A feature to stream logs to Kinesis Data Streams for near real-time monitoring.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Origin Shield in CloudFront?</span>
  <div class="answer">
        Adds an additional caching layer to reduce load on origins and improve performance.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the maximum number of cache behaviors per distribution?</span>
  <div class="answer">
        Up to 25 behaviors per distribution.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you secure CloudFront from DDoS attacks?</span>
  <div class="answer">
        Use AWS WAF with CloudFront and enable AWS Shield.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the maximum number of distributions per account?</span>
  <div class="answer">
        200 (can be increased via support request).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How does CloudFront handle cookie forwarding?</span>
  <div class="answer">
        You can configure behaviors to forward all, whitelist, or none.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are response headers policies?</span>
  <div class="answer">
        They control HTTP headers that CloudFront includes in responses.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are origin request policies?</span>
  <div class="answer">
        Define what headers, cookies, and query strings CloudFront includes in requests to origins.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can CloudFront compress objects?</span>
  <div class="answer">
        Yes, CloudFront supports automatic GZIP and Brotli compression.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the purpose of the Host header in CloudFront requests?</span>
  <div class="answer">
        Indicates the origin host; can be modified to support multiple sites behind one CloudFront.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What happens if your origin server uses a self-signed certificate?</span>
  <div class="answer">
        CloudFront will reject the origin unless you configure it to trust the certificate (not recommended for production).
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the purpose of caching based on query strings?</span>
  <div class="answer">
        Allows CloudFront to cache multiple versions of the same path based on query parameters.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">Can CloudFront be used with API Gateway?</span>
  <div class="answer">
        Yes, to cache and deliver APIs at edge locations for faster responses.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How does CloudFront integrate with Route 53?</span>
  <div class="answer">
        You can use Route 53 to manage DNS and point your domain to a CloudFront distribution.
      </div>
  </li>
    
  
  
  <li data-id="q231" class="yellow"><span class="faq-question">AWS Kubernetes</span></li>
      <li data-id="q231">
  <span class="faq-question">What is Kubernetes?</span>
  <div class="answer">
        Kubernetes is an open-source container orchestration platform used to automate deployment, scaling, and operations of application containers across clusters of hosts.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Pod in Kubernetes?</span>
  <div class="answer">
        A Pod is the smallest and simplest Kubernetes object. It represents a single instance of a running process in a cluster.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Node?</span>
  <div class="answer">
        A Node is a physical or virtual machine on which Kubernetes runs and manages Pods.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Cluster?</span>
  <div class="answer">
        A set of nodes that run containerized applications managed by Kubernetes.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Kubelet?</span>
  <div class="answer">
        An agent that runs on each node in the cluster and ensures containers are running in a Pod.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Deployment?</span>
  <div class="answer">
        A controller that provides declarative updates to Pods and ReplicaSets.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a ReplicaSet?</span>
  <div class="answer">
        Ensures a specified number of Pod replicas are running at any given time.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Service in Kubernetes?</span>
  <div class="answer">
        An abstraction that defines a logical set of Pods and a policy to access them.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between a Deployment and a StatefulSet?</span>
  <div class="answer">
        Deployments are used for stateless applications, while StatefulSets are used for stateful applications with stable identities.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is etcd?</span>
  <div class="answer">
        A distributed key-value store used by Kubernetes for all cluster data.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Namespace?</span>
  <div class="answer">
        A Namespace allows you to partition resources within the same cluster.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the Control Plane?</span>
  <div class="answer">
        The collection of components (API Server, Scheduler, Controller Manager, etcd) that manage the cluster.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the API Server?</span>
  <div class="answer">
        The component that exposes the Kubernetes API and serves as the frontend to the cluster's control plane.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a DaemonSet?</span>
  <div class="answer">
        Ensures that a copy of a specific Pod runs on all (or some) nodes.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Job in Kubernetes?</span>
  <div class="answer">
        A controller that creates Pods to run a task to completion.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a CronJob?</span>
  <div class="answer">
        A Job that runs on a scheduled time, similar to cron in Linux.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a ConfigMap?</span>
  <div class="answer">
        Used to store non-confidential data in key-value pairs.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Secret?</span>
  <div class="answer">
        Similar to ConfigMap, but intended for storing sensitive information like passwords and API keys.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Helm?</span>
  <div class="answer">
        A package manager for Kubernetes that simplifies deployment of applications via Helm charts.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are Labels and Selectors?</span>
  <div class="answer">
        Labels are key-value pairs attached to objects. Selectors are used to filter and identify objects by label.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a PersistentVolume (PV)?</span>
  <div class="answer">
        A piece of storage in the cluster provisioned by an administrator.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a PersistentVolumeClaim (PVC)?</span>
  <div class="answer">
        A request for storage by a user that uses a PersistentVolume.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between Rolling Update and Recreate strategy?</span>
  <div class="answer">
        Rolling Update gradually replaces Pods. Recreate deletes all old Pods before creating new ones.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Node Affinity?</span>
  <div class="answer">
        A set of rules to constrain which nodes your Pod is eligible to be scheduled on.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are Taints and Tolerations?</span>
  <div class="answer">
        Taints prevent Pods from being scheduled on nodes unless the Pod tolerates the taint.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Horizontal Pod Autoscaler (HPA)?</span>
  <div class="answer">
        Automatically scales the number of Pods based on CPU/memory usage or custom metrics.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Vertical Pod Autoscaler (VPA)?</span>
  <div class="answer">
        Automatically adjusts the resource requests and limits of Pods.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Cluster Autoscaler?</span>
  <div class="answer">
        Automatically adjusts the number of nodes in your cluster based on pending Pods.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Ingress?</span>
  <div class="answer">
        An API object that manages external access to services, typically HTTP.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between Ingress and LoadBalancer?</span>
  <div class="answer">
        LoadBalancer exposes service externally using a cloud provider‚Äôs load balancer. Ingress offers advanced routing rules.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How does Kubernetes handle networking?</span>
  <div class="answer">
        Every Pod gets a unique IP, and communication between Pods is handled via flat network model.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a CNI?</span>
  <div class="answer">
        Container Network Interface plugin responsible for configuring network interfaces in containers.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the role of kube-proxy?</span>
  <div class="answer">
        Maintains network rules on nodes and enables communication to services.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is RBAC?</span>
  <div class="answer">
        Role-Based Access Control defines permissions for users and services within the cluster.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a ServiceAccount?</span>
  <div class="answer">
        A special account for processes running in Pods to interact with the Kubernetes API.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What are readiness and liveness probes?</span>
  <div class="answer">
        Readiness: determines if a Pod is ready to receive traffic. Liveness: checks if a Pod is still running.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a MutatingWebhook and ValidatingWebhook?</span>
  <div class="answer">
        Admission controllers that intercept requests to modify or validate objects before they‚Äôre persisted.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you perform rolling updates in Kubernetes?</span>
  <div class="answer">
        By updating the Deployment with a new image or spec; Kubernetes handles the rollout.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you rollback a deployment?</span>
  <div class="answer">
        Use `kubectl rollout undo deployment/&lt;name&gt;`
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is kubeadm?</span>
  <div class="answer">
        A tool to bootstrap and manage Kubernetes clusters.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is Minikube?</span>
  <div class="answer">
        A tool to run Kubernetes locally.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Custom Resource Definition (CRD)?</span>
  <div class="answer">
        Allows users to define custom resources that extend the Kubernetes API.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is an Operator in Kubernetes?</span>
  <div class="answer">
        A method of packaging, deploying, and managing a Kubernetes application using custom resources and controllers.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is a Sidecar Container?</span>
  <div class="answer">
        A secondary container that runs alongside the main container in a Pod to enhance its functionality.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How does Kubernetes handle secrets securely?</span>
  <div class="answer">
        Secrets are base64-encoded and can be encrypted at rest using KMS or external providers.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you debug a Kubernetes Pod?</span>
  <div class="answer">
        Use commands like `kubectl logs`, `kubectl exec`, and `kubectl describe pod`.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">What is the difference between soft and hard limits in Kubernetes resources?</span>
  <div class="answer">
        Soft (requests) define guaranteed resources. Hard (limits) define max resources a Pod can use.
      </div>
  </li>
    
      <li data-id="q231">
  <span class="faq-question">How do you monitor a Kubernetes cluster?</span>
  <div class="answer">
        Use tools like Prometheus, Grafana, Metrics Server, and ELK stack.
      </div>
  </li>
   




<li data-id="q32" class="yellow"><span class="faq-question">
  Microservices
</span>
<div class="answer">

  <ol>
    <li>What are microservices?</li>
    <li>How do microservices differ from monolithic architecture?</li>
    <li>What are the main benefits of using microservices?</li>
    <li>What are the common challenges in microservices architecture?</li>
    <li>What is a service registry?</li>
    <li>What is service discovery in microservices?</li>
    <li>What is API Gateway and why is it used in microservices?</li>
    <li>How do microservices communicate with each other?</li>
    <li>What is synchronous vs asynchronous communication in microservices?</li>
    <li>What are REST and gRPC in microservices communication?</li>
    <li>What is service orchestration?</li>
    <li>What is service choreography?</li>
    <li>What is circuit breaker pattern?</li>
    <li>What is the purpose of a load balancer in microservices?</li>
    <li>What is eventual consistency?</li>
    <li>What is the Saga pattern?</li>
    <li>What is the difference between orchestration and choreography in Saga?</li>
    <li>What is a sidecar pattern?</li>
    <li>What is the strangler pattern?</li>
    <li>What are the advantages of decentralized data management in microservices?</li>
    <li>How is data consistency maintained across microservices?</li>
    <li>What is a bounded context in microservices?</li>
    <li>What is domain-driven design (DDD)?</li>
    <li>How do you handle transactions in microservices?</li>
    <li>What is a distributed transaction?</li>
    <li>How do you secure microservices?</li>
    <li>What is OAuth2 and how is it used in microservices?</li>
    <li>What is OpenID Connect?</li>
    <li>What is service mesh?</li>
    <li>How does Istio or Linkerd work in a microservices setup?</li>
    <li>What is containerization and how does it help microservices?</li>
    <li>What is the role of Docker in microservices?</li>
    <li>What is Kubernetes and how does it relate to microservices?</li>
    <li>How do you monitor microservices?</li>
    <li>What tools are used for logging in microservices?</li>
    <li>How is tracing handled in distributed microservices?</li>
    <li>What is Zipkin or Jaeger?</li>
    <li>How do you handle fault tolerance in microservices?</li>
    <li>What is load shedding in microservices?</li>
    <li>What is backpressure?</li>
    <li>How do you deploy microservices?</li>
    <li>What is a blue-green deployment?</li>
    <li>What is a canary deployment?</li>
    <li>What is the 12-factor app methodology?</li>
    <li>What are environment variables and why are they used?</li>
    <li>How do you handle versioning in microservices?</li>
    <li>What is a polyglot persistence architecture?</li>
    <li>How do you ensure idempotency in microservices?</li>
    <li>What is anti-corruption layer in microservices?</li>
    <li>What is the bulkhead pattern?</li>
    <li>What is the retry pattern?</li>
    <li>What is the difference between API Gateway and Service Mesh?</li>
    <li>How do you implement rate limiting in microservices?</li>
    <li>What are idempotent operations?</li>
    <li>What is the role of message brokers in microservices?</li>
    <li>What is RabbitMQ / Kafka and how are they used?</li>
    <li>What is a dead letter queue (DLQ)?</li>
    <li>What is a poison message?</li>
    <li>How do you handle schema evolution in microservices?</li>
    <li>What are contract tests in microservices?</li>
    <li>What is consumer-driven contract testing?</li>
    <li>What is Pact and how does it work?</li>
    <li>How do you manage microservice dependencies?</li>
    <li>How do you isolate failures in microservices?</li>
    <li>What is a distributed cache?</li>
    <li>How does Redis or Memcached help in microservices?</li>
    <li>What are some best practices in designing microservices?</li>
    <li>How do you handle cross-cutting concerns in microservices?</li>
    <li>What is centralized logging?</li>
    <li>How do you test microservices?</li>
    <li>What are unit tests, integration tests, and end-to-end tests in microservices?</li>
    <li>How do you debug microservices in production?</li>
    <li>What is chaos engineering?</li>
    <li>What is Netflix OSS stack for microservices?</li>
    <li>What is Hystrix and why was it deprecated?</li>
    <li>What is Spring Cloud?</li>
    <li>What is Consul or Eureka in microservices?</li>
    <li>How do you scale microservices?</li>
    <li>What is horizontal scaling vs vertical scaling?</li>
    <li>What are shared-nothing architectures?</li>
    <li>How do you migrate a monolith to microservices?</li>
    <li>What is the database-per-service pattern?</li>
    <li>What is the shared-database anti-pattern?</li>
    <li>How do you handle configuration in microservices?</li>
    <li>What is centralized configuration management?</li>
    <li>What is Spring Cloud Config / HashiCorp Vault?</li>
    <li>How do you handle secrets in microservices?</li>
    <li>What is the Ambassador pattern?</li>
    <li>What is the Adapter pattern in microservices?</li>
    <li>How do you ensure observability in microservices?</li>
    <li>What are metrics and how do you expose them?</li>
    <li>What are Prometheus and Grafana used for?</li>
    <li>How do you handle slow services in microservices architecture?</li>
    <li>What is service timeout and retry strategy?</li>
    <li>What are best practices for API design in microservices?</li>
    <li>How do you document microservices APIs?</li>
    <li>What is Swagger / OpenAPI?</li>
    <li>How do you handle multi-tenancy in microservices?</li>
    <li>What is tenant isolation?</li>
    <li>How do microservices affect DevOps?</li>
    <li>What is CI/CD for microservices?</li>
    <li>How do you implement feature toggles in microservices?</li>
    <li>What are dark launches?</li>
    <li>How do you ensure transactional integrity in a distributed microservices environment?</li>
    <li>Can you explain the difference between Saga pattern and 2-phase commit? When would you use each?</li>
    <li>How would you handle distributed tracing across 100+ microservices?</li>
    <li>What are the major trade-offs of eventual consistency vs strong consistency?</li>
    <li>How do you implement zero-downtime deployments for microservices?</li>
    <li>How do you resolve cyclic dependencies between microservices?</li>
    <li>How would you handle schema evolution in Kafka-based microservices communication?</li>
    <li>Explain how to design a microservice that needs to perform large batch processing without overwhelming downstream services.</li>
    <li>How would you implement role-based access control (RBAC) in a microservice architecture?</li>
    <li>What are the performance implications of synchronous vs asynchronous communication in a highly-scalable microservice system?</li>
    <li>How would you design multi-region microservices with low latency and high availability?</li>
    <li>How do you ensure data consistency between services that share no common database?</li>
    <li>How would you design a versioning strategy for public-facing APIs in microservices?</li>
    <li>How would you handle the "n+1 query problem" in a microservices architecture?</li>
    <li>How do you monitor and enforce SLAs (Service Level Agreements) for each microservice?</li>
    <li>What are the limitations of API Gateway pattern, and how do you overcome them?</li>
    <li>How do you manage secrets across 100+ microservices securely?</li>
    <li>How would you implement fine-grained rate limiting per user and per service?</li>
    <li>What is the CAP theorem and how does it apply to microservice design?</li>
    <li>What challenges arise when running stateful microservices on Kubernetes?</li>
    <li>How would you handle race conditions when updating shared data across services?</li>
    <li>How do you implement a fail-safe mechanism for service dependencies?</li>
    <li>How do you manage backward compatibility when breaking up a monolith into microservices?</li>
    <li>How do you detect and prevent cascading failures in a microservice system?</li>
    <li>What strategies would you use to isolate a noisy neighbor microservice?</li>
    <li>How would you ensure idempotency in event-driven microservices?</li>
    <li>How do you perform load testing for microservice communication paths?</li>
    <li>How would you structure log correlation IDs across distributed systems?</li>
    <li>Explain how the Outbox Pattern helps in distributed event publishing.</li>
    <li>How do you deal with partial failures in long-running workflows?</li>
    <li>How would you implement retry with exponential backoff and jitter for service calls?</li>
    <li>How do you manage connection pools in services making high volume database or HTTP requests?</li>
    <li>How do you design a data aggregation layer across multiple microservices?</li>
    <li>How would you architect a microservices-based real-time analytics system?</li>
    <li>How do you coordinate deployments of interdependent microservices without downtime?</li>
    <li>How do you ensure GDPR compliance in a microservices architecture?</li>
    <li>How would you implement centralized auditing in a decentralized service ecosystem?</li>
    <li>How would you handle concurrent updates to shared data across services?</li>
    <li>How do you maintain referential integrity when using separate databases per service?</li>
    <li>What is the role of eventual consistency in highly available systems and what are its caveats?</li>
    <li>How do you debug performance issues in a microservice with high latency?</li>
    <li>How would you handle timeouts and retries in a nested call chain of microservices?</li>
    <li>How do you secure communication between services in an untrusted network?</li>
    <li>What are the pros and cons of using gRPC vs REST in internal microservice communication?</li>
    <li>How do you automate chaos engineering tests in microservice deployments?</li>
    <li>How would you enforce authentication and authorization uniformly across microservices?</li>
    <li>How would you implement a global transaction log across services?</li>
    <li>How would you evolve your database schema while minimizing downtime and impact to dependent services?</li>
    <li>How would you implement data sharding in a microservices architecture?</li>
  </ol>
    



</div></li>



  <li data-id="q1wwww">
    <span class="faq-question">What are microservices?</span>
    <div class="answer">
      Microservices are an architectural style where an application is structured as a collection of loosely coupled, independently deployable services. Each service is responsible for a specific business capability and communicates with other services through well-defined APIs.
    </div>
  </li>

  <li data-id="q2qq">
    <span class="faq-question">How do microservices differ from monolithic architecture?</span>
    <div class="answer">
      In a monolithic architecture, all components are tightly integrated and run as a single application. Microservices, on the other hand, break the application into smaller, independent services that can be developed, deployed, and scaled separately. This leads to better flexibility, scalability, and maintainability.
    </div>
  </li>

  <li data-id="qqq3">
    <span class="faq-question">What are the main benefits of using microservices?</span>
    <div class="answer">
      <ul>
        <li>Independent deployment and scaling</li>
        <li>Better fault isolation and resilience</li>
        <li>Technology flexibility for each service</li>
        <li>Improved developer productivity</li>
        <li>Easier continuous delivery and DevOps integration</li>
      </ul>
    </div>
  </li>

  <li data-id="q4qq">
    <span class="faq-question">What are the common challenges in microservices architecture?</span>
    <div class="answer">
      <ul>
        <li>Complex service communication and orchestration</li>
        <li>Distributed data management</li>
        <li>Monitoring and debugging complexity</li>
        <li>Service versioning and backward compatibility</li>
        <li>Security and authorization between services</li>
      </ul>
    </div>
  </li>

  <li data-id="qqqqq5">
    <span class="faq-question">What is a service registry?</span>
    <div class="answer">
      A service registry is a database or directory used to dynamically register and discover microservices. It keeps track of service instances and their locations (IP/port), allowing other services to find and communicate with them. Popular examples include Netflix Eureka, Consul, and etcd.
    </div>
  </li>
  <li data-id="mbqqq1">
    <span class="faq-question">What is service discovery in microservices?</span>
    <div class="answer">
      Service discovery is the process by which a microservice automatically detects the location (IP address and port) of other services in the architecture. This is crucial in dynamic environments where services may scale up/down or restart frequently. Service discovery can be client-side (e.g., Netflix Eureka) or server-side (e.g., Kubernetes).
    </div>
  </li>
  
  <li data-id="mbqqq2">
    <span class="faq-question">What is API Gateway and why is it used in microservices?</span>
    <div class="answer">
      An API Gateway acts as a single entry point for all client requests in a microservices architecture. It handles request routing, authentication, rate limiting, load balancing, and protocol translation. It abstracts the internal service structure and helps simplify communication between clients and services.
    </div>
  </li>
  
  <li data-id="mbqqq3">
    <span class="faq-question">How do microservices communicate with each other?</span>
    <div class="answer">
      Microservices communicate via network protocols using inter-process communication. The most common methods are:
      <ul>
        <li><strong>HTTP/HTTPS</strong> (REST APIs)</li>
        <li><strong>gRPC</strong> (binary, efficient communication)</li>
        <li><strong>Message brokers</strong> like RabbitMQ, Kafka (for asynchronous messaging)</li>
      </ul>
      The choice depends on latency, data volume, and architectural style.
    </div>
  </li>
  
  <li data-id="mbqqq4">
    <span class="faq-question">What is synchronous vs asynchronous communication in microservices?</span>
    <div class="answer">
      <ul>
        <li><strong>Synchronous communication</strong> involves a direct request-response interaction between services (e.g., REST or gRPC). The calling service waits for a response.</li>
        <li><strong>Asynchronous communication</strong> uses message queues or event streaming (e.g., RabbitMQ, Kafka) where the sender doesn't wait for a response. It's useful for decoupling, scaling, and resiliency.</li>
      </ul>
    </div>
  </li>
  
  <li data-id="mbqqq5">
    <span class="faq-question">What are REST and gRPC in microservices communication?</span>
    <div class="answer">
      <ul>
        <li><strong>REST (Representational State Transfer)</strong> is a widely used HTTP-based protocol where services expose endpoints. It's language-agnostic, human-readable (JSON), but slower due to overhead.</li>
        <li><strong>gRPC (Google Remote Procedure Call)</strong> uses HTTP/2 and Protocol Buffers for compact, efficient communication. It supports bi-directional streaming and is ideal for internal service communication where performance matters.</li>
      </ul>
    </div>
  </li>
  


  <li data-id="mbqqq6">
    <span class="faq-question">What is service orchestration?</span>
    <div class="answer">
      Service orchestration is a centralized approach to managing the interactions between microservices. A central controller (or orchestrator) coordinates the flow of messages and tasks, ensuring that services perform specific steps in a defined order. Tools like Camunda, AWS Step Functions, and Apache Airflow are often used for orchestration.
    </div>
  </li>
  
  <li data-id="mbqqq7">
    <span class="faq-question">What is service choreography?</span>
    <div class="answer">
      Service choreography is a decentralized approach to microservices communication. Each service knows when to act and whom to notify, based on events. There's no central coordinator‚Äîservices interact through events or messages, making the system more loosely coupled. This is common in event-driven architectures.
    </div>
  </li>
  
  <li data-id="mbqqq8">
    <span class="faq-question">What is circuit breaker pattern?</span>
    <div class="answer">
      The circuit breaker pattern is used to detect and handle failures gracefully. When a service call fails repeatedly, the circuit breaker trips, preventing further requests for a time. This helps to avoid overwhelming a failing service and allows it to recover. Libraries like Netflix Hystrix or Resilience4j implement this pattern.
    </div>
  </li>
  
  <li data-id="mbqqq9">
    <span class="faq-question">What is the purpose of a load balancer in microservices?</span>
    <div class="answer">
      A load balancer distributes incoming requests evenly across multiple instances of a microservice. It helps improve fault tolerance, scalability, and availability by ensuring no single instance is overwhelmed. Load balancers can be implemented at various layers ‚Äî DNS, L4 (TCP), or L7 (HTTP).
    </div>
  </li>
  
  <li data-id="mbqqq10">
    <span class="faq-question">What is eventual consistency?</span>
    <div class="answer">
      Eventual consistency is a consistency model used in distributed systems where updates to data are not immediately visible to all services but will become consistent over time. It sacrifices strong consistency for availability and partition tolerance (as per CAP theorem), and is commonly used in microservices and NoSQL databases.
    </div>
  </li>
  

  <li data-id="mbqqq11">
    <span class="faq-question">What is the Saga pattern?</span>
    <div class="answer">
      The Saga pattern is a design pattern for managing distributed transactions across multiple microservices. Instead of a single, atomic transaction, a Saga breaks the process into a series of local transactions. Each step has a compensating action to undo its work in case of failure, ensuring data consistency without 2PC (two-phase commit).
    </div>
  </li>
  
  <li data-id="mbqqq12">
    <span class="faq-question">What is the difference between orchestration and choreography in Saga?</span>
    <div class="answer">
      <ul>
        <li><strong>Orchestration:</strong> A central service (or orchestrator) controls the sequence of steps in the Saga and invokes other services to perform tasks.</li>
        <li><strong>Choreography:</strong> Each service listens for events and performs its step independently, emitting a new event to trigger the next step. There's no central controller.</li>
      </ul>
    </div>
  </li>
  
  <li data-id="mbqqq13">
    <span class="faq-question">What is a sidecar pattern?</span>
    <div class="answer">
      The sidecar pattern is a design pattern where a helper service (sidecar) is deployed alongside the main microservice in the same container or pod. It adds capabilities such as logging, monitoring, service discovery, or security without modifying the main application logic. Istio uses this for its service mesh data plane.
    </div>
  </li>
  
  <li data-id="mbqqq14">
    <span class="faq-question">What is the strangler pattern?</span>
    <div class="answer">
      The strangler pattern is a technique for gradually migrating a monolithic system to microservices. New functionality is developed as independent services, and parts of the monolith are replaced over time. The legacy system is slowly "strangled" until it can be completely decommissioned.
    </div>
  </li>
  
  <li data-id="mbqqq15">
    <span class="faq-question">What are the advantages of decentralized data management in microservices?</span>
    <div class="answer">
      <ul>
        <li>Each service can use the database that best fits its requirements (polyglot persistence).</li>
        <li>Services are more loosely coupled and can evolve independently.</li>
        <li>Improves scalability and performance by avoiding shared database bottlenecks.</li>
        <li>Reduces single points of failure and allows better fault isolation.</li>
      </ul>
    </div>
  </li>
  
  <li data-id="mbqqq16">
    <span class="faq-question">How is data consistency maintained across microservices?</span>
    <div class="answer">
      In microservices, data consistency is typically achieved using eventual consistency mechanisms such as:
      <ul>
        <li>Saga Pattern for long-running distributed transactions</li>
        <li>Event-driven architecture with reliable messaging (Kafka, RabbitMQ)</li>
        <li>Idempotent operations to safely handle retries</li>
        <li>Outbox pattern to ensure reliable event publishing from databases</li>
      </ul>
      Strong consistency is avoided due to the trade-offs in availability and performance in distributed systems.
    </div>
  </li>
  
  <li data-id="mbqqq17">
    <span class="faq-question">What is a bounded context in microservices?</span>
    <div class="answer">
      A bounded context defines a logical boundary within which a particular domain model is defined and applicable. In microservices, each service typically represents a bounded context, meaning it owns and encapsulates its own data and logic, preventing tight coupling and promoting clear domain separation.
    </div>
  </li>
  
  <li data-id="mbqqq18">
    <span class="faq-question">What is domain-driven design (DDD)?</span>
    <div class="answer">
      Domain-Driven Design (DDD) is an approach to software development that emphasizes deep understanding of the business domain. It encourages structuring software around domain models and business logic. DDD promotes concepts like entities, value objects, aggregates, repositories, and bounded contexts, which align naturally with microservices architecture.
    </div>
  </li>
  
  <li data-id="mbqqq19">
    <span class="faq-question">How do you handle transactions in microservices?</span>
    <div class="answer">
      Traditional ACID transactions are hard to maintain in distributed systems. Microservices handle transactions using:
      <ul>
        <li>Saga Pattern for coordinating a series of local transactions</li>
        <li>Compensating transactions to roll back actions in case of failure</li>
        <li>Eventual consistency and reliable messaging</li>
        <li>Idempotent APIs and retry mechanisms</li>
      </ul>
    </div>
  </li>
  
  <li data-id="mbqqq20">
    <span class="faq-question">What is a distributed transaction?</span>
    <div class="answer">
      A distributed transaction involves multiple services or databases participating in a single logical transaction. Ensuring atomicity across them is difficult due to network delays and failures. Distributed transactions can be coordinated using two-phase commit (2PC), but this is heavy and not scalable. Microservices often avoid distributed transactions in favor of eventual consistency models.
    </div>
  </li>
  
      

<li data-id="q32" class="yellow"><span class="faq-question">
------------------------------------------------------------------
</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">
--------------------------------------------------------------
</span></li>
<li data-id="q32" class="yellow"><span class="faq-question">
-------------------------------------------------
<br />
rm package-lock.json && rm -rf node_modules && npm install && npm install --package-lock-only && git add package-lock.json && git commit -m "Fix: update lockfile to match package.json" && git push
</span></li>
    
</ul>

<script src="script.js"></script>

</body>
</html>
